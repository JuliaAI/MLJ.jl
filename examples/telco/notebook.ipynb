{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLJ for Data Scientists in Two Hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An end-to-end application of the [MLJ\n",
    "toolbox](https://alan-turing-institute.github.io/MLJ.jl/dev/) to the\n",
    "Telco Customer Churn dataset, aimed at practicing data scientists\n",
    "new to MLJ (Machine Learning in Julia)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLJ is a *multi-paradigm* machine learning toolbox (i.e., not just\n",
    "deep-learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New to machine learning?**\n",
    "Try the \"Introduction to Statistical Learning\" notebooks at [Data\n",
    "Science\n",
    "Tutorials](https://juliaai.github.io/DataScienceTutorials.jl/),\n",
    "starting with [this\n",
    "tutorial](https://juliaai.github.io/DataScienceTutorials.jl/isl/lab-2/).\n",
    "Or have a look at the [Julia Data\n",
    "Science](https://github.com/JuliaDataScience/JuliaDataScience) book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Want a shorter tour of key MLJ functionality?**\n",
    "Try this [Lightning\n",
    "Tour](https://github.com/alan-turing-institute/MLJ.jl/blob/dev/examples/lightning_tour/lightning_tour.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Something more leisurely?** See\n",
    "[MLJTutorial](https://github.com/ablaom/MLJTutorial.jl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Completely new to Julia?** Browse [these\n",
    "resources](https://julialang.org/learning/) or visit\n",
    "[HelloJulia](https://github.com/ablaom/HelloJulia.jl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more end-to-end examples, see [Data Science\n",
    "Tutorials](https://juliaai.github.io/DataScienceTutorials.jl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topics covered**: Grabbing and preparing a dataset, basic\n",
    "fit/predict workflow, constructing a pipeline to include data\n",
    "pre-processing, estimating performance metrics, ROC curves, confusion\n",
    "matrices, feature importance, basic feature selection, controlling iterative\n",
    "models, hyper-parameter optimization (tuning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prerequisites for this tutorial.** Previous experience building,\n",
    "evaluating, and optimizing machine learning models using\n",
    "scikit-learn, caret, MLR, weka, or similar tool. No previous\n",
    "experience with MLJ. Only fairly basic familiarity with Julia is\n",
    "required. Uses\n",
    "[DataFrames.jl](https://dataframes.juliadata.org/stable/) but in a\n",
    "minimal way ([this\n",
    "cheatsheet](https://ahsmart.com/pub/data-wrangling-with-data-frames-jl-cheat-sheet/index.html)\n",
    "may help)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time.** Between two and three hours, first time through."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of methods and types introduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|code   | purpose|\n",
    "|:-------|:-------------------------------------------------------|\n",
    "|`OpenML.load(id)` | grab a dataset from [OpenML.org](https://www.openml.org)|\n",
    "|`scitype(X)`      | inspect the scientific type (scitype) of object `X`|\n",
    "|`schema(X)`       | inspect the column scitypes (scientific types) of a table `X`|\n",
    "|`coerce(X, ...)`   | fix column encodings to get appropriate scitypes|\n",
    "|`partition(data, frac1, frac2, ...; rng=...)` | vertically split `data`, which can be a table, vector or matrix|\n",
    "|`unpack(table, f1, f2, ...)` | horizontally split `table` based on conditions `f1`, `f2`, ..., applied to column names|\n",
    "|`@load ModelType pkg=...`           | load code defining a model type|\n",
    "|`input_scitype(model)` | inspect the scitype that a model requires for features (inputs)|\n",
    "|`target_scitype(model)`| inspect the scitype that a model requires for the target (labels)|\n",
    "|`ContinuousEncoder`   | built-in model type for re-encoding all features as `Continuous`|# |`model1 |> model2` |> ...` | combine multiple models into a pipeline\n",
    "| `measures(\"under curve\")` | list all measures (metrics) with string \"under curve\" in documentation\n",
    "| `accuracy(yhat, y)` | compute accuracy of predictions `yhat` against ground truth observations `y`\n",
    "| `auc(yhat, y)`, `brier_loss(yhat, y)` | evaluate two probabilistic measures (`yhat` a vector of probability distributions)\n",
    "| `machine(model, X, y)` | bind `model` to training data `X` (features) and `y` (target)\n",
    "| `fit!(mach, rows=...)` | train machine using specified rows (observation indices)\n",
    "| `predict(mach, rows=...)`, | make in-sample model predictions given specified rows\n",
    "| `predict(mach, Xnew)` | make predictions given new features `Xnew`\n",
    "| `fitted_params(mach)` | inspect learned parameters\n",
    "| `report(mach)`        | inspect other outcomes of training\n",
    "| `confmat(yhat, y)`    | confusion matrix for predictions `yhat` and ground truth `y`\n",
    "| `roc(yhat, y)` | compute points on the receiver-operator Characteristic\n",
    "| `StratifiedCV(nfolds=6)` | 6-fold stratified cross-validation resampling strategy\n",
    "| `Holdout(fraction_train=0.7)` | holdout resampling strategy\n",
    "| `evaluate(model, X, y; resampling=..., options...)` | estimate performance metrics `model` using the data `X`, `y`\n",
    "| `FeatureSelector()` | transformer for selecting features\n",
    "| `Step(3)` | iteration control for stepping 3 iterations\n",
    "| `NumberSinceBest(6)`, `TimeLimit(60/5), InvalidValue()` | iteration control stopping criteria\n",
    "| `IteratedModel(model=..., controls=..., options...)` | wrap an iterative `model` in control strategies\n",
    "| `range(model,  :some_hyperparam, lower=..., upper=...)` | define a numeric range\n",
    "| `RandomSearch()` | random search tuning strategy\n",
    "| `TunedModel(model=..., tuning=..., options...)` | wrap the supervised `model` in specified `tuning` strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate a Julia environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code replicates precisely the set of Julia packages\n",
    "used to develop this tutorial. If this is your first time running\n",
    "the notebook, package instantiation and pre-compilation may take a\n",
    "minute or so to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `~/GoogleDrive/Julia/MLJ/MLJ/examples/telco/Project.toml`\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_libpthread_stubs_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_xtrans_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFriBidi_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLZO_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLibuuid_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mWayland_protocols_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLibffi_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mx264_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLibmount_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLAME_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mlibfdk_aac_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLibgpg_error_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGraphite2_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mlibpng_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_libXdmcp_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPixman_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mOpus_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mBzip2_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_libXau_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mx265_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mJpegTurbo_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mExpat_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLLVMExtra_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPCRE_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mOgg_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLibgcrypt_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFreeType2_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGettext_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mWayland_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLibtiff_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mlibvorbis_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXSLT_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFontconfig_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGlib_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_libxcb_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_xcb_util_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_libX11_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_xcb_util_image_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_xcb_util_renderutil_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_xcb_util_keysyms_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_libXext_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_xcb_util_wm_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_libXrender_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_libxkbfile_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_libXfixes_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mSpecialFunctions\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLLVM\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_libXinerama_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLibglvnd_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_libXrandr_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_xkbcomp_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_libXcursor_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_libXi_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCairo_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mXorg_xkeyboard_config_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGLFW_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mHarfBuzz_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mxkbcommon_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStatsFuns\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mlibass_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mQt5Base_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGPUArrays\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFFMPEG_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFFMPEG\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGR_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGPUCompiler\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGR\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mDistributions\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mScientificTypes\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCategoricalDistributions\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMLJModels\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMLJBase\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMLJEnsembles\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMLJTuning\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMLJSerialization\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMLJIteration\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mMLJ\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCUDA\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mPlots\n",
      "\u001b[32m  ✓ \u001b[39mEvoTrees\n",
      "  80 dependencies successfully precompiled in 62 seconds (120 already precompiled)\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(@__DIR__) # get env from TOML files in same directory as this notebook\n",
    "Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm up: Building a model for the iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before turning to the Telco Customer Churn dataset, we very quickly\n",
    "build a predictive model for Fisher's well-known iris data set, as way of\n",
    "introducing the main actors in any MLJ workflow. Details that you\n",
    "don't fully grasp should become clearer in the Telco study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is a condensed adaption of the [Getting Started\n",
    "example](https://alan-turing-institute.github.io/MLJ.jl/dev/getting_started/#Fit-and-predict)\n",
    "in the MLJ documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, using the built-in iris dataset, we load and inspect the features\n",
    "`X_iris` (a table) and target variable `y_iris` (a vector):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling MLJ [add582a8-e3ab-11e8-2d5e-e98b27df1bc7]\n",
      "└ @ Base loading.jl:1342\n"
     ]
    }
   ],
   "source": [
    "using MLJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────────┬────────────┬─────────┐\n",
       "│\u001b[22m names        \u001b[0m│\u001b[22m scitypes   \u001b[0m│\u001b[22m types   \u001b[0m│\n",
       "├──────────────┼────────────┼─────────┤\n",
       "│ sepal_length │ Continuous │ Float64 │\n",
       "│ sepal_width  │ Continuous │ Float64 │\n",
       "│ petal_length │ Continuous │ Float64 │\n",
       "│ petal_width  │ Continuous │ Float64 │\n",
       "└──────────────┴────────────┴─────────┘\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const X_iris, y_iris = @load_iris;\n",
    "schema(X_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element CategoricalArrays.CategoricalArray{String,1,UInt32}:\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_iris[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{String}:\n",
       " \"setosa\"\n",
       " \"versicolor\"\n",
       " \"virginica\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels(y_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a decision tree model, from the package DecisionTree.jl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main /Users/anthony/.julia/packages/MLJModels/EhaRK/src/loading.jl:168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJDecisionTreeInterface ✔\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(\n",
       "    max_depth = -1,\n",
       "    min_samples_leaf = 1,\n",
       "    min_samples_split = 5,\n",
       "    min_purity_increase = 0.0,\n",
       "    n_subfeatures = 0,\n",
       "    post_prune = false,\n",
       "    merge_purity_threshold = 1.0,\n",
       "    pdf_smoothing = 0.0,\n",
       "    display_depth = 5,\n",
       "    rng = Random._GLOBAL_RNG())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTree = @load DecisionTreeClassifier pkg=DecisionTree # model type\n",
    "model = DecisionTree(min_samples_split=5)                    # model instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In MLJ, a *model* is just a container for hyper-parameters of\n",
    "some learning algorithm. It does not store learned parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we bind the model together with the available data in what's\n",
    "called a *machine*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Machine{DecisionTreeClassifier,…} trained 0 times; caches data\n",
       "  model: MLJDecisionTreeInterface.DecisionTreeClassifier\n",
       "  args: \n",
       "    1:\tSource @223 ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\tSource @375 ⏎ `AbstractVector{Multiclass{3}}`\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mach = machine(model, X_iris, y_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A machine is essentially just a model (ie, hyper-parameters) plus data, but\n",
    "it additionally stores *learned parameters* (the tree) once it is\n",
    "trained on some view of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{DecisionTreeClassifier,…}.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/pCiRR/src/machines.jl:464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tree = Decision Tree\n",
       "Leaves: 5\n",
       "Depth:  3,\n",
       " encoding = Dict{CategoricalArrays.CategoricalValue{String, UInt32}, UInt32}(\"virginica\" => 0x00000003, \"setosa\" => 0x00000001, \"versicolor\" => 0x00000002),)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rows = vcat(1:60, 91:150); # some row indices (observations are rows not columns)\n",
    "fit!(mach, rows=train_rows)\n",
    "fitted_params(mach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A machine stores some other information enabling [warm\n",
    "restart](https://alan-turing-institute.github.io/MLJ.jl/dev/machines/#Warm-restarts)\n",
    "for some models, but we won't go into that here. You are allowed to\n",
    "access and mutate the `model` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Updating Machine{DecisionTreeClassifier,…}.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/pCiRR/src/machines.jl:465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Machine{DecisionTreeClassifier,…} trained 2 times; caches data\n",
       "  model: MLJDecisionTreeInterface.DecisionTreeClassifier\n",
       "  args: \n",
       "    1:\tSource @223 ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\tSource @375 ⏎ `AbstractVector{Multiclass{3}}`\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mach.model.min_samples_split  = 10\n",
    "fit!(mach, rows=train_rows) # re-train with new hyper-parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make predictions on some other view of the data, as in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element CategoricalDistributions.UnivariateFiniteVector{Multiclass{3}, String, UInt32, Float64}:\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.0, versicolor=>0.0, virginica=>1.0)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.0, versicolor=>1.0, virginica=>0.0)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.0, versicolor=>0.25, virginica=>0.75)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(mach, rows=71:73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or on completely new data, as in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element CategoricalDistributions.UnivariateFiniteVector{Multiclass{3}, String, UInt32, Float64}:\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>1.0, versicolor=>0.0, virginica=>0.0)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.0, versicolor=>0.25, virginica=>0.75)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnew = (sepal_length = [5.1, 6.3],\n",
    "        sepal_width = [3.0, 2.5],\n",
    "        petal_length = [1.4, 4.9],\n",
    "        petal_width = [0.3, 1.5])\n",
    "yhat = predict(mach, Xnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are probabilistic predictions which can be manipulated using a\n",
    "widely adopted interface defined in the Distributions.jl\n",
    "package. For example, we can get raw probabilities like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 0.0\n",
       " 0.75"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.(yhat, \"virginica\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now turn to the Telco dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Telco data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling DataFrames [a93c6f00-e57d-5684-b7b6-d8193f3e46c0]\n",
      "└ @ Base loading.jl:1342\n"
     ]
    }
   ],
   "source": [
    "import DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>4 rows × 21 columns (omitted printing of 13 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>customerID</th><th>gender</th><th>SeniorCitizen</th><th>Partner</th><th>Dependents</th><th>tenure</th><th>PhoneService</th><th>MultipleLines</th></tr><tr><th></th><th title=\"String\">String</th><th title=\"String\">String</th><th title=\"Float64\">Float64</th><th title=\"String\">String</th><th title=\"String\">String</th><th title=\"Float64\">Float64</th><th title=\"String\">String</th><th title=\"String\">String</th></tr></thead><tbody><tr><th>1</th><td>7590-VHVEG</td><td>Female</td><td>0.0</td><td>Yes</td><td>No</td><td>1.0</td><td>No</td><td>No phone service</td></tr><tr><th>2</th><td>5575-GNVDE</td><td>Male</td><td>0.0</td><td>No</td><td>No</td><td>34.0</td><td>Yes</td><td>No</td></tr><tr><th>3</th><td>3668-QPYBK</td><td>Male</td><td>0.0</td><td>No</td><td>No</td><td>2.0</td><td>Yes</td><td>No</td></tr><tr><th>4</th><td>7795-CFOCW</td><td>Male</td><td>0.0</td><td>No</td><td>No</td><td>45.0</td><td>No</td><td>No phone service</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& customerID & gender & SeniorCitizen & Partner & Dependents & tenure & PhoneService & MultipleLines & \\\\\n",
       "\t\\hline\n",
       "\t& String & String & Float64 & String & String & Float64 & String & String & \\\\\n",
       "\t\\hline\n",
       "\t1 & 7590-VHVEG & Female & 0.0 & Yes & No & 1.0 & No & No phone service & $\\dots$ \\\\\n",
       "\t2 & 5575-GNVDE & Male & 0.0 & No & No & 34.0 & Yes & No & $\\dots$ \\\\\n",
       "\t3 & 3668-QPYBK & Male & 0.0 & No & No & 2.0 & Yes & No & $\\dots$ \\\\\n",
       "\t4 & 7795-CFOCW & Male & 0.0 & No & No & 45.0 & No & No phone service & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m4×21 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m customerID \u001b[0m\u001b[1m gender \u001b[0m\u001b[1m SeniorCitizen \u001b[0m\u001b[1m Partner \u001b[0m\u001b[1m Dependents \u001b[0m\u001b[1m tenure  \u001b[0m\u001b[1m PhoneS\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String     \u001b[0m\u001b[90m String \u001b[0m\u001b[90m Float64       \u001b[0m\u001b[90m String  \u001b[0m\u001b[90m String     \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m String\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ 7590-VHVEG  Female            0.0  Yes      No              1.0  No     ⋯\n",
       "   2 │ 5575-GNVDE  Male              0.0  No       No             34.0  Yes\n",
       "   3 │ 3668-QPYBK  Male              0.0  No       No              2.0  Yes\n",
       "   4 │ 7795-CFOCW  Male              0.0  No       No             45.0  No\n",
       "\u001b[36m                                                              15 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = OpenML.load(42178) # data set from OpenML.org\n",
    "df0 = DataFrames.DataFrame(data)\n",
    "first(df0, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object of this tutorial is to build and evaluate supervised\n",
    "learning models to predict the `:Churn` variable, a binary variable\n",
    "measuring customer retention, based on other variables that are\n",
    "relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table, observations correspond to rows, and features to\n",
    "columns, which is the convention for representing all\n",
    "two-dimensional data in MLJ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type coercion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Introduces: `scitype`, `schema`, `coerce`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [\"scientific\n",
    "type\"](https://juliaai.github.io/ScientificTypes.jl/dev/) or\n",
    "*scitype* indicates how MLJ will *interpret* data. For example,\n",
    "`typeof(3.14) == Float64`, while `scitype(3.14) == Continuous` and\n",
    "also `scitype(3.14f0) == Continuous`. In MLJ, model data\n",
    "requirements are articulated using scitypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are common \"scalar\" scitypes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/scitypes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also container scitypes. For example, the scitype of any\n",
    "`N`-dimensional array is `AbstractArray{S, N}`, where `S` is the scitype of the\n",
    "elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AbstractVector{Textual} (alias for AbstractArray{Textual, 1})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scitype([\"cat\", \"mouse\", \"dog\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `schema` operator summarizes the column scitypes of a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>21 rows × 3 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>names</th><th>scitypes</th><th>types</th></tr><tr><th></th><th title=\"Symbol\">Symbol</th><th title=\"DataType\">DataType</th><th title=\"DataType\">DataType</th></tr></thead><tbody><tr><th>1</th><td>customerID</td><td>Textual</td><td>String</td></tr><tr><th>2</th><td>gender</td><td>Textual</td><td>String</td></tr><tr><th>3</th><td>SeniorCitizen</td><td>Continuous</td><td>Float64</td></tr><tr><th>4</th><td>Partner</td><td>Textual</td><td>String</td></tr><tr><th>5</th><td>Dependents</td><td>Textual</td><td>String</td></tr><tr><th>6</th><td>tenure</td><td>Continuous</td><td>Float64</td></tr><tr><th>7</th><td>PhoneService</td><td>Textual</td><td>String</td></tr><tr><th>8</th><td>MultipleLines</td><td>Textual</td><td>String</td></tr><tr><th>9</th><td>InternetService</td><td>Textual</td><td>String</td></tr><tr><th>10</th><td>OnlineSecurity</td><td>Textual</td><td>String</td></tr><tr><th>11</th><td>OnlineBackup</td><td>Textual</td><td>String</td></tr><tr><th>12</th><td>DeviceProtection</td><td>Textual</td><td>String</td></tr><tr><th>13</th><td>TechSupport</td><td>Textual</td><td>String</td></tr><tr><th>14</th><td>StreamingTV</td><td>Textual</td><td>String</td></tr><tr><th>15</th><td>StreamingMovies</td><td>Textual</td><td>String</td></tr><tr><th>16</th><td>Contract</td><td>Textual</td><td>String</td></tr><tr><th>17</th><td>PaperlessBilling</td><td>Textual</td><td>String</td></tr><tr><th>18</th><td>PaymentMethod</td><td>Textual</td><td>String</td></tr><tr><th>19</th><td>MonthlyCharges</td><td>Continuous</td><td>Float64</td></tr><tr><th>20</th><td>TotalCharges</td><td>Textual</td><td>String</td></tr><tr><th>21</th><td>Churn</td><td>Textual</td><td>String</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& names & scitypes & types\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & DataType & DataType\\\\\n",
       "\t\\hline\n",
       "\t1 & customerID & Textual & String \\\\\n",
       "\t2 & gender & Textual & String \\\\\n",
       "\t3 & SeniorCitizen & Continuous & Float64 \\\\\n",
       "\t4 & Partner & Textual & String \\\\\n",
       "\t5 & Dependents & Textual & String \\\\\n",
       "\t6 & tenure & Continuous & Float64 \\\\\n",
       "\t7 & PhoneService & Textual & String \\\\\n",
       "\t8 & MultipleLines & Textual & String \\\\\n",
       "\t9 & InternetService & Textual & String \\\\\n",
       "\t10 & OnlineSecurity & Textual & String \\\\\n",
       "\t11 & OnlineBackup & Textual & String \\\\\n",
       "\t12 & DeviceProtection & Textual & String \\\\\n",
       "\t13 & TechSupport & Textual & String \\\\\n",
       "\t14 & StreamingTV & Textual & String \\\\\n",
       "\t15 & StreamingMovies & Textual & String \\\\\n",
       "\t16 & Contract & Textual & String \\\\\n",
       "\t17 & PaperlessBilling & Textual & String \\\\\n",
       "\t18 & PaymentMethod & Textual & String \\\\\n",
       "\t19 & MonthlyCharges & Continuous & Float64 \\\\\n",
       "\t20 & TotalCharges & Textual & String \\\\\n",
       "\t21 & Churn & Textual & String \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m21×3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m names            \u001b[0m\u001b[1m scitypes   \u001b[0m\u001b[1m types    \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Symbol           \u001b[0m\u001b[90m DataType   \u001b[0m\u001b[90m DataType \u001b[0m\n",
       "─────┼────────────────────────────────────────\n",
       "   1 │ customerID        Textual     String\n",
       "   2 │ gender            Textual     String\n",
       "   3 │ SeniorCitizen     Continuous  Float64\n",
       "   4 │ Partner           Textual     String\n",
       "   5 │ Dependents        Textual     String\n",
       "   6 │ tenure            Continuous  Float64\n",
       "   7 │ PhoneService      Textual     String\n",
       "   8 │ MultipleLines     Textual     String\n",
       "   9 │ InternetService   Textual     String\n",
       "  10 │ OnlineSecurity    Textual     String\n",
       "  11 │ OnlineBackup      Textual     String\n",
       "  12 │ DeviceProtection  Textual     String\n",
       "  13 │ TechSupport       Textual     String\n",
       "  14 │ StreamingTV       Textual     String\n",
       "  15 │ StreamingMovies   Textual     String\n",
       "  16 │ Contract          Textual     String\n",
       "  17 │ PaperlessBilling  Textual     String\n",
       "  18 │ PaymentMethod     Textual     String\n",
       "  19 │ MonthlyCharges    Continuous  Float64\n",
       "  20 │ TotalCharges      Textual     String\n",
       "  21 │ Churn             Textual     String"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema(df0) |> DataFrames.DataFrame  # converted to DataFrame for better display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the fields being interpreted as `Textual` are really\n",
    "something else, either `Multiclass` or, in the case of\n",
    "`:TotalCharges`, `Continuous`. In fact, `:TotalCharges` is\n",
    "mostly floats wrapped as strings. However, it needs special\n",
    "treatment because some elements consist of a single space, \" \",\n",
    "which we'll treat as \"0.0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_blanks(v) = map(v) do x\n",
    "    if x == \" \"\n",
    "        return \"0.0\"\n",
    "    else\n",
    "        return x\n",
    "    end\n",
    "end\n",
    "\n",
    "df0.TotalCharges = fix_blanks(df0.TotalCharges);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coercing the `:TotalCharges` type to ensure a `Continuous` scitype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "coerce!(df0, :TotalCharges => Continuous);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coercing all remaining `Textual` data to `Multiclass`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "coerce!(df0, Textual => Multiclass);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll coerce our target variable `:Churn` to be\n",
    "`OrderedFactor`, rather than `Multiclass`, to enable a reliable\n",
    "interpretation of metrics like \"true positive rate\".  By convention,\n",
    "the first class is the negative one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{String}:\n",
       " \"No\"\n",
       " \"Yes\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coerce!(df0, :Churn => OrderedFactor)\n",
    "levels(df0.Churn) # to check order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-inspecting the scitypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>21 rows × 3 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>names</th><th>scitypes</th><th>types</th></tr><tr><th></th><th title=\"Symbol\">Symbol</th><th title=\"DataType\">DataType</th><th title=\"DataType\">DataType</th></tr></thead><tbody><tr><th>1</th><td>customerID</td><td>Multiclass{7043}</td><td>CategoricalValue{String, UInt32}</td></tr><tr><th>2</th><td>gender</td><td>Multiclass{2}</td><td>CategoricalValue{String, UInt32}</td></tr><tr><th>3</th><td>SeniorCitizen</td><td>Continuous</td><td>Float64</td></tr><tr><th>4</th><td>Partner</td><td>Multiclass{2}</td><td>CategoricalValue{String, UInt32}</td></tr><tr><th>5</th><td>Dependents</td><td>Multiclass{2}</td><td>CategoricalValue{String, UInt32}</td></tr><tr><th>6</th><td>tenure</td><td>Continuous</td><td>Float64</td></tr><tr><th>7</th><td>PhoneService</td><td>Multiclass{2}</td><td>CategoricalValue{String, UInt32}</td></tr><tr><th>8</th><td>MultipleLines</td><td>Multiclass{3}</td><td>CategoricalValue{String, UInt32}</td></tr><tr><th>9</th><td>InternetService</td><td>Multiclass{3}</td><td>CategoricalValue{String, UInt32}</td></tr><tr><th>10</th><td>OnlineSecurity</td><td>Multiclass{3}</td><td>CategoricalValue{String, UInt32}</td></tr><tr><th>11</th><td>OnlineBackup</td><td>Multiclass{3}</td><td>CategoricalValue{String, UInt32}</td></tr><tr><th>12</th><td>DeviceProtection</td><td>Multiclass{3}</td><td>CategoricalValue{String, UInt32}</td></tr><tr><th>13</th><td>TechSupport</td><td>Multiclass{3}</td><td>CategoricalValue{String, UInt32}</td></tr><tr><th>14</th><td>StreamingTV</td><td>Multiclass{3}</td><td>CategoricalValue{String, UInt32}</td></tr><tr><th>15</th><td>StreamingMovies</td><td>Multiclass{3}</td><td>CategoricalValue{String, UInt32}</td></tr><tr><th>16</th><td>Contract</td><td>Multiclass{3}</td><td>CategoricalValue{String, UInt32}</td></tr><tr><th>17</th><td>PaperlessBilling</td><td>Multiclass{2}</td><td>CategoricalValue{String, UInt32}</td></tr><tr><th>18</th><td>PaymentMethod</td><td>Multiclass{4}</td><td>CategoricalValue{String, UInt32}</td></tr><tr><th>19</th><td>MonthlyCharges</td><td>Continuous</td><td>Float64</td></tr><tr><th>20</th><td>TotalCharges</td><td>Continuous</td><td>Float64</td></tr><tr><th>21</th><td>Churn</td><td>OrderedFactor{2}</td><td>CategoricalValue{String, UInt32}</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& names & scitypes & types\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & DataType & DataType\\\\\n",
       "\t\\hline\n",
       "\t1 & customerID & Multiclass\\{7043\\} & CategoricalValue\\{String, UInt32\\} \\\\\n",
       "\t2 & gender & Multiclass\\{2\\} & CategoricalValue\\{String, UInt32\\} \\\\\n",
       "\t3 & SeniorCitizen & Continuous & Float64 \\\\\n",
       "\t4 & Partner & Multiclass\\{2\\} & CategoricalValue\\{String, UInt32\\} \\\\\n",
       "\t5 & Dependents & Multiclass\\{2\\} & CategoricalValue\\{String, UInt32\\} \\\\\n",
       "\t6 & tenure & Continuous & Float64 \\\\\n",
       "\t7 & PhoneService & Multiclass\\{2\\} & CategoricalValue\\{String, UInt32\\} \\\\\n",
       "\t8 & MultipleLines & Multiclass\\{3\\} & CategoricalValue\\{String, UInt32\\} \\\\\n",
       "\t9 & InternetService & Multiclass\\{3\\} & CategoricalValue\\{String, UInt32\\} \\\\\n",
       "\t10 & OnlineSecurity & Multiclass\\{3\\} & CategoricalValue\\{String, UInt32\\} \\\\\n",
       "\t11 & OnlineBackup & Multiclass\\{3\\} & CategoricalValue\\{String, UInt32\\} \\\\\n",
       "\t12 & DeviceProtection & Multiclass\\{3\\} & CategoricalValue\\{String, UInt32\\} \\\\\n",
       "\t13 & TechSupport & Multiclass\\{3\\} & CategoricalValue\\{String, UInt32\\} \\\\\n",
       "\t14 & StreamingTV & Multiclass\\{3\\} & CategoricalValue\\{String, UInt32\\} \\\\\n",
       "\t15 & StreamingMovies & Multiclass\\{3\\} & CategoricalValue\\{String, UInt32\\} \\\\\n",
       "\t16 & Contract & Multiclass\\{3\\} & CategoricalValue\\{String, UInt32\\} \\\\\n",
       "\t17 & PaperlessBilling & Multiclass\\{2\\} & CategoricalValue\\{String, UInt32\\} \\\\\n",
       "\t18 & PaymentMethod & Multiclass\\{4\\} & CategoricalValue\\{String, UInt32\\} \\\\\n",
       "\t19 & MonthlyCharges & Continuous & Float64 \\\\\n",
       "\t20 & TotalCharges & Continuous & Float64 \\\\\n",
       "\t21 & Churn & OrderedFactor\\{2\\} & CategoricalValue\\{String, UInt32\\} \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m21×3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m names            \u001b[0m\u001b[1m scitypes         \u001b[0m\u001b[1m types                            \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Symbol           \u001b[0m\u001b[90m DataType         \u001b[0m\u001b[90m DataType                         \u001b[0m\n",
       "─────┼──────────────────────────────────────────────────────────────────────\n",
       "   1 │ customerID        Multiclass{7043}  CategoricalValue{String, UInt32}\n",
       "   2 │ gender            Multiclass{2}     CategoricalValue{String, UInt32}\n",
       "   3 │ SeniorCitizen     Continuous        Float64\n",
       "   4 │ Partner           Multiclass{2}     CategoricalValue{String, UInt32}\n",
       "   5 │ Dependents        Multiclass{2}     CategoricalValue{String, UInt32}\n",
       "   6 │ tenure            Continuous        Float64\n",
       "   7 │ PhoneService      Multiclass{2}     CategoricalValue{String, UInt32}\n",
       "   8 │ MultipleLines     Multiclass{3}     CategoricalValue{String, UInt32}\n",
       "   9 │ InternetService   Multiclass{3}     CategoricalValue{String, UInt32}\n",
       "  10 │ OnlineSecurity    Multiclass{3}     CategoricalValue{String, UInt32}\n",
       "  11 │ OnlineBackup      Multiclass{3}     CategoricalValue{String, UInt32}\n",
       "  12 │ DeviceProtection  Multiclass{3}     CategoricalValue{String, UInt32}\n",
       "  13 │ TechSupport       Multiclass{3}     CategoricalValue{String, UInt32}\n",
       "  14 │ StreamingTV       Multiclass{3}     CategoricalValue{String, UInt32}\n",
       "  15 │ StreamingMovies   Multiclass{3}     CategoricalValue{String, UInt32}\n",
       "  16 │ Contract          Multiclass{3}     CategoricalValue{String, UInt32}\n",
       "  17 │ PaperlessBilling  Multiclass{2}     CategoricalValue{String, UInt32}\n",
       "  18 │ PaymentMethod     Multiclass{4}     CategoricalValue{String, UInt32}\n",
       "  19 │ MonthlyCharges    Continuous        Float64\n",
       "  20 │ TotalCharges      Continuous        Float64\n",
       "  21 │ Churn             OrderedFactor{2}  CategoricalValue{String, UInt32}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema(df0) |> DataFrames.DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing a holdout set for final testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Introduces: `partition`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce training times for the purposes of this tutorial, we're\n",
    "going to dump 90% of observations (after shuffling) and split off\n",
    "30% of the remainder for use as a lock-and-throw-away-the-key\n",
    "holdout set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: df not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: df not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[23]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "df, df_test, df_dumped = partition(df0, 0.07, 0.003, # in ratios 7:3:90\n",
    "                                   stratified=df.Churn,\n",
    "                                   rng=123);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reader interested in including all data can instead do `df,\n",
    "df_test = partition(df0, 0.7, rng=123)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into target and features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Introduces: `unpack`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following call, the column with name `:Churn` is copied over\n",
    "to a vector `y`, and every remaining column, except `:customerID`\n",
    "(which contains no useful information) goes into a table `X`. Here\n",
    "`:Churn` is the target variable for which we seek predictions, given\n",
    "new versions of the features `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: df not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: df not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[24]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "const y, X = unpack(df, ==(:Churn), !=(:customerID));\n",
    "schema(X).names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: X not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: X not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[25]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "intersect([:Churn, :customerID], schema(X).names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do the same for the holdout data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: df_test not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: df_test not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[26]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "const ytest, Xtest = unpack(df_test, ==(:Churn), !=(:customerID));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a model and checking type requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Introduces: `@load`, `input_scitype`, `target_scitype`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tools helping us to identify suitable models, see the [Model\n",
    "Search](https://alan-turing-institute.github.io/MLJ.jl/dev/model_search/#model_search)\n",
    "section of the manual. We will build a gradient tree-boosting model,\n",
    "a popular first choice for structured data like we have here. Model\n",
    "code is contained in a third-party package called\n",
    "[EvoTrees.jl](https://github.com/Evovest/EvoTrees.jl) which is\n",
    "loaded as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main /Users/anthony/.julia/packages/MLJModels/EhaRK/src/loading.jl:168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import EvoTrees"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling EvoTrees [f6006082-12f8-11e9-0c9c-0d5d367ab1e5]\n",
      "└ @ Base loading.jl:1342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ✔\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EvoTrees.EvoTreeClassifier"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Booster = @load EvoTreeClassifier pkg=EvoTrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that a *model* is just a container for some algorithm's\n",
    "hyper-parameters. Let's create a `Booster` with default values for\n",
    "the hyper-parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvoTreeClassifier(\n",
       "    loss = EvoTrees.Softmax(),\n",
       "    nrounds = 10,\n",
       "    λ = 0.0,\n",
       "    γ = 0.0,\n",
       "    η = 0.1,\n",
       "    max_depth = 5,\n",
       "    min_weight = 1.0,\n",
       "    rowsample = 1.0,\n",
       "    colsample = 1.0,\n",
       "    nbins = 64,\n",
       "    α = 0.5,\n",
       "    metric = :mlogloss,\n",
       "    rng = MersenneTwister(123),\n",
       "    device = \"cpu\")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booster = Booster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is appropriate for the kind of target variable we have because of\n",
    "the following passing test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: y not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: y not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[29]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "scitype(y) <: target_scitype(booster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, our features `X` cannot be directly used with `booster`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: X not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: X not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[30]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "scitype(X) <: input_scitype(booster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out, this is because `booster`, like the majority of MLJ\n",
    "supervised models, expects the features to be `Continuous`. (With\n",
    "some experience, this can be gleaned from `input_scitype(booster)`.)\n",
    "So we need feature encoding, discussed next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a model pipeline to incorporate feature encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Introduces: `ContinuousEncoder`, pipeline operator `|>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The built-in `ContinuousEncoder` model transforms an arbitrary table\n",
    "to a table whose features are all `Continuous` (dropping any fields\n",
    "it does not know how to encode). In particular, all `Multiclass`\n",
    "features are one-hot encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *pipeline* is a stand-alone model that internally combines one or\n",
    "more models in a linear (non-branching) pipeline. Here's a pipeline\n",
    "that adds the `ContinuousEncoder` as a pre-processor to the\n",
    "gradient tree-boosting model above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProbabilisticPipeline(\n",
       "    continuous_encoder = ContinuousEncoder(\n",
       "            drop_last = false,\n",
       "            one_hot_ordered_factors = false),\n",
       "    evo_tree_classifier = EvoTreeClassifier(\n",
       "            loss = EvoTrees.Softmax(),\n",
       "            nrounds = 10,\n",
       "            λ = 0.0,\n",
       "            γ = 0.0,\n",
       "            η = 0.1,\n",
       "            max_depth = 5,\n",
       "            min_weight = 1.0,\n",
       "            rowsample = 1.0,\n",
       "            colsample = 1.0,\n",
       "            nbins = 64,\n",
       "            α = 0.5,\n",
       "            metric = :mlogloss,\n",
       "            rng = MersenneTwister(123),\n",
       "            device = \"cpu\"),\n",
       "    cache = true)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = ContinuousEncoder() |> booster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the component models appear as hyper-parameters of\n",
    "`pipe`. Pipelines are an implementation of a more general [model\n",
    "composition](https://alan-turing-institute.github.io/MLJ.jl/dev/composing_models/#Composing-Models)\n",
    "interface provided by MLJ that advanced users may want to learn about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above display, we see that component model hyper-parameters\n",
    "are now *nested*, but they are still accessible (important in hyper-parameter\n",
    "optimization):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.evo_tree_classifier.max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the pipeline model's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Introduces: `measures` (function), **measures:** `brier_loss`, `auc`, `accuracy`;\n",
    "> `machine`, `fit!`, `predict`, `fitted_params`, `report`, `roc`, **resampling strategy** `StratifiedCV`, `evaluate`, `FeatureSelector`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without touching our test set `Xtest`, `ytest`, we will estimate the\n",
    "performance of our pipeline model, with default hyper-parameters, in\n",
    "two different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll do this \"by hand\" using the `fit!` and `predict`\n",
    "workflow illustrated for the iris data set above, using a\n",
    "holdout resampling strategy. At the same time we'll see how to\n",
    "generate a **confusion matrix**, **ROC curve**, and inspect\n",
    "**feature importances**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll apply the more typical and convenient `evaluate`\n",
    "workflow, but using `StratifiedCV` (stratified cross-validation)\n",
    "which is more informative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any case, we need to choose some measures (metrics) to quantify\n",
    "the performance of our model. For a complete list of measures, one\n",
    "does `measures()`. Or we also can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{NamedTuple{(:name, :instances, :human_name, :target_scitype, :supports_weights, :supports_class_weights, :prediction_type, :orientation, :reports_each_observation, :aggregation, :is_feature_dependent, :docstring, :distribution_type), T} where T<:Tuple}:\n",
       " (name = BrierLoss, instances = [brier_loss], ...)\n",
       " (name = BrierScore, instances = [brier_score], ...)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measures(\"Brier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be primarily using `brier_loss`, but also `auc` (area under\n",
    "the ROC curve) and `accuracy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating by hand (with a holdout set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our pipeline model can be trained just like the decision tree model\n",
    "we built for the iris data set. Binding all non-test data to the\n",
    "pipeline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: X not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: X not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[34]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "mach_pipe = machine(pipe, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already encountered the `partition` method above. Here we apply\n",
    "it to row indices, instead of data containers, as `fit!` and\n",
    "`predict` only need a *view* of the data to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: y not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: y not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[35]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "train, validation = partition(1:length(y), 0.7)\n",
    "fit!(mach_pipe, rows=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note in passing that we can access two kinds of information from a trained machine:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The **learned parameters** (eg, coefficients of a linear model): We use `fitted_params(mach)`\n",
    "- Other **by-products of training** (eg, feature importances): We use `report(mach)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: mach_pipe not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: mach_pipe not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[36]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "fp = fitted_params(mach_pipe);\n",
    "keys(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can check that the encoder did not actually drop any features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: fp not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: fp not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[37]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "Set(fp.continuous_encoder.features_to_keep) == Set(schema(X).names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, from the report, extract feature importances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: mach_pipe not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: mach_pipe not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[38]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "rpt = report(mach_pipe)\n",
    "keys(rpt.evo_tree_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: rpt not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: rpt not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[39]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "fi = rpt.evo_tree_classifier.feature_importances\n",
    "feature_importance_table =\n",
    "    (feature=Symbol.(first.(fi)), importance=last.(fi)) |> DataFrames.DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For models not reporting feature importances, we recommend the\n",
    "[Shapley.jl](https://expandingman.gitlab.io/Shapley.jl/) package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returning to predictions and evaluations of our measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: validation not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: validation not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[40]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "ŷ = predict(mach_pipe, rows=validation);\n",
    "@info(\"Measurements\",\n",
    "      brier_loss(ŷ, y[validation]) |> mean,\n",
    "      auc(ŷ, y[validation]),\n",
    "      accuracy(mode.(ŷ), y[validation])\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we need `mode` in the last case because `accuracy` expects\n",
    "point predictions, not probabilistic ones. (One can alternatively\n",
    "use `predict_mode` to generate the predictions.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we're here, lets also generate a **confusion matrix** and\n",
    "[receiver-operator\n",
    "characteristic](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)\n",
    "(ROC):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: ŷ not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: ŷ not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[41]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "confmat(mode.(ŷ), y[validation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Importing the plotting package and calling the plotting\n",
    "functions for the first time can take a minute or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80]\n",
      "└ @ Base loading.jl:1342\n"
     ]
    }
   ],
   "source": [
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: y not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: y not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[43]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "roc_curve = roc(ŷ, y[validation])\n",
    "plt = scatter(roc_curve, legend=false)\n",
    "plot!(plt, xlab=\"false positive rate\", ylab=\"true positive rate\")\n",
    "plot!([0, 1], [0, 1], linewidth=2, linestyle=:dash, color=:black)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated performance evaluation (more typical workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get performance estimates with a single call to the\n",
    "`evaluate` function, which also allows for more complicated\n",
    "resampling - in this case stratified cross-validation. To make this\n",
    "more comprehensive, we set `repeats=3` below to make our\n",
    "cross-validation \"Monte Carlo\" (3 random size-6 partitions of the\n",
    "observation space, for a total of 18 folds) and set\n",
    "`acceleration=CPUThreads()` to parallelize the computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose a `StratifiedCV` resampling strategy; the complete list of options is\n",
    "[here](https://alan-turing-institute.github.io/MLJ.jl/dev/evaluating_model_performance/#Built-in-resampling-strategies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: X not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: X not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[44]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "e_pipe = evaluate(pipe, X, y,\n",
    "                  resampling=StratifiedCV(nfolds=6, rng=123),\n",
    "                  measures=[brier_loss, auc, accuracy],\n",
    "                  repeats=3,\n",
    "                  acceleration=CPUThreads())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(There is also a version of `evaluate` for machines. Query the\n",
    "`evaluate` and `evaluate!` doc-strings to learn more about these\n",
    "functions and what the `PerformanceEvaluation` object `e_pipe` records.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While [less than ideal](https://arxiv.org/abs/2104.00673), let's\n",
    "adopt the common practice of using the standard error of a\n",
    "cross-validation score as an estimate of the uncertainty of a\n",
    "performance measure's expected value. Here's a utility function to\n",
    "calculate confidence intervals for our performance estimates based\n",
    "on this practice, and it's application to the current evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: e_pipe not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: e_pipe not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[46]:10",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "function confidence_intervals(e)\n",
    "    measure = e.measure\n",
    "    nfolds = length(measure)\n",
    "    measurement = [e.measurement[j] ± std(e.per_fold[j])/sqrt(nfolds - 1)\n",
    "                   for j in eachindex(measure)]\n",
    "    table = (measure=measure, measurement=measurement)\n",
    "    return DataFrames.DataFrame(table)\n",
    "end\n",
    "\n",
    "const confidence_intervals_basic_model = confidence_intervals(e_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering out unimportant features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Introduces: `FeatureSelector`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing, we'll modify our pipeline to drop those features\n",
    "with low feature importance, to speed up later optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: feature_importance_table not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: feature_importance_table not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[47]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "unimportant_features = filter(:importance => <(0.005), feature_importance_table).feature\n",
    "\n",
    "pipe2 = ContinuousEncoder() |>\n",
    "    FeatureSelector(features=unimportant_features, ignore=true) |> booster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reader can check this change makes negligible difference to the\n",
    "model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping our model in control strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Introduces: **control strategies:** `Step`, `NumberSinceBest`, `TimeLimit`, `InvalidValue`, **model wrapper** `IteratedModel`, **resampling strategy:** `Holdout`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to optimize the hyper-parameters of our model. Since our\n",
    "model is iterative, these parameters include the (nested) iteration\n",
    "parameter `pipe.evo_tree_classifier.nrounds`. Sometimes this\n",
    "parameter is optimized first, fixed, and then maybe optimized again\n",
    "after the other parameters. Here we take a more principled approach,\n",
    "**wrapping our model in a control strategy** that makes it\n",
    "\"self-iterating\". The strategy applies a stopping criterion to\n",
    "*out-of-sample* estimates of the model performance, constructed\n",
    "using an internally constructed holdout set. In this way, we avoid\n",
    "some data hygiene issues, and, when we subsequently optimize other\n",
    "parameters, we will always being using an optimal number of\n",
    "iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this approach can be applied to any iterative MLJ model,\n",
    "eg, the neural network models provided by\n",
    "[MLJFlux.jl](https://github.com/FluxML/MLJFlux.jl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we select appropriate controls from [this\n",
    "list](https://alan-turing-institute.github.io/MLJ.jl/dev/controlling_iterative_models/#Controls-provided):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Any}:\n",
       " Step(1)\n",
       " NumberSinceBest(6)\n",
       " TimeLimit(Dates.Millisecond(30000))\n",
       " InvalidValue()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controls = [\n",
    "    Step(1),              # increment to iteration parameter (`pipe.nrounds`)\n",
    "    NumberSinceBest(n=6), # main stopping criterion\n",
    "    TimeLimit(0.5/60),    # never train longer than half a minute\n",
    "    InvalidValue()        # stop if NaN or ±Inf encountered\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we wrap our pipeline model using the `IteratedModel` wrapper,\n",
    "being sure to specify the `measure` on which internal estimates of\n",
    "the out-of-sample performance will be based:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: pipe2 not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: pipe2 not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[49]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "iterated_pipe = IteratedModel(model=pipe2,\n",
    "                              controls=controls,\n",
    "                              measure=brier_loss, # or BrierLoss()\n",
    "                              resampling=Holdout(fraction_train=0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've set `resampling=Holdout(fraction_train=0.7)` to arrange that\n",
    "data attached to our model should be internally split into a train\n",
    "set (70%) and a holdout set (30%) for determining the out-of-sample\n",
    "estimate of the Brier loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, let's bind `iterated_model` to all data\n",
    "not in our don't-touch holdout set, and train on all of that data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: iterated_pipe not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: iterated_pipe not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[50]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "mach_iterated_pipe = machine(iterated_pipe, X, y)\n",
    "fit!(mach_iterated_pipe, force=true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that internally this training is split into two separate steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A controlled iteration step, training on the holdout set, with the total number of iterations determined by the specified stopping criteria (based on the out-of-sample performance estimates)\n",
    "- A final step that trains the atomic model on *all* available\n",
    "  data using the number of iterations determined in the first step. Calling `predict` on the `mach` means using the learned parameters of the second step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter optimization (model tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Introduces: `range`, **model wrapper** `TunedModel`, `RandomSearch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now turn to hyper-parameter optimization. A tool not discussed\n",
    "here is the `learning_curve` function, which can be useful when\n",
    "wanting to visualize the effect of changes to a *single*\n",
    "hyper-parameter (which could be an iteration parameter). See, for\n",
    "example, [this section of the\n",
    "manual](https://alan-turing-institute.github.io/MLJ.jl/dev/learning_curves/)\n",
    "or [this\n",
    "tutorial](https://github.com/ablaom/MLJTutorial.jl/blob/dev/notebooks/04_tuning/notebook.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning the hyper-parameters of a gradient booster can be\n",
    "somewhat involved. Here we settle for simultaneously optimizing two\n",
    "key parameters: `max_depth` and `η` (learning_rate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like iteration control, **model optimization in MLJ is implemented as\n",
    "a model wrapper**, called `TunedModel`. After wrapping a model in a\n",
    "tuning strategy and binding the wrapped model to data in a machine\n",
    "called `mach`, calling `fit!(mach)` instigates a search for optimal\n",
    "model hyperparameters, within a specified range, and then uses all\n",
    "supplied data to train the best model. To predict using that model,\n",
    "one then calls `predict(mach, Xnew)`. In this way the wrapped model\n",
    "may be viewed as a \"self-tuning\" version of the unwrapped\n",
    "model. That is, wrapping the model simply transforms certain\n",
    "hyper-parameters into learned parameters (just as `IteratedModel`\n",
    "does for an iteration parameter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with, we define ranges for the parameters of\n",
    "interest. Since these parameters are nested, let's force a\n",
    "display of our model to a larger depth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: iterated_pipe not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: iterated_pipe not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[51]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "show(iterated_pipe, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: iterated_pipe not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: iterated_pipe not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[52]:4",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "p1 = :(model.evo_tree_classifier.η)\n",
    "p2 = :(model.evo_tree_classifier.max_depth)\n",
    "\n",
    "r1 = range(iterated_pipe, p1, lower=-3, upper=-2, scale=x->10^x)\n",
    "r2 = range(iterated_pipe, p2, lower=2, upper=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nominal ranges are defined by specifying `values` instead of `lower`\n",
    "and `upper`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we choose an optimization strategy from [this\n",
    "list](https://alan-turing-institute.github.io/MLJ.jl/dev/tuning_models/#Tuning-Models):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomSearch(\n",
       "    bounded = Distributions.Uniform,\n",
       "    positive_unbounded = Distributions.Gamma,\n",
       "    other = Distributions.Normal,\n",
       "    rng = MersenneTwister(123))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning = RandomSearch(rng=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we wrap the model, specifying a `resampling` strategy and a\n",
    "`measure`, as we did for `IteratedModel`.  In fact, we can include a\n",
    "battery of `measures`; by default, optimization is with respect to\n",
    "performance estimates based on the first measure, but estimates for\n",
    "all measures can be accessed from the model's `report`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keyword `n` specifies the total number of models (sets of\n",
    "hyper-parameters) to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: r1 not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: r1 not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[54]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "tuned_iterated_pipe = TunedModel(model=iterated_pipe,\n",
    "                                 range=[r1, r2],\n",
    "                                 tuning=tuning,\n",
    "                                 measures=[brier_loss, auc, accuracy],\n",
    "                                 resampling=StratifiedCV(nfolds=6, rng=123),\n",
    "                                 acceleration=CPUThreads(),\n",
    "                                 n=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save time, we skip the `repeats` here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binding our final model to data and training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: tuned_iterated_pipe not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: tuned_iterated_pipe not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[55]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "mach_tuned_iterated_pipe = machine(tuned_iterated_pipe, X, y)\n",
    "fit!(mach_tuned_iterated_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained above, the training we have just performed was split\n",
    "internally into two separate steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A step to determine the parameter values that optimize the aggregated cross-validation scores\n",
    "- A final step that trains the optimal model on *all* available data. Future predictions `predict(mach, ...)` are based on this final training step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From `report(mach_tuned_iterated_pipe)` we can extract details about\n",
    "the optimization procedure. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: mach_tuned_iterated_pipe not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: mach_tuned_iterated_pipe not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[56]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "rpt2 = report(mach_tuned_iterated_pipe);\n",
    "best_booster = rpt2.best_model.model.evo_tree_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: best_booster not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: best_booster not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ logging.jl:341",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "@info \"Optimal hyper-parameters:\" best_booster.max_depth best_booster.η;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `confidence_intervals` function we defined earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: rpt2 not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: rpt2 not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[58]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "e_best = rpt2.best_history_entry\n",
    "confidence_intervals(e_best) |> DataFrames.DataFrame # for pretty printing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can visualize the optimization results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: mach_tuned_iterated_pipe not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: mach_tuned_iterated_pipe not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[59]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "plot(mach_tuned_iterated_pipe, size=(600,450))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Introduces: `MLJ.save`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to serialize our final, trained self-iterating,\n",
    "self-tuning pipeline machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: mach_tuned_iterated_pipe not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: mach_tuned_iterated_pipe not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[60]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "MLJ.save(\"tuned_iterated_pipe.jlso\", mach_tuned_iterated_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll deserialize this in \"Testing the final model\" below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final performance estimate;;;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to get an even more accurate estimate of performance, we\n",
    "can evaluate our model using stratified cross-validation and all the\n",
    "data attached to our machine. Because this evaluation implies\n",
    "[nested\n",
    "resampling](https://mlr.mlr-org.com/articles/tutorial/nested_resampling.html),\n",
    "this computation takes quite a bit longer than the previous one\n",
    "(which is being repeated six times, using 5/6th of the data each\n",
    "time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: tuned_iterated_pipe not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: tuned_iterated_pipe not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[61]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "e_tuned_iterated_pipe = evaluate(tuned_iterated_pipe, X, y,\n",
    "                                 resampling=StratifiedCV(nfolds=6, rng=123),\n",
    "                                 measures=[brier_loss, auc, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: e_tuned_iterated_pipe not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: e_tuned_iterated_pipe not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[62]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "confidence_intervals(e_tuned_iterated_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, here are the confidence intervals for the basic\n",
    "pipeline model (no feature selection and default hyperparameters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: confidence_intervals_basic_model not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: confidence_intervals_basic_model not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ :0",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "confidence_intervals_basic_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see a small improvement in the `brier_score` and `auc`, but\n",
    "these are not statistically significant improvements; default\n",
    "`booster` hyper-parameters do a pretty good job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now determine the performance of our model on our\n",
    "lock-and-throw-away-the-key holdout set. To demonstrate\n",
    "deserialization, we'll pretend we're in a new Julia session (but\n",
    "have and called `import`/`using` on the same packages). Then the\n",
    "following should suffice to recover our model trained under\n",
    "\"Hyper-parameter optimization\" above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Machine{ProbabilisticTunedModel{RandomSearch,…},…} trained 1 time; caches data\n",
       "  model: MLJTuning.ProbabilisticTunedModel{RandomSearch, MLJIteration.ProbabilisticIteratedModel{MLJBase.ProbabilisticPipeline{NamedTuple{(:continuous_encoder, :feature_selector, :evo_tree_classifier), Tuple{Unsupervised, Unsupervised, Probabilistic}}, MLJModelInterface.predict}}}\n",
       "  args: \n"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mach_restored = machine(\"tuned_iterated_pipe.jlso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute predictions on the holdout set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: Xtest not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: Xtest not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[65]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "ŷ_tuned = predict(mach_restored, Xtest);\n",
    "ŷ_tuned[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And can compute the final performance measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: ŷ_tuned not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: ŷ_tuned not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ logging.jl:341",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "@info(\"Tuned model measurements on test:\",\n",
    "      brier_loss(ŷ_tuned, ytest) |> mean,\n",
    "      auc(ŷ_tuned, ytest),\n",
    "      accuracy(mode.(ŷ_tuned), ytest)\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, here's the performance for the basic pipeline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: X not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: X not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[67]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "mach_basic = machine(pipe, X, y)\n",
    "fit!(mach_basic, verbosity=0)\n",
    "\n",
    "ŷ_basic = predict(mach_basic, Xtest);\n",
    "\n",
    "@info(\"Basic model measurements on test set:\",\n",
    "      brier_loss(ŷ_basic, ytest) |> mean,\n",
    "      auc(ŷ_basic, ytest),\n",
    "      accuracy(mode.(ŷ_basic), ytest)\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.5",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 3
}
