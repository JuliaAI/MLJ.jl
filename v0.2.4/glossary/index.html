<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Glossary · MLJ</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>MLJ</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Getting Started</a></li><li><a class="toctext" href="../working_with_tasks/">Working with Tasks</a></li><li><a class="toctext" href="../built_in_transformers/">Built-in Transformers</a></li><li><a class="toctext" href="../learning_networks/">Learning Networks</a></li><li><a class="toctext" href="../simple_user_defined_models/">Simple User Defined Models</a></li><li><a class="toctext" href="../adding_models_for_general_use/">Adding Models for General Use</a></li><li><a class="toctext" href="../internals/">Internals</a></li><li class="current"><a class="toctext" href>Glossary</a><ul class="internal"></ul></li><li><a class="toctext" href="../api/">API</a></li><li><a class="toctext" href="../frequently_asked_questions/">FAQ</a></li><li><a class="toctext" href="../NEWS/">MLJ News</a></li><li><a class="toctext" href="../julia_blogpost/">Julia BlogPost</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Glossary</a></li></ul><a class="edit-page" href="https://github.com/alan-turing-institute/MLJ.jl/blob/master/docs/src/glossary.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Glossary</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Glossary-1" href="#Glossary-1">Glossary</a></h1><p>Note: This glossary includes some detail intended mainly for MLJ developers.</p><h3><a class="nav-anchor" id="Basics-1" href="#Basics-1">Basics</a></h3><h4><a class="nav-anchor" id="task-(object-of-type-Task)-1" href="#task-(object-of-type-Task)-1">task (object of type <code>Task</code>)</a></h4><p>Data plus a learning objective (e.g., &quot;probabilistic prediction of Sales&quot;). In MLJ a task does not include a description of how the completed task is to be evaluated.</p><h4><a class="nav-anchor" id="hyperparameters-1" href="#hyperparameters-1">hyperparameters</a></h4><p>Parameters on which some learning algorithm depends, specified before the algorithm is applied, and where learning is interpreted in the broadest sense. For example, PCA feature reduction is a &quot;preprocessing&quot; transformation &quot;learning&quot; a projection from training data, governed by a dimension hyperparameter. Hyperparameters in our sense may specify configuration (eg, number of parallel processes) even when this does not effect the end-product of learning. (But we exlcude verbosity level.)</p><h4><a class="nav-anchor" id="model-(object-of-abstract-type-Model)-1" href="#model-(object-of-abstract-type-Model)-1">model (object of abstract type <code>Model</code>)</a></h4><p>Object collecting together hyperameters of a single algorithm. Most models are classified either as <em>supervised</em> or <em>unsupervised</em> models (generally, &quot;transformers&quot;).</p><h4><a class="nav-anchor" id="fit-result-(type-generally-defined-outside-of-MLJ)-1" href="#fit-result-(type-generally-defined-outside-of-MLJ)-1">fit-result (type generally defined outside of MLJ)</a></h4><p>Also known as &quot;learned&quot; or &quot;fitted&quot; parameters, these are &quot;weights&quot;, &quot;coefficients&quot;, or similar paramaters learned by an algorithm, after adopting the prescribed hyperparameters. For example, decision trees of a random forest, the coefficients and intercept of a linear model, or the rotation and projection matrices of PCA reduction scheme.</p><h4><a class="nav-anchor" id="operation-1" href="#operation-1">operation</a></h4><p>Data-manipulating operations (methods) parameterized by some fit-result. For supervised learners, the <code>predict</code>, <code>predict_mean</code>, <code>predict_median</code>, or <code>predict_mode</code> methods; for transformers, the <code>transform</code> or <code>inverse_transform</code> method. In some contexts, such an operation might be replaced by an ordinary operation (method) that does <em>not</em> depend on an fit-result, which are then then called <em>static</em> operations for clarity. An operation that is not static is <em>dynamic</em>.</p><h4><a class="nav-anchor" id="machine-(object-of-type-Machine)-1" href="#machine-(object-of-type-Machine)-1">machine (object of type <code>Machine</code>)</a></h4><p>An object consisting of:</p><p>(1) A model </p><p>(2) A fit-result (undefined until training)</p><p>(3) <em>Training arguments</em> (one for each data argument of the model&#39;s associated <code>fit</code> method). A training argument is data used for training. Generally, there are two training arguments for supervised models, and just one for unsuperivsed models.</p><p>In addition machines store &quot;report&quot; metadata, for recording algorithm-specific statistics of training (eg, internal estimate of generalization error, feature importances); and they cache information allowing the fit-result to be updated without repeating unnecessary information.</p><p>Trainable models are trained by calls to a <code>fit</code> method which may be passed an optional argument specifying the rows of data to be used in training.</p><h3><a class="nav-anchor" id="Learning-Networks-and-Composite-Models-1" href="#Learning-Networks-and-Composite-Models-1">Learning Networks and Composite Models</a></h3><p><em>Note:</em> Multiple nodal machines may share the same model, and multiple learning nodes may share the same nodal machine.</p><h4><a class="nav-anchor" id="source-node-(object-of-type-Source)-1" href="#source-node-(object-of-type-Source)-1">source node (object of type <code>Source</code>)</a></h4><p>A container for training data and point of entry for new data in a learning network (see below).</p><h4><a class="nav-anchor" id="nodal-machine-(object-of-type-NodalMachine)-1" href="#nodal-machine-(object-of-type-NodalMachine)-1">nodal machine (object of type <code>NodalMachine</code>)</a></h4><p>Like a machine with the following exceptions:</p><p>(1) Training arguments are source nodes or regular nodes (see below) in the learning network, instead of data.</p><p>(2) The object internally records dependencies on other other nodal machines, as implied by the training arguments, and so on. </p><h4><a class="nav-anchor" id="node-(object-of-type-Node)-1" href="#node-(object-of-type-Node)-1">node (object of type <code>Node</code>)</a></h4><p>Essentially a nodal machine wrapped in an associated operation (e.g., <code>predict</code> or <code>inverse_transform</code>). It detail, it consists of:</p><p>(1) An operation, static or dynamic.</p><p>(2) A nodal machine, void if the operation is static.</p><p>(3) Upstream connections to other learning or source nodes, specified by a list    of <em>arguments</em> (one for each argument of the operation).</p><p>(4) Metadata recording the dependencies of the object&#39;s machine, and the dependecies on other nodal machines implied by its arguments.</p><h4><a class="nav-anchor" id="learning-network-1" href="#learning-network-1">learning network</a></h4><p>An acyclic directed graph implicit in the connections of a collection of source(s) and nodes. Each connected component is ordinarily restricted to have a unique source.</p><h4><a class="nav-anchor" id="wrapper-1" href="#wrapper-1">wrapper</a></h4><p>Any model with one or more other models as hyperparameters.</p><h4><a class="nav-anchor" id="composite-model-1" href="#composite-model-1">composite model</a></h4><p>Any wrapper, or any learning network &quot;exported&quot; as a model (see <a href="../learning_networks/">Learning Networks</a>).</p><footer><hr/><a class="previous" href="../internals/"><span class="direction">Previous</span><span class="title">Internals</span></a><a class="next" href="../api/"><span class="direction">Next</span><span class="title">API</span></a></footer></article></body></html>
