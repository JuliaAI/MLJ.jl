<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Introduction · MLJ</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href><img src="assets/logo.svg" alt="MLJ logo"/></a><div class="docs-package-name"><span class="docs-autofit">MLJ</span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Introduction</a><ul class="internal"><li><a class="tocitem" href="#Lightning-tour-1"><span>Lightning tour</span></a></li><li><a class="tocitem" href="#Key-goals-1"><span>Key goals</span></a></li><li><a class="tocitem" href="#Key-features-1"><span>Key features</span></a></li><li><a class="tocitem" href="#Model-composability-1"><span>Model composability</span></a></li><li><a class="tocitem" href="#Reporting-problems-1"><span>Reporting problems</span></a></li><li><a class="tocitem" href="#Installation-1"><span>Installation</span></a></li><li><a class="tocitem" href="#Learning-Julia-1"><span>Learning Julia</span></a></li><li><a class="tocitem" href="#Learning-to-use-MLJ-1"><span>Learning to use MLJ</span></a></li><li><a class="tocitem" href="#Citing-MLJ-1"><span>Citing MLJ</span></a></li></ul></li><li><a class="tocitem" href="getting_started/">Getting Started</a></li><li><a class="tocitem" href="common_mlj_workflows/">Common MLJ Workflows</a></li><li><a class="tocitem" href="working_with_categorical_data/">Working with Categorical Data</a></li><li><a class="tocitem" href="model_search/">Model Search</a></li><li><a class="tocitem" href="machines/">Machines</a></li><li><a class="tocitem" href="evaluating_model_performance/">Evaluating Model Performance</a></li><li><a class="tocitem" href="performance_measures/">Performance Measures</a></li><li><a class="tocitem" href="tuning_models/">Tuning Models</a></li><li><a class="tocitem" href="learning_curves/">Learning Curves</a></li><li><a class="tocitem" href="transformers/">Transformers and other unsupervised models</a></li><li><a class="tocitem" href="composing_models/">Composing Models</a></li><li><a class="tocitem" href="homogeneous_ensembles/">Homogeneous Ensembles</a></li><li><a class="tocitem" href="generating_synthetic_data/">Generating Synthetic Data</a></li><li><a class="tocitem" href="openml_integration/">OpenML Integration</a></li><li><a class="tocitem" href="simple_user_defined_models/">Simple User Defined Models</a></li><li><a class="tocitem" href="quick_start_guide_to_adding_models/">Quick-Start Guide to Adding Models</a></li><li><a class="tocitem" href="adding_models_for_general_use/">Adding Models for General Use</a></li><li><a class="tocitem" href="benchmarking/">Benchmarking</a></li><li><a class="tocitem" href="internals/">Internals</a></li><li><a class="tocitem" href="list_of_supported_models/">List of Supported Models</a></li><li><a class="tocitem" href="glossary/">Glossary</a></li><li><a class="tocitem" href="mlj_cheatsheet/">MLJ Cheatsheet</a></li><li><a class="tocitem" href="frequently_asked_questions/">FAQ</a></li><li><a class="tocitem" href="julia_blogpost/">Julia BlogPost</a></li><li><a class="tocitem" href="acceleration_and_parallelism/">Acceleration and Parallelism</a></li><li><a class="tocitem" href="api/">Index of Methods</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Introduction</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Introduction</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/alan-turing-institute/MLJ.jl/blob/master/docs/src/index.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><span style="color:darkslateblue;font-size:2.25em;font-style:italic;">
A Machine Learning Framework for Julia
</span>
<br>
<br>
<div style="font-size:1.25em;font-weight:bold;">
  <a href="#Installation-1">Installation</a>    &nbsp;|&nbsp;
  <a href="mlj_cheatsheet">Cheatsheet</a>       &nbsp;|&nbsp;
  <a href="common_mlj_workflows">Workflows</a>  &nbsp;|&nbsp;
  <a href="https://alan-turing-institute.github.io/DataScienceTutorials.jl/">Tutorials</a>       &nbsp;|&nbsp;
  <a href="https://github.com/alan-turing-institute/MLJ.jl/">For Developers</a> &nbsp;|&nbsp;
  <a href="https://mybinder.org/v2/gh/alan-turing-institute/MLJ.jl/master?filepath=binder%2FMLJ_demo.ipynb">Live Demo</a>
</div><h1 id="Introduction-1"><a class="docs-heading-anchor" href="#Introduction-1">Introduction</a><a class="docs-heading-anchor-permalink" href="#Introduction-1" title="Permalink"></a></h1><p>MLJ (Machine Learning in Julia) is a toolbox written in Julia providing a common interface and meta-algorithms for selecting, tuning, evaluating, composing and comparing over 140 machine learning models written in Julia and other languages. In particular MLJ wraps a large number of <a href="https://scikit-learn.org/stable/">scikit-learn</a> models.</p><p>MLJ is released under the MIT licensed and sponsored by the <a href="https://www.turing.ac.uk/">Alan Turing Institute</a>.</p><h2 id="Lightning-tour-1"><a class="docs-heading-anchor" href="#Lightning-tour-1">Lightning tour</a><a class="docs-heading-anchor-permalink" href="#Lightning-tour-1" title="Permalink"></a></h2><p><em>For a more elementary introduction to MLJ usage see <a href="getting_started/#Getting-Started-1">Getting Started</a>.</em></p><p>The first code snippet below creates a new Julia environment <code>MLJ_tour</code> and installs just those packages needed for the tour. See <a href="#Installation-1">Installation</a> for more on creating a Julia environment for use with MLJ.</p><p>Julia installation instructions are <a href="https://julialang.org/downloads/">here</a>.</p><pre><code class="language-julia">using Pkg
Pkg.activate(&quot;MLJ_tour&quot;, shared=true)
Pkg.add(&quot;MLJ&quot;)
Pkg.add(&quot;MLJModels&quot;)
Pkg.add(&quot;EvoTrees&quot;)</code></pre><p>Load a selection of features and labels from the Ames House Price dataset:</p><pre><code class="language-julia">using MLJ
X, y = @load_reduced_ames;</code></pre><p>Load and instantiate a gradient tree-boosting model:</p><pre><code class="language-julia">booster = @load EvoTreeRegressor
booster.max_depth = 2
booster.nrounds=50</code></pre><p>Combine the model with categorical feature encoding:</p><pre><code class="language-julia">pipe = @pipeline ContinuousEncoder booster</code></pre><p>Define a hyper-parameter range for optimization:</p><pre><code class="language-julia">max_depth_range = range(pipe,
                        :(evo_tree_regressor.max_depth),
                        lower = 1,
                        upper = 10)</code></pre><p>Wrap the pipeline model in an optimization strategy:</p><pre><code class="language-julia">self_tuning_pipe = TunedModel(model=pipe,
                              tuning=RandomSearch(),
                              ranges = max_depth_range,
                              resampling=CV(nfolds=3, rng=456),
                              measure=l1,
                              acceleration=CPUThreads(),
                              n=50)</code></pre><p>Bind the &quot;self-tuning&quot; pipeline model (just a container for hyper-parameters) to data in a <em>machine</em> (which will additionally store <em>learned</em> parameters):</p><pre><code class="language-julia">mach = machine(self_tuning_pipe, X, y)</code></pre><p>Evaluate the &quot;self-tuning&quot; pipeline model&#39;s performance (implies nested resampling):</p><pre><code class="language-julia">julia&gt; evaluate!(mach,
                measures=[l1, l2],
                resampling=CV(nfolds=6, rng=123),
                acceleration=CPUProcesses(), verbosity=2)
┌───────────┬───────────────┬────────────────────────────────────────────────────────┐
│ _.measure │ _.measurement │ _.per_fold                                             │
├───────────┼───────────────┼────────────────────────────────────────────────────────┤
│ l1        │ 16700.0       │ [16100.0, 16400.0, 14500.0, 17000.0, 16400.0, 19500.0] │
│ l2        │ 6.43e8        │ [5.88e8, 6.81e8, 4.35e8, 6.35e8, 5.98e8, 9.18e8]       │
└───────────┴───────────────┴────────────────────────────────────────────────────────┘
_.per_observation = [[[29100.0, 9990.0, ..., 103.0], [12100.0, 1330.0, ..., 13200.0], [6490.0, 22000.0, ..., 13800.0], [9090.0, 9530.0, ..., 13900.0], [50800.0, 22700.0, ..., 1550.0], [32800.0, 4940.0, ..., 1110.0]], [[8.45e8, 9.98e7, ..., 10500.0], [1.46e8, 1.77e6, ..., 1.73e8], [4.22e7, 4.86e8, ..., 1.9e8], [8.26e7, 9.09e7, ..., 1.93e8], [2.58e9, 5.13e8, ..., 2.42e6], [1.07e9, 2.44e7, ..., 1.24e6]]]
_.fitted_params_per_fold = [ … ]
_.report_per_fold = [ … ]
</code></pre><p>Try out MLJ yourself in the following batteries-included Binder <a href="https://mybinder.org/v2/gh/alan-turing-institute/MLJ.jl/master?filepath=binder%2FMLJ_demo.ipynb">notebook</a>. No installation required.</p><h2 id="Key-goals-1"><a class="docs-heading-anchor" href="#Key-goals-1">Key goals</a><a class="docs-heading-anchor-permalink" href="#Key-goals-1" title="Permalink"></a></h2><ul><li><p>Offer a consistent way to use, compose and tune machine learning models in Julia,</p></li><li><p>Promote the improvement of the Julia ML/Stats ecosystem by making it easier to use models from a wide range of packages,</p></li><li><p>Unlock performance gains by exploiting Julia&#39;s support for parallelism, automatic differentiation, GPU, optimisation etc.</p></li></ul><h2 id="Key-features-1"><a class="docs-heading-anchor" href="#Key-features-1">Key features</a><a class="docs-heading-anchor-permalink" href="#Key-features-1" title="Permalink"></a></h2><ul><li><p>Data agnostic, train models on any data supported by the <a href="https://github.com/JuliaData/Tables.jl">Tables.jl</a> interface,</p></li><li><p>Extensive, state-of-the art, support for model composition (<em>pipelines</em> and <em>learning networks</em>) (see more <a href="#model-composability">below</a>),</p></li><li><p>Convenient syntax to tune and evaluate (composite) models.</p></li><li><p>Consistent interface to handle probabilistic predictions.</p></li><li><p>Extensible <a href="https://github.com/alan-turing-institute/MLJTuning.jl">tuning interface</a>, to support growing number of optimization strategies, and designed to play well with model composition.</p></li></ul><h2 id="Model-composability-1"><a class="docs-heading-anchor" href="#Model-composability-1">Model composability</a><a class="docs-heading-anchor-permalink" href="#Model-composability-1" title="Permalink"></a></h2><p>The generic model composition API&#39;s provided by other toolboxes we have surveyed share one or more of the following shortcomings, which do not exist in MLJ:</p><ul><li><p>Composite models do not inherit all the behavior of ordinary models.</p></li><li><p>Composition is limited to linear (non-branching) pipelines.</p></li><li><p>Supervised components in a linear pipeline can only occur at the end of the pipeline.</p></li><li><p>Only static (unlearned) target transformations/inverse transformations are supported.</p></li><li><p>Hyper-parameters in homogeneous model ensembles cannot be coupled.</p></li><li><p>Model stacking, with out-of-sample predictions for base learners, cannot be implemented (using the generic API alone).</p></li><li><p>Hyper-parameters and/or learned parameters of component models are not easily inspected or manipulated (by tuning algorithms, for example)</p></li><li><p>Composite models cannot implement multiple opertations, for example, both a <code>predict</code> and <code>transform</code> method (as in clustering models) or both a <code>transform</code> and <code>inverse_transform</code> method.</p></li></ul><p>Some of these features are demonstrated in <a href="https://github.com/ablaom/MachineLearningInJulia2020/blob/master/wow.ipynb">this notebook</a></p><p>For more information see the <a href="https://github.com/alan-turing-institute/MLJ.jl/blob/master/paper/paper.md">MLJ design paper</a></p><h2 id="Reporting-problems-1"><a class="docs-heading-anchor" href="#Reporting-problems-1">Reporting problems</a><a class="docs-heading-anchor-permalink" href="#Reporting-problems-1" title="Permalink"></a></h2><p>Users are encouraged to provide feedback on their experience using MLJ and to report issues. You can do so <a href="https://github.com/alan-turing-institute/MLJ.jl/issues">here</a> or on the <code>#mlj</code> Julia slack channel.</p><p>For known issues that are not strictly MLJ bugs, see <a href="https://github.com/alan-turing-institute/MLJ.jl#known-issues">here</a></p><h2 id="Installation-1"><a class="docs-heading-anchor" href="#Installation-1">Installation</a><a class="docs-heading-anchor-permalink" href="#Installation-1" title="Permalink"></a></h2><p>Initially it is recommended that MLJ and associated packages be installed in a new <a href="https://julialang.github.io/Pkg.jl/v1/environments/">environment</a> to avoid package conflicts. You can do this with</p><pre><code class="language-julia">julia&gt; using Pkg; Pkg.activate(&quot;my_MLJ_env&quot;, shared=true)</code></pre><p>Installing MLJ is also done with the package manager:</p><pre><code class="language-julia">julia&gt; Pkg.add(&quot;MLJ&quot;)</code></pre><p><strong>Optional:</strong> To test your installation, run</p><pre><code class="language-julia">julia&gt; Pkg.test(&quot;MLJ&quot;)</code></pre><p>It is important to note that MLJ is essentially a big wrapper providing a unified access to <em>model providing packages</em> and so you will also need to make sure these packages are available in your environment.  For instance, if you want to use a <strong>Decision Tree Classifier</strong>, you need to have <a href="https://github.com/bensadeghi/DecisionTree.jl">DecisionTree.jl</a> installed:</p><pre><code class="language-julia">julia&gt; Pkg.add(&quot;DecisionTree&quot;);
julia&gt; using MLJ;
julia&gt; @load DecisionTreeClassifier</code></pre><p>For a list of models and their packages run</p><pre><code class="language-julia">using MLJ
models()</code></pre><p>or refer to <a href="list_of_supported_models/#List-of-Supported-Models-1">List of Supported Models</a></p><p>It is recommended that you start with models marked as coming from mature packages such as DecisionTree.jl, ScikitLearn.jl or XGBoost.jl.</p><p>MLJ is supported by a number of satelite packages (MLJTuning, MLJModelInterface, etc) which the general user is <em>not</em> required to install directly. Developers can learn more about these <a href="https://github.com/alan-turing-institute/MLJ.jl/blob/master/ORGANIZATION.md">here</a></p><h2 id="Learning-Julia-1"><a class="docs-heading-anchor" href="#Learning-Julia-1">Learning Julia</a><a class="docs-heading-anchor-permalink" href="#Learning-Julia-1" title="Permalink"></a></h2><p>If you have experience in programming in another language but are new to Julia, then we highly recommend Aaron Christinson&#39;s tutorial <a href="https://github.com/ninjaaron/dispatching-design-patterns">Dispatching Design Patterns</a> which is nicely compressed in his <a href="https://live.juliacon.org/talk/JYNERU">half-hour video presentation</a>.</p><p>However, one doesn&#39;t need to be able to program in Julia to start using MLJ.</p><h2 id="Learning-to-use-MLJ-1"><a class="docs-heading-anchor" href="#Learning-to-use-MLJ-1">Learning to use MLJ</a><a class="docs-heading-anchor-permalink" href="#Learning-to-use-MLJ-1" title="Permalink"></a></h2><p>The present document, although littered with examples, is primarily intended as a complete reference. For a short introduction to basic MLJ functionality, read the <a href="getting_started/#Getting-Started-1">Getting Started</a> section of this manual. For extensive tutorials, we recommend the <a href="https://alan-turing-institute.github.io/DataScienceTutorials.jl/">MLJ Tutorials</a> website.  Each tutorial can be downloaded as a notebook or Julia script to facilitate experimentation. Finally, you may like to checkout the <a href="https://github.com/ablaom/MachineLearningInJulia2020">JuliaCon2020 Workshop</a> on MLJ (recorded <a href="https://www.youtube.com/watch?time_continue=27&amp;v=qSWbCn170HU&amp;feature=emb_title">here</a>).</p><p>You can try also MLJ out in the following <a href="https://mybinder.org/v2/gh/alan-turing-institute/MLJ.jl/master?filepath=binder%2FMLJ_demo.ipynb">notebook</a> on Binder, without installing Julia or MLJ.</p><p>Users are also welcome to join the <code>#mlj</code> Julia slack channel to ask questions and make suggestions.</p><h2 id="Citing-MLJ-1"><a class="docs-heading-anchor" href="#Citing-MLJ-1">Citing MLJ</a><a class="docs-heading-anchor-permalink" href="#Citing-MLJ-1" title="Permalink"></a></h2><p>When presenting work that uses MLJ, please cite the <a href="https://arxiv.org/abs/2007.12285">MLJ design paper</a>. Here is the relevant bibtex entry:</p><pre><code class="language-bitex">@misc{blaom2020mlj,
    title={MLJ: A Julia package for composable machine learning},
    author={Anthony D. Blaom and Franz Kiraly and Thibaut Lienart and Yiannis Simillides and Diego Arenas and Sebastian J. Vollmer},
    year={2020},
    eprint={2007.12285},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}</code></pre></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="getting_started/">Getting Started »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 12 October 2020 23:58">Monday 12 October 2020</span>. Using Julia version 1.2.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
