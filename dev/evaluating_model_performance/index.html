<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Evaluating Model Performance · MLJ</title><meta name="title" content="Evaluating Model Performance · MLJ"/><meta property="og:title" content="Evaluating Model Performance · MLJ"/><meta property="twitter:title" content="Evaluating Model Performance · MLJ"/><meta name="description" content="Documentation for MLJ."/><meta property="og:description" content="Documentation for MLJ."/><meta property="twitter:description" content="Documentation for MLJ."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,100;0,300;0,400;0,700;0,900;1,100;1,300;1,400;1,700;1,900&amp;family=Montserrat:ital,wght@0,100..900;1,100..900&amp;display=swap" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="MLJ logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">MLJ</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../model_browser/">Model Browser</a></li><li><a class="tocitem" href="../about_mlj/">About MLJ</a></li><li><a class="tocitem" href="../learning_mlj/">Learning MLJ</a></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">Basics</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../getting_started/">Getting Started</a></li><li><a class="tocitem" href="../common_mlj_workflows/">Common MLJ Workflows</a></li><li><a class="tocitem" href="../machines/">Machines</a></li><li><a class="tocitem" href="../mlj_cheatsheet/">MLJ Cheatsheet</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">Data</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../working_with_categorical_data/">Working with Categorical Data</a></li><li><a class="tocitem" href="../preparing_data/">Preparing Data</a></li><li><a class="tocitem" href="../generating_synthetic_data/">Generating Synthetic Data</a></li><li><a class="tocitem" href="../openml_integration/">OpenML Integration</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-7" type="checkbox"/><label class="tocitem" for="menuitem-7"><span class="docs-label">Model Basics</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../model_search/">Model Search</a></li><li><a class="tocitem" href="../loading_model_code/">Loading Model Code</a></li><li><a class="tocitem" href="../transformers/">Transformers and Other Unsupervised models</a></li><li><a class="tocitem" href="../list_of_supported_models/">List of Supported Models</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-8" type="checkbox" checked/><label class="tocitem" for="menuitem-8"><span class="docs-label">Meta-algorithms</span><i class="docs-chevron"></i></label><ul class="collapsed"><li class="is-active"><a class="tocitem" href>Evaluating Model Performance</a><ul class="internal"><li><a class="tocitem" href="#Evaluating-against-a-single-measure"><span>Evaluating against a single measure</span></a></li><li><a class="tocitem" href="#Multiple-measures"><span>Multiple measures</span></a></li><li><a class="tocitem" href="#Specifying-weights"><span>Specifying weights</span></a></li><li><a class="tocitem" href="#User-specified-train/test-sets"><span>User-specified train/test sets</span></a></li><li><a class="tocitem" href="#Built-in-resampling-strategies"><span>Built-in resampling strategies</span></a></li><li><a class="tocitem" href="#Custom-resampling-strategies"><span>Custom resampling strategies</span></a></li></ul></li><li><a class="tocitem" href="../tuning_models/">Tuning Models</a></li><li><a class="tocitem" href="../learning_curves/">Learning Curves</a></li><li><a class="tocitem" href="../controlling_iterative_models/">Controlling Iterative Models</a></li><li><a class="tocitem" href="../correcting_class_imbalance/">Correcting Class Imbalance</a></li><li><a class="tocitem" href="../thresholding_probabilistic_predictors/">Thresholding Probabilistic Predictors</a></li><li><a class="tocitem" href="../target_transformations/">Target Transformations</a></li><li><a class="tocitem" href="../homogeneous_ensembles/">Homogeneous Ensembles</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-9" type="checkbox"/><label class="tocitem" for="menuitem-9"><span class="docs-label">Model Composition</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../composing_models/">Composing Models</a></li><li><a class="tocitem" href="../linear_pipelines/">Linear Pipelines</a></li><li><a class="tocitem" href="../model_stacking/">Model Stacking</a></li><li><a class="tocitem" href="../learning_networks/">Learning Networks</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-10" type="checkbox"/><label class="tocitem" for="menuitem-10"><span class="docs-label">Third Party Tools</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../logging_workflows/">Logging Workflows using MLflow</a></li><li><a class="tocitem" href="../third_party_packages/">Third Party Packages</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-11" type="checkbox"/><label class="tocitem" for="menuitem-11"><span class="docs-label">Customization and Extension</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../simple_user_defined_models/">Simple User Defined Models</a></li><li><a class="tocitem" href="../quick_start_guide_to_adding_models/">Quick-Start Guide to Adding Models</a></li><li><a class="tocitem" href="../adding_models_for_general_use/">Adding Models for General Use</a></li><li><a class="tocitem" href="../modifying_behavior/">Modifying Behavior</a></li><li><a class="tocitem" href="../internals/">Internals</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-12" type="checkbox"/><label class="tocitem" for="menuitem-12"><span class="docs-label">Miscellaneous</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../performance_measures/">Performance Measures</a></li><li><a class="tocitem" href="../weights/">Weights</a></li><li><a class="tocitem" href="../acceleration_and_parallelism/">Acceleration and Parallelism</a></li><li><a class="tocitem" href="../glossary/">Glossary</a></li><li><a class="tocitem" href="../frequently_asked_questions/">FAQ</a></li></ul></li><li><a class="tocitem" href="../api/">Index of Methods</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Meta-algorithms</a></li><li class="is-active"><a href>Evaluating Model Performance</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Evaluating Model Performance</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaAI/MLJ.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaAI/MLJ.jl/blob/dev/docs/src/evaluating_model_performance.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Evaluating-Model-Performance"><a class="docs-heading-anchor" href="#Evaluating-Model-Performance">Evaluating Model Performance</a><a id="Evaluating-Model-Performance-1"></a><a class="docs-heading-anchor-permalink" href="#Evaluating-Model-Performance" title="Permalink"></a></h1><p>MLJ allows quick evaluation of a supervised model&#39;s performance against a battery of selected losses or scores. For more on available performance measures, see <a href="../performance_measures/">Performance Measures</a>.</p><p>In addition to hold-out and cross-validation, the user can specify an explicit list of train/test pairs of row indices for resampling, or define new resampling strategies.</p><p>For simultaneously evaluating <em>multiple</em> models, see <a href="@ref">Comparing models of different type and nested cross-validation</a>.</p><p>For externally logging the outcomes of performance evaluation experiments, see <a href="../logging_workflows/#Logging-Workflows">Logging Workflows</a></p><h2 id="Evaluating-against-a-single-measure"><a class="docs-heading-anchor" href="#Evaluating-against-a-single-measure">Evaluating against a single measure</a><a id="Evaluating-against-a-single-measure-1"></a><a class="docs-heading-anchor-permalink" href="#Evaluating-against-a-single-measure" title="Permalink"></a></h2><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; using MLJ</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; X = (a=rand(12), b=rand(12), c=rand(12));</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; y = X.a + 2X.b + 0.05*rand(12);</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; model = (@load RidgeRegressor pkg=MultivariateStats verbosity=0)()</code><code class="nohighlight hljs ansi" style="display:block;">RidgeRegressor(
  lambda = 1.0,
  bias = true)</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; cv = CV(nfolds=3)</code><code class="nohighlight hljs ansi" style="display:block;">CV(
  nfolds = 3,
  shuffle = false,
  rng = Random._GLOBAL_RNG())</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; evaluate(model, X, y, resampling=cv, measure=l2, verbosity=0)</code><code class="nohighlight hljs ansi" style="display:block;">PerformanceEvaluation object with these fields:
  model, measure, operation,
  measurement, per_fold, per_observation,
  fitted_params_per_fold, report_per_fold,
  train_test_rows, resampling, repeats
Extract:
┌──────────┬───────────┬─────────────┐
│ measure  │ operation │ measurement │
├──────────┼───────────┼─────────────┤
│ LPLoss(  │ predict   │ 0.184       │
│   p = 2) │           │             │
└──────────┴───────────┴─────────────┘
┌────────────────────────┬─────────┐
│ per_fold               │ 1.96*SE │
├────────────────────────┼─────────┤
│ [0.298, 0.163, 0.0892] │ 0.147   │
└────────────────────────┴─────────┘</code></pre><p>Alternatively, instead of applying <code>evaluate</code> to a model + data, one may call <code>evaluate!</code> on an existing machine wrapping the model in data:</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; mach = machine(model, X, y)</code><code class="nohighlight hljs ansi" style="display:block;">untrained Machine; caches model-specific representations of data
  model: RidgeRegressor(lambda = 1.0, …)
  args:
    1:	Source @420 ⏎ Table{AbstractVector{Continuous}}
    2:	Source @983 ⏎ AbstractVector{Continuous}</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; evaluate!(mach, resampling=cv, measure=l2, verbosity=0)</code><code class="nohighlight hljs ansi" style="display:block;">PerformanceEvaluation object with these fields:
  model, measure, operation,
  measurement, per_fold, per_observation,
  fitted_params_per_fold, report_per_fold,
  train_test_rows, resampling, repeats
Extract:
┌──────────┬───────────┬─────────────┐
│ measure  │ operation │ measurement │
├──────────┼───────────┼─────────────┤
│ LPLoss(  │ predict   │ 0.184       │
│   p = 2) │           │             │
└──────────┴───────────┴─────────────┘
┌────────────────────────┬─────────┐
│ per_fold               │ 1.96*SE │
├────────────────────────┼─────────┤
│ [0.298, 0.163, 0.0892] │ 0.147   │
└────────────────────────┴─────────┘</code></pre><p>(The latter call is a mutating call as the learned parameters stored in the machine potentially change. )</p><h2 id="Multiple-measures"><a class="docs-heading-anchor" href="#Multiple-measures">Multiple measures</a><a id="Multiple-measures-1"></a><a class="docs-heading-anchor-permalink" href="#Multiple-measures" title="Permalink"></a></h2><p>Multiple measures are specified as a vector:</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; evaluate!(
           mach,
           resampling=cv,
           measures=[l1, rms, rmslp1],
           verbosity=0,
       )</code><code class="nohighlight hljs ansi" style="display:block;">PerformanceEvaluation object with these fields:
  model, measure, operation,
  measurement, per_fold, per_observation,
  fitted_params_per_fold, report_per_fold,
  train_test_rows, resampling, repeats
Extract:
┌───┬──────────────────────────────────────┬───────────┬─────────────┐
│   │ measure                              │ operation │ measurement │
├───┼──────────────────────────────────────┼───────────┼─────────────┤
│ A │ LPLoss(                              │ predict   │ 0.38        │
│   │   p = 1)                             │           │             │
│ B │ RootMeanSquaredError()               │ predict   │ 0.429       │
│ C │ RootMeanSquaredLogProportionalError( │ predict   │ 0.18        │
│   │   offset = 1)                        │           │             │
└───┴──────────────────────────────────────┴───────────┴─────────────┘
┌───┬───────────────────────┬─────────┐
│   │ per_fold              │ 1.96*SE │
├───┼───────────────────────┼─────────┤
│ A │ [0.526, 0.319, 0.294] │ 0.176   │
│ B │ [0.546, 0.404, 0.299] │ 0.172   │
│ C │ [0.207, 0.203, 0.116] │ 0.0714  │
└───┴───────────────────────┴─────────┘</code></pre><p><a href="../performance_measures/#Custom-measures">Custom measures</a> can also be provided.</p><h2 id="Specifying-weights"><a class="docs-heading-anchor" href="#Specifying-weights">Specifying weights</a><a id="Specifying-weights-1"></a><a class="docs-heading-anchor-permalink" href="#Specifying-weights" title="Permalink"></a></h2><p>Per-observation weights can be passed to measures. If a measure does not support weights, the weights are ignored:</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; holdout = Holdout(fraction_train=0.8)</code><code class="nohighlight hljs ansi" style="display:block;">Holdout(
  fraction_train = 0.8,
  shuffle = false,
  rng = Random._GLOBAL_RNG())</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; weights = [1, 1, 2, 1, 1, 2, 3, 1, 1, 2, 3, 1];</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; evaluate!(
           mach,
           resampling=CV(nfolds=3),
           measure=[l2, rsquared],
           weights=weights,
       )</code><code class="nohighlight hljs ansi" style="display:block;">┌ Warning: Sample weights ignored in evaluations of the following measures, as unsupported: 
│ RSquared() 
└ @ MLJBase ~/.julia/packages/MLJBase/QyZZM/src/resampling.jl:946
Evaluating over 3 folds:  67%[================&gt;        ]  ETA: 0:00:00Evaluating over 3 folds: 100%[=========================] Time: 0:00:00
PerformanceEvaluation object with these fields:
  model, measure, operation,
  measurement, per_fold, per_observation,
  fitted_params_per_fold, report_per_fold,
  train_test_rows, resampling, repeats
Extract:
┌───┬────────────┬───────────┬─────────────┐
│   │ measure    │ operation │ measurement │
├───┼────────────┼───────────┼─────────────┤
│ A │ LPLoss(    │ predict   │ 0.269       │
│   │   p = 2)   │           │             │
│ B │ RSquared() │ predict   │ 0.471       │
└───┴────────────┴───────────┴─────────────┘
┌───┬───────────────────────┬─────────┐
│   │ per_fold              │ 1.96*SE │
├───┼───────────────────────┼─────────┤
│ A │ [0.33, 0.344, 0.133]  │ 0.164   │
│ B │ [0.464, 0.365, 0.583] │ 0.151   │
└───┴───────────────────────┴─────────┘</code></pre><p>In classification problems, use <code>class_weights=...</code> to specify a class weight dictionary.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJBase.evaluate!" href="#MLJBase.evaluate!"><code>MLJBase.evaluate!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">evaluate!(mach; resampling=CV(), measure=nothing, options...)</code></pre><p>Estimate the performance of a machine <code>mach</code> wrapping a supervised model in data, using the specified <code>resampling</code> strategy (defaulting to 6-fold cross-validation) and <code>measure</code>, which can be a single measure or vector. Returns a <a href="#MLJBase.PerformanceEvaluation"><code>PerformanceEvaluation</code></a> object.</p><p>Available resampling strategies are <code>CV</code>, <code>Holdout</code>, <code>InSample</code>, <code>StratifiedCV</code> and <code>TimeSeriesCV</code>. If <code>resampling</code> is not an instance of one of these, then a vector of tuples of the form <code>(train_rows, test_rows)</code> is expected. For example, setting</p><pre><code class="language-julia hljs">resampling = [((1:100), (101:200)),
              ((101:200), (1:100))]</code></pre><p>gives two-fold cross-validation using the first 200 rows of data.</p><p>Any measure conforming to the <a href="https://juliaai.github.io/StatisticalMeasuresBase.jl/dev/">StatisticalMeasuresBase.jl</a> API can be provided, assuming it can consume multiple observations.</p><p>Although <code>evaluate!</code> is mutating, <code>mach.model</code> and <code>mach.args</code> are not mutated.</p><p><strong>Additional keyword options</strong></p><ul><li><p><code>rows</code> - vector of observation indices from which both train and test folds are constructed (default is all observations)</p></li><li><p><code>operation</code>/<code>operations=nothing</code> - One of <code>predict</code>, <code>predict_mean</code>, <code>predict_mode</code>, <code>predict_median</code>, or <code>predict_joint</code>, or a vector of these of the same length as <code>measure</code>/<code>measures</code>. Automatically inferred if left unspecified. For example, <code>predict_mode</code> will be used for a <code>Multiclass</code> target, if <code>model</code> is a probabilistic predictor, but <code>measure</code> is expects literal (point) target predictions. Operations actually applied can be inspected from the <code>operation</code> field of the object returned.</p></li><li><p><code>weights</code> - per-sample <code>Real</code> weights for measures that support them (not to be confused with weights used in training, such as the <code>w</code> in <code>mach = machine(model, X, y, w)</code>).</p></li><li><p><code>class_weights</code> - dictionary of <code>Real</code> per-class weights for use with measures that support these, in classification problems (not to be confused with weights used in training, such as the <code>w</code> in <code>mach = machine(model, X, y, w)</code>).</p></li><li><p><code>repeats::Int=1</code>: set to a higher value for repeated (Monte Carlo) resampling. For example, if <code>repeats = 10</code>, then <code>resampling = CV(nfolds=5, shuffle=true)</code>, generates a total of 50 <code>(train, test)</code> pairs for evaluation and subsequent aggregation.</p></li><li><p><code>acceleration=CPU1()</code>: acceleration/parallelization option; can be any instance of <code>CPU1</code>, (single-threaded computation), <code>CPUThreads</code> (multi-threaded computation) or <code>CPUProcesses</code> (multi-process computation); default is <code>default_resource()</code>. These types are owned by ComputationalResources.jl.</p></li><li><p><code>force=false</code>: set to <code>true</code> to force cold-restart of each training event</p></li><li><p><code>verbosity::Int=1</code> logging level; can be negative</p></li><li><p><code>check_measure=true</code>: whether to screen measures for possible incompatibility with the model. Will not catch all incompatibilities.</p></li><li><p><code>per_observation=true</code>: whether to calculate estimates for individual observations; if <code>false</code> the <code>per_observation</code> field of the returned object is populated with <code>missing</code>s. Setting to <code>false</code> may reduce compute time and allocations.</p></li><li><p><code>logger</code> - a logger object (see <a href="@ref"><code>MLJBase.log_evaluation</code></a>)</p></li><li><p><code>compact=false</code> - if <code>true</code>, the returned evaluation object excludes these fields: <code>fitted_params_per_fold</code>, <code>report_per_fold</code>, <code>train_test_rows</code>.</p></li></ul><p>See also <a href="#MLJModelInterface.evaluate"><code>evaluate</code></a>, <a href="#MLJBase.PerformanceEvaluation"><code>PerformanceEvaluation</code></a>, <a href="@ref"><code>CompactPerformanceEvaluation</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/MLJBase.jl/blob/v1.4.0/src/resampling.jl#L1005-L1079">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJModelInterface.evaluate" href="#MLJModelInterface.evaluate"><code>MLJModelInterface.evaluate</code></a> — <span class="docstring-category">Function</span></header><section><div><p>some meta-models may choose to implement the <code>evaluate</code> operations</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/MLJModelInterface.jl/blob/v1.10.0/src/model_api.jl#L163-L165">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJBase.PerformanceEvaluation" href="#MLJBase.PerformanceEvaluation"><code>MLJBase.PerformanceEvaluation</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PerformanceEvaluation &lt;: AbstractPerformanceEvaluation</code></pre><p>Type of object returned by <a href="#MLJModelInterface.evaluate"><code>evaluate</code></a> (for models plus data) or <a href="#MLJBase.evaluate!"><code>evaluate!</code></a> (for machines). Such objects encode estimates of the performance (generalization error) of a supervised model or outlier detection model, and store other information ancillary to the computation.</p><p>If <a href="#MLJModelInterface.evaluate"><code>evaluate</code></a> or <a href="#MLJBase.evaluate!"><code>evaluate!</code></a> is called with the <code>compact=true</code> option, then a <a href="@ref"><code>CompactPerformanceEvaluation</code></a> object is returned instead.</p><p>When <code>evaluate</code>/<code>evaluate!</code> is called, a number of train/test pairs (&quot;folds&quot;) of row indices are generated, according to the options provided, which are discussed in the <a href="#MLJBase.evaluate!"><code>evaluate!</code></a> doc-string. Rows correspond to observations. The generated train/test pairs are recorded in the <code>train_test_rows</code> field of the <code>PerformanceEvaluation</code> struct, and the corresponding estimates, aggregated over all train/test pairs, are recorded in <code>measurement</code>, a vector with one entry for each measure (metric) recorded in <code>measure</code>.</p><p>When displayed, a <code>PerformanceEvaluation</code> object includes a value under the heading <code>1.96*SE</code>, derived from the standard error of the <code>per_fold</code> entries. This value is suitable for constructing a formal 95% confidence interval for the given <code>measurement</code>. Such intervals should be interpreted with caution. See, for example, Bates et al.  <a href="https://arxiv.org/abs/2104.00673">(2021)</a>.</p><p><strong>Fields</strong></p><p>These fields are part of the public API of the <code>PerformanceEvaluation</code> struct.</p><ul><li><p><code>model</code>: model used to create the performance evaluation. In the case a   tuning model, this is the best model found.</p></li><li><p><code>measure</code>: vector of measures (metrics) used to evaluate performance</p></li><li><p><code>measurement</code>: vector of measurements - one for each element of <code>measure</code> - aggregating the performance measurements over all train/test pairs (folds). The aggregation method applied for a given measure <code>m</code> is <code>StatisticalMeasuresBase.external_aggregation_mode(m)</code> (commonly <code>Mean()</code> or <code>Sum()</code>)</p></li><li><p><code>operation</code> (e.g., <code>predict_mode</code>): the operations applied for each measure to generate predictions to be evaluated. Possibilities are: <code>predict</code>, <code>predict_mean</code>, <code>predict_mode</code>, <code>predict_median</code>, or <code>predict_joint</code>.</p></li><li><p><code>per_fold</code>: a vector of vectors of individual test fold evaluations (one vector per measure). Useful for obtaining a rough estimate of the variance of the performance estimate.</p></li><li><p><code>per_observation</code>: a vector of vectors of vectors containing individual per-observation measurements: for an evaluation <code>e</code>, <code>e.per_observation[m][f][i]</code> is the measurement for the <code>i</code>th observation in the <code>f</code>th test fold, evaluated using the <code>m</code>th measure.  Useful for some forms of hyper-parameter optimization. Note that an aggregregated measurement for some measure <code>measure</code> is repeated across all observations in a fold if <code>StatisticalMeasures.can_report_unaggregated(measure) == true</code>. If <code>e</code> has been computed with the <code>per_observation=false</code> option, then <code>e_per_observation</code> is a vector of <code>missings</code>.</p></li><li><p><code>fitted_params_per_fold</code>: a vector containing <code>fitted params(mach)</code> for each machine <code>mach</code> trained during resampling - one machine per train/test pair. Use this to extract the learned parameters for each individual training event.</p></li><li><p><code>report_per_fold</code>: a vector containing <code>report(mach)</code> for each machine <code>mach</code> training in resampling - one machine per train/test pair.</p></li><li><p><code>train_test_rows</code>: a vector of tuples, each of the form <code>(train, test)</code>, where <code>train</code> and <code>test</code> are vectors of row (observation) indices for training and evaluation respectively.</p></li><li><p><code>resampling</code>: the user-specified resampling strategy to generate the train/test pairs (or literal train/test pairs if that was directly specified).</p></li><li><p><code>repeats</code>: the number of times the resampling strategy was repeated.</p></li></ul><p>See also <a href="@ref"><code>CompactPerformanceEvaluation</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/MLJBase.jl/blob/v1.4.0/src/resampling.jl#L518-L590">source</a></section></article><h2 id="User-specified-train/test-sets"><a class="docs-heading-anchor" href="#User-specified-train/test-sets">User-specified train/test sets</a><a id="User-specified-train/test-sets-1"></a><a class="docs-heading-anchor-permalink" href="#User-specified-train/test-sets" title="Permalink"></a></h2><p>Users can either provide an explicit list of train/test pairs of row indices for resampling, as in this example:</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; fold1 = 1:6; fold2 = 7:12;</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; evaluate!(
           mach,
           resampling = [(fold1, fold2), (fold2, fold1)],
           measures=[l1, l2],
           verbosity=0,
       )</code><code class="nohighlight hljs ansi" style="display:block;">PerformanceEvaluation object with these fields:
  model, measure, operation,
  measurement, per_fold, per_observation,
  fitted_params_per_fold, report_per_fold,
  train_test_rows, resampling, repeats
Extract:
┌───┬──────────┬───────────┬─────────────┐
│   │ measure  │ operation │ measurement │
├───┼──────────┼───────────┼─────────────┤
│ A │ LPLoss(  │ predict   │ 0.45        │
│   │   p = 1) │           │             │
│ B │ LPLoss(  │ predict   │ 0.264       │
│   │   p = 2) │           │             │
└───┴──────────┴───────────┴─────────────┘
┌───┬────────────────┬─────────┐
│   │ per_fold       │ 1.96*SE │
├───┼────────────────┼─────────┤
│ A │ [0.289, 0.612] │ 0.448   │
│ B │ [0.1, 0.429]   │ 0.455   │
└───┴────────────────┴─────────┘</code></pre><p>Or the user can define their own re-usable <code>ResamplingStrategy</code> objects; see <a href="#Custom-resampling-strategies">Custom resampling strategies</a> below.</p><h2 id="Built-in-resampling-strategies"><a class="docs-heading-anchor" href="#Built-in-resampling-strategies">Built-in resampling strategies</a><a id="Built-in-resampling-strategies-1"></a><a class="docs-heading-anchor-permalink" href="#Built-in-resampling-strategies" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJBase.Holdout" href="#MLJBase.Holdout"><code>MLJBase.Holdout</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">holdout = Holdout(; fraction_train=0.7, shuffle=nothing, rng=nothing)</code></pre><p>Instantiate a <code>Holdout</code> resampling strategy, for use in <code>evaluate!</code>, <code>evaluate</code> and in tuning.</p><pre><code class="language-julia hljs">train_test_pairs(holdout, rows)</code></pre><p>Returns the pair <code>[(train, test)]</code>, where <code>train</code> and <code>test</code> are vectors such that <code>rows=vcat(train, test)</code> and <code>length(train)/length(rows)</code> is approximatey equal to fraction_train`.</p><p>Pre-shuffling of <code>rows</code> is controlled by <code>rng</code> and <code>shuffle</code>. If <code>rng</code> is an integer, then the <code>Holdout</code> keyword constructor resets it to <code>MersenneTwister(rng)</code>. Otherwise some <code>AbstractRNG</code> object is expected.</p><p>If <code>rng</code> is left unspecified, <code>rng</code> is reset to <code>Random.GLOBAL_RNG</code>, in which case rows are only pre-shuffled if <code>shuffle=true</code> is specified.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/MLJBase.jl/blob/v1.4.0/src/resampling.jl#L159-L182">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJBase.CV" href="#MLJBase.CV"><code>MLJBase.CV</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">cv = CV(; nfolds=6,  shuffle=nothing, rng=nothing)</code></pre><p>Cross-validation resampling strategy, for use in <code>evaluate!</code>, <code>evaluate</code> and tuning.</p><pre><code class="language-julia hljs">train_test_pairs(cv, rows)</code></pre><p>Returns an <code>nfolds</code>-length iterator of <code>(train, test)</code> pairs of vectors (row indices), where each <code>train</code> and <code>test</code> is a sub-vector of <code>rows</code>. The <code>test</code> vectors are mutually exclusive and exhaust <code>rows</code>. Each <code>train</code> vector is the complement of the corresponding <code>test</code> vector. With no row pre-shuffling, the order of <code>rows</code> is preserved, in the sense that <code>rows</code> coincides precisely with the concatenation of the <code>test</code> vectors, in the order they are generated. The first <code>r</code> test vectors have length <code>n + 1</code>, where <code>n, r = divrem(length(rows), nfolds)</code>, and the remaining test vectors have length <code>n</code>.</p><p>Pre-shuffling of <code>rows</code> is controlled by <code>rng</code> and <code>shuffle</code>. If <code>rng</code> is an integer, then the <code>CV</code> keyword constructor resets it to <code>MersenneTwister(rng)</code>. Otherwise some <code>AbstractRNG</code> object is expected.</p><p>If <code>rng</code> is left unspecified, <code>rng</code> is reset to <code>Random.GLOBAL_RNG</code>, in which case rows are only pre-shuffled if <code>shuffle=true</code> is explicitly specified.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/MLJBase.jl/blob/v1.4.0/src/resampling.jl#L210-L240">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJBase.StratifiedCV" href="#MLJBase.StratifiedCV"><code>MLJBase.StratifiedCV</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">stratified_cv = StratifiedCV(; nfolds=6,
                               shuffle=false,
                               rng=Random.GLOBAL_RNG)</code></pre><p>Stratified cross-validation resampling strategy, for use in <code>evaluate!</code>, <code>evaluate</code> and in tuning. Applies only to classification problems (<code>OrderedFactor</code> or <code>Multiclass</code> targets).</p><pre><code class="language-julia hljs">train_test_pairs(stratified_cv, rows, y)</code></pre><p>Returns an <code>nfolds</code>-length iterator of <code>(train, test)</code> pairs of vectors (row indices) where each <code>train</code> and <code>test</code> is a sub-vector of <code>rows</code>. The <code>test</code> vectors are mutually exclusive and exhaust <code>rows</code>. Each <code>train</code> vector is the complement of the corresponding <code>test</code> vector.</p><p>Unlike regular cross-validation, the distribution of the levels of the target <code>y</code> corresponding to each <code>train</code> and <code>test</code> is constrained, as far as possible, to replicate that of <code>y[rows]</code> as a whole.</p><p>The stratified <code>train_test_pairs</code> algorithm is invariant to label renaming. For example, if you run <code>replace!(y, &#39;a&#39; =&gt; &#39;b&#39;, &#39;b&#39; =&gt; &#39;a&#39;)</code> and then re-run <code>train_test_pairs</code>, the returned <code>(train, test)</code> pairs will be the same.</p><p>Pre-shuffling of <code>rows</code> is controlled by <code>rng</code> and <code>shuffle</code>. If <code>rng</code> is an integer, then the <code>StratifedCV</code> keywod constructor resets it to <code>MersenneTwister(rng)</code>. Otherwise some <code>AbstractRNG</code> object is expected.</p><p>If <code>rng</code> is left unspecified, <code>rng</code> is reset to <code>Random.GLOBAL_RNG</code>, in which case rows are only pre-shuffled if <code>shuffle=true</code> is explicitly specified.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/MLJBase.jl/blob/v1.4.0/src/resampling.jl#L389-L424">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJBase.TimeSeriesCV" href="#MLJBase.TimeSeriesCV"><code>MLJBase.TimeSeriesCV</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">tscv = TimeSeriesCV(; nfolds=4)</code></pre><p>Cross-validation resampling strategy, for use in <code>evaluate!</code>, <code>evaluate</code> and tuning, when observations are chronological and not expected to be independent.</p><pre><code class="language-julia hljs">train_test_pairs(tscv, rows)</code></pre><p>Returns an <code>nfolds</code>-length iterator of <code>(train, test)</code> pairs of vectors (row indices), where each <code>train</code> and <code>test</code> is a sub-vector of <code>rows</code>. The rows are partitioned sequentially into <code>nfolds + 1</code> approximately equal length partitions, where the first partition is the first train set, and the second partition is the first test set. The second train set consists of the first two partitions, and the second test set consists of the third partition, and so on for each fold.</p><p>The first partition (which is the first train set) has length <code>n + r</code>, where <code>n, r = divrem(length(rows), nfolds + 1)</code>, and the remaining partitions (all of the test folds) have length <code>n</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; MLJBase.train_test_pairs(TimeSeriesCV(nfolds=3), 1:10)
3-element Vector{Tuple{UnitRange{Int64}, UnitRange{Int64}}}:
 (1:4, 5:6)
 (1:6, 7:8)
 (1:8, 9:10)

julia&gt; model = (@load RidgeRegressor pkg=MultivariateStats verbosity=0)();

julia&gt; data = @load_sunspots;

julia&gt; X = (lag1 = data.sunspot_number[2:end-1],
            lag2 = data.sunspot_number[1:end-2]);

julia&gt; y = data.sunspot_number[3:end];

julia&gt; tscv = TimeSeriesCV(nfolds=3);

julia&gt; evaluate(model, X, y, resampling=tscv, measure=rmse, verbosity=0)
┌───────────────────────────┬───────────────┬────────────────────┐
│ _.measure                 │ _.measurement │ _.per_fold         │
├───────────────────────────┼───────────────┼────────────────────┤
│ RootMeanSquaredError @753 │ 21.7          │ [25.4, 16.3, 22.4] │
└───────────────────────────┴───────────────┴────────────────────┘
_.per_observation = [missing]
_.fitted_params_per_fold = [ … ]
_.report_per_fold = [ … ]
_.train_test_rows = [ … ]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/MLJBase.jl/blob/v1.4.0/src/resampling.jl#L294-L348">source</a></section></article><h2 id="Custom-resampling-strategies"><a class="docs-heading-anchor" href="#Custom-resampling-strategies">Custom resampling strategies</a><a id="Custom-resampling-strategies-1"></a><a class="docs-heading-anchor-permalink" href="#Custom-resampling-strategies" title="Permalink"></a></h2><p>To define a new resampling strategy, make relevant parameters of your strategy the fields of a new type <code>MyResamplingStrategy &lt;: MLJ.ResamplingStrategy</code>, and implement one of the following methods:</p><pre><code class="language-julia hljs">MLJ.train_test_pairs(my_strategy::MyResamplingStrategy, rows)
MLJ.train_test_pairs(my_strategy::MyResamplingStrategy, rows, y)
MLJ.train_test_pairs(my_strategy::MyResamplingStrategy, rows, X, y)</code></pre><p>Each method takes a vector of indices <code>rows</code> and returns a vector <code>[(t1, e1), (t2, e2), ... (tk, ek)]</code> of train/test pairs of row indices selected from <code>rows</code>. Here <code>X</code>, <code>y</code> are the input and target data (ignored in simple strategies, such as <code>Holdout</code> and <code>CV</code>).</p><p>Here is the code for the <code>Holdout</code> strategy as an example:</p><pre><code class="language-julia hljs">struct Holdout &lt;: ResamplingStrategy
    fraction_train::Float64
    shuffle::Bool
    rng::Union{Int,AbstractRNG}

    function Holdout(fraction_train, shuffle, rng)
        0 &lt; fraction_train &lt; 1 ||
            error(&quot;`fraction_train` must be between 0 and 1.&quot;)
        return new(fraction_train, shuffle, rng)
    end
end

# Keyword Constructor
function Holdout(; fraction_train::Float64=0.7, shuffle=nothing, rng=nothing)
    if rng isa Integer
        rng = MersenneTwister(rng)
    end
    if shuffle === nothing
        shuffle = ifelse(rng===nothing, false, true)
    end
    if rng === nothing
        rng = Random.GLOBAL_RNG
    end
    return Holdout(fraction_train, shuffle, rng)
end

function train_test_pairs(holdout::Holdout, rows)
    train, test = partition(rows, holdout.fraction_train,
                          shuffle=holdout.shuffle, rng=holdout.rng)
    return [(train, test),]
end</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../list_of_supported_models/">« List of Supported Models</a><a class="docs-footer-nextpage" href="../tuning_models/">Tuning Models »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.1 on <span class="colophon-date" title="Monday 10 June 2024 01:25">Monday 10 June 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
