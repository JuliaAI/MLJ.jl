<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Tuning Models · MLJ</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="MLJ logo"/></a><div class="docs-package-name"><span class="docs-autofit">MLJ</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../about_mlj/">About MLJ</a></li><li><a class="tocitem" href="../learning_mlj/">Learning MLJ</a></li><li><a class="tocitem" href="../getting_started/">Getting Started</a></li><li><a class="tocitem" href="../common_mlj_workflows/">Common MLJ Workflows</a></li><li><a class="tocitem" href="../working_with_categorical_data/">Working with Categorical Data</a></li><li><a class="tocitem" href="../model_search/">Model Search</a></li><li><a class="tocitem" href="../loading_model_code/">Loading Model Code</a></li><li><a class="tocitem" href="../machines/">Machines</a></li><li><a class="tocitem" href="../evaluating_model_performance/">Evaluating Model Performance</a></li><li><a class="tocitem" href="../performance_measures/">Performance Measures</a></li><li><a class="tocitem" href="../weights/">Weights</a></li><li class="is-active"><a class="tocitem" href>Tuning Models</a><ul class="internal"><li><a class="tocitem" href="#Overview"><span>Overview</span></a></li><li><a class="tocitem" href="#Tuning-a-single-hyperparameter-using-a-grid-search-(regression-example)"><span>Tuning a single hyperparameter using a grid search (regression example)</span></a></li><li><a class="tocitem" href="#A-probabilistic-classifier-example"><span>A probabilistic classifier example</span></a></li><li><a class="tocitem" href="#Tuning-multiple-nested-hyperparameters"><span>Tuning multiple nested hyperparameters</span></a></li><li><a class="tocitem" href="#Tuning-using-a-random-search"><span>Tuning using a random search</span></a></li><li><a class="tocitem" href="#Tuning-using-Latin-hypercube-sampling"><span>Tuning using Latin hypercube sampling</span></a></li><li><a class="tocitem" href="#explicit"><span>Comparing models of different type and nested cross-validation</span></a></li><li><a class="tocitem" href="#API"><span>API</span></a></li></ul></li><li><a class="tocitem" href="../learning_curves/">Learning Curves</a></li><li><a class="tocitem" href="../preparing_data/">Preparing Data</a></li><li><a class="tocitem" href="../transformers/">Transformers and Other Unsupervised models</a></li><li><a class="tocitem" href="../more_on_probabilistic_predictors/">More on Probabilistic Predictors</a></li><li><a class="tocitem" href="../composing_models/">Composing Models</a></li><li><a class="tocitem" href="../linear_pipelines/">Linear Pipelines</a></li><li><a class="tocitem" href="../target_transformations/">Target Transformations</a></li><li><a class="tocitem" href="../homogeneous_ensembles/">Homogeneous Ensembles</a></li><li><a class="tocitem" href="../model_stacking/">Model Stacking</a></li><li><a class="tocitem" href="../learning_networks/">Learning Networks</a></li><li><a class="tocitem" href="../controlling_iterative_models/">Controlling Iterative Models</a></li><li><a class="tocitem" href="../generating_synthetic_data/">Generating Synthetic Data</a></li><li><a class="tocitem" href="../openml_integration/">OpenML Integration</a></li><li><a class="tocitem" href="../acceleration_and_parallelism/">Acceleration and Parallelism</a></li><li><a class="tocitem" href="../simple_user_defined_models/">Simple User Defined Models</a></li><li><a class="tocitem" href="../quick_start_guide_to_adding_models/">Quick-Start Guide to Adding Models</a></li><li><a class="tocitem" href="../adding_models_for_general_use/">Adding Models for General Use</a></li><li><a class="tocitem" href="../modifying_behavior/">Modifying Behavior</a></li><li><a class="tocitem" href="../internals/">Internals</a></li><li><a class="tocitem" href="../list_of_supported_models/">List of Supported Models</a></li><li><a class="tocitem" href="../third_party_packages/">Third Party Packages</a></li><li><a class="tocitem" href="../glossary/">Glossary</a></li><li><a class="tocitem" href="../mlj_cheatsheet/">MLJ Cheatsheet</a></li><li><a class="tocitem" href="../known_issues/">Known Issues</a></li><li><a class="tocitem" href="../frequently_asked_questions/">FAQ</a></li><li><a class="tocitem" href="../julia_blogpost/">Julia BlogPost</a></li><li><a class="tocitem" href="../api/">Index of Methods</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Tuning Models</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Tuning Models</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/alan-turing-institute/MLJ.jl/blob/master/docs/src/tuning_models.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Tuning-Models"><a class="docs-heading-anchor" href="#Tuning-Models">Tuning Models</a><a id="Tuning-Models-1"></a><a class="docs-heading-anchor-permalink" href="#Tuning-Models" title="Permalink"></a></h1><p>MLJ provides several built-in and third-party options for optimizing a model&#39;s hyper-parameters.  The quick-reference table below omits some advanced keyword options.</p><table><tr><th style="text-align: right">tuning strategy</th><th style="text-align: right">notes</th><th style="text-align: right">package to import</th><th style="text-align: right">package providing the core algorithm</th></tr><tr><td style="text-align: right"><a href="#MLJTuning.Grid"><code>Grid</code></a><code>(goal=nothing, resolution=10)</code></td><td style="text-align: right">shuffled by default; <code>goal</code> is upper bound for number of grid points</td><td style="text-align: right">MLJ.jl or MLJTuning.jl</td><td style="text-align: right"><a href="https://github.com/FluxML/model-zoo">MLJTuning.jl</a></td></tr><tr><td style="text-align: right"><a href="#MLJTuning.RandomSearch"><code>RandomSearch</code></a><code>(rng=GLOBAL_RNG)</code></td><td style="text-align: right">with customizable priors</td><td style="text-align: right">MLJ.jl or MLJTuning.jl</td><td style="text-align: right"><a href="https://github.com/FluxML/model-zoo">MLJTuning.jl</a></td></tr><tr><td style="text-align: right"><a href="#MLJTuning.LatinHypercube"><code>LatinHypercube</code></a><code>(rng=GLOBAL_RNG)</code></td><td style="text-align: right">with discrete parameter support</td><td style="text-align: right">MLJ.jl or MLJTuning.jl</td><td style="text-align: right"><a href="https://github.com/MrUrq/LatinHypercubeSampling.jl">LatinHypercubeSampling</a></td></tr><tr><td style="text-align: right"><code>MLJTreeParzenTuning()</code></td><td style="text-align: right">See this <a href="https://github.com/IQVIA-ML/TreeParzen.jl/blob/master/docs/examples/simple_mlj_demo/simple_mlj_demo.md">example</a> for usage</td><td style="text-align: right">TreeParzen.jl</td><td style="text-align: right"><a href="https://github.com/IQVIA-ML/TreeParzen.jl">TreeParzen.jl</a> (port to Julia of <a href="http://hyperopt.github.io/hyperopt/">hyperopt</a>)</td></tr><tr><td style="text-align: right"><code>ParticleSwarm(n_particles=3, rng=GLOBAL_RNG)</code></td><td style="text-align: right">Standard Kennedy-Eberhart algorithm, plus discrete parameter support</td><td style="text-align: right">MLJParticleSwarmOptimization.jl</td><td style="text-align: right"><a href="https://github.com/JuliaAI/MLJParticleSwarmOptimization.jl/">MLJParticleSwarmOptimization.jl</a></td></tr><tr><td style="text-align: right"><code>AdaptiveParticleSwarm(n_particles=3, rng=GLOBAL_RNG)</code></td><td style="text-align: right">Zhan et al. variant with automated swarm coefficient updates, plus discrete parameter support</td><td style="text-align: right">MLJParticleSwarmOptimization.jl</td><td style="text-align: right"><a href="https://github.com/JuliaAI/MLJParticleSwarmOptimization.jl/">MLJParticleSwarmOptimization.jl</a></td></tr><tr><td style="text-align: right"><code>Explicit()</code></td><td style="text-align: right">For an <a href="#explicit">explicit list</a> of models of varying type</td><td style="text-align: right">MLJ.jl or MLJTuning.jl</td><td style="text-align: right"><a href="https://github.com/FluxML/model-zoo">MLJTuning.jl</a></td></tr></table><p>Below we illustrate hyperparameter optimization using the <a href="#MLJTuning.Grid"><code>Grid</code></a>, <a href="#MLJTuning.RandomSearch"><code>RandomSearch</code></a>, <a href="#MLJTuning.LatinHypercube"><code>LatinHypercube</code></a> and <code>Explicit</code> tuning strategies.</p><h2 id="Overview"><a class="docs-heading-anchor" href="#Overview">Overview</a><a id="Overview-1"></a><a class="docs-heading-anchor-permalink" href="#Overview" title="Permalink"></a></h2><p>In MLJ model tuning is implemented as a model wrapper. After wrapping a model in a tuning strategy and binding the wrapped model to data in a machine called <code>mach</code>, calling <code>fit!(mach)</code> instigates a search for optimal model hyperparameters, within a specified <code>range</code>, and then uses all supplied data to train the best model. To predict using that model, one then calls <code>predict(mach, Xnew)</code>. In this way, the wrapped model may be viewed as a &quot;self-tuning&quot; version of the unwrapped model. That is, wrapping the model simply transforms certain hyper-parameters into <em>learned</em> parameters.</p><p>A corollary of the tuning-as-wrapper approach is that the evaluation of the performance of a <code>TunedModel</code> instance using <a href="../evaluating_model_performance/#MLJBase.evaluate!"><code>evaluate!</code></a> implies nested resampling. This approach is inspired by <a href="https://mlr.mlr-org.com/articles/tutorial/nested_resampling.html">MLR</a>. See also <a href="#explicit">below</a>.</p><p>In MLJ, tuning is an <em>iterative</em> procedure, with an iteration parameter <code>n</code>, the total number of model instances to be evaluated. Accordingly, tuning can be controlled using MLJ&#39;s <a href="../controlling_iterative_models/#MLJIteration.IteratedModel"><code>IteratedModel</code></a> wrapper. After familiarizing oneself with the <code>TunedModel</code> wrapper described below, see <a href="../controlling_iterative_models/#Controlling-model-tuning">Controlling model tuning</a> for more on this advanced feature.</p><p>For a more in-depth overview of tuning in MLJ, or for implementation details, see the <a href="https://github.com/JuliaAI/MLJTuning.jl">MLJTuning documentation</a>. For a complete list of options see the <a href="#MLJTuning.TunedModel"><code>TunedModel</code></a> doc-string below.</p><h2 id="Tuning-a-single-hyperparameter-using-a-grid-search-(regression-example)"><a class="docs-heading-anchor" href="#Tuning-a-single-hyperparameter-using-a-grid-search-(regression-example)">Tuning a single hyperparameter using a grid search (regression example)</a><a id="Tuning-a-single-hyperparameter-using-a-grid-search-(regression-example)-1"></a><a class="docs-heading-anchor-permalink" href="#Tuning-a-single-hyperparameter-using-a-grid-search-(regression-example)" title="Permalink"></a></h2><pre><code class="language-julia">using MLJ
X = MLJ.table(rand(100, 10));
y = 2X.x1 - X.x2 + 0.05*rand(100);
Tree = @load DecisionTreeRegressor pkg=DecisionTree verbosity=0;
tree = Tree()</code></pre><pre class="documenter-example-output">DecisionTreeRegressor(
  max_depth = -1, 
  min_samples_leaf = 5, 
  min_samples_split = 2, 
  min_purity_increase = 0.0, 
  n_subfeatures = 0, 
  post_prune = false, 
  merge_purity_threshold = 1.0, 
  feature_importance = :impurity, 
  rng = Random._GLOBAL_RNG())</pre><p>Let&#39;s tune <code>min_purity_increase</code> in the model above, using a grid-search. To do so we will use the simplest <code>range</code> object, a one-dimensional range object constructed using the <code>range</code> method:</p><pre><code class="language-julia">r = range(tree, :min_purity_increase, lower=0.001, upper=1.0, scale=:log);
self_tuning_tree = TunedModel(model=tree,
							  resampling=CV(nfolds=3),
							  tuning=Grid(resolution=10),
							  range=r,
							  measure=rms);</code></pre><pre class="documenter-example-output">DeterministicTunedModel(
  model = DecisionTreeRegressor(
        max_depth = -1, 
        min_samples_leaf = 5, 
        min_samples_split = 2, 
        min_purity_increase = 0.0, 
        n_subfeatures = 0, 
        post_prune = false, 
        merge_purity_threshold = 1.0, 
        feature_importance = :impurity, 
        rng = Random._GLOBAL_RNG()), 
  tuning = Grid(
        goal = nothing, 
        resolution = 10, 
        shuffle = true, 
        rng = Random._GLOBAL_RNG()), 
  resampling = CV(
        nfolds = 3, 
        shuffle = false, 
        rng = Random._GLOBAL_RNG()), 
  measure = RootMeanSquaredError(), 
  weights = nothing, 
  class_weights = nothing, 
  operation = nothing, 
  range = NumericRange(0.001 ≤ min_purity_increase ≤ 1.0; origin=0.5005, unit=0.4995; on log scale), 
  selection_heuristic = MLJTuning.NaiveSelection(nothing), 
  train_best = true, 
  repeats = 1, 
  n = nothing, 
  acceleration = CPU1{Nothing}(nothing), 
  acceleration_resampling = CPU1{Nothing}(nothing), 
  check_measure = true, 
  cache = true)</pre><p>Incidentally, a grid is generated internally &quot;over the range&quot; by calling the <code>iterator</code> method with an appropriate resolution:</p><pre><code class="language-julia">iterator(r, 5)</code></pre><pre class="documenter-example-output">5-element Vector{Float64}:
 0.0010000000000000002
 0.005623413251903492
 0.0316227766016838
 0.1778279410038923
 1.0</pre><p>Non-numeric hyperparameters are handled a little differently:</p><pre><code class="language-julia">selector = FeatureSelector();
r2 = range(selector, :features, values = [[:x1,], [:x1, :x2]]);
iterator(r2)</code></pre><pre class="documenter-example-output">2-element Vector{Vector{Symbol}}:
 [:x1]
 [:x1, :x2]</pre><p>Unbounded ranges are also permitted. See the <a href="#Base.range"><code>range</code></a> and <a href="#MLJBase.iterator"><code>iterator</code></a> docstrings below for details, and the <a href="#Distributions.sampler"><code>sampler</code></a> docstring for generating random samples from one-dimensional ranges (used internally by the <a href="#MLJTuning.RandomSearch"><code>RandomSearch</code></a> strategy).</p><p>Returning to the wrapped tree model:</p><pre><code class="language-julia">mach = machine(self_tuning_tree, X, y);
fit!(mach, verbosity=0)</code></pre><pre class="documenter-example-output">trained Machine; does not cache data
  model: DeterministicTunedModel(model = DecisionTreeRegressor(max_depth = -1, …), …)
  args: 
    1:	Source @095 ⏎ Table{AbstractVector{Continuous}}
    2:	Source @687 ⏎ AbstractVector{Continuous}
</pre><p>We can inspect the detailed results of the grid search with <code>report(mach)</code> or just retrieve the optimal model, as here:</p><pre><code class="language-julia">fitted_params(mach).best_model</code></pre><pre class="documenter-example-output">DecisionTreeRegressor(
  max_depth = -1, 
  min_samples_leaf = 5, 
  min_samples_split = 2, 
  min_purity_increase = 0.010000000000000004, 
  n_subfeatures = 0, 
  post_prune = false, 
  merge_purity_threshold = 1.0, 
  feature_importance = :impurity, 
  rng = Random._GLOBAL_RNG())</pre><p>For more detailed information, we can look at <code>report(mach)</code>, for example:</p><pre><code class="language-julia">entry = report(mach).best_history_entry</code></pre><pre class="documenter-example-output">(model = DecisionTreeRegressor(max_depth = -1, …),
 measure = [RootMeanSquaredError()],
 measurement = [0.26972775186169046],
 per_fold = [[0.22098922603087104, 0.35686244628875036, 0.20511493553656762]],)</pre><p>Predicting on new input observations using the optimal model, <em>trained on all the data</em> bound to <code>mach</code>:</p><pre><code class="language-julia">Xnew  = MLJ.table(rand(3, 10));
predict(mach, Xnew)</code></pre><pre class="documenter-example-output">3-element Vector{Float64}:
  1.792160485744994
  0.8249751131366307
 -0.28828185236240333</pre><p>Or predicting on some subset of the observations bound to <code>mach</code>:</p><pre><code class="language-julia">test = 1:3
predict(mach, rows=test)</code></pre><pre class="documenter-example-output">3-element Vector{Float64}:
  0.8249751131366307
 -0.28828185236240333
  0.24133412566816137</pre><p>For tuning using only a subset <code>train</code> of all observation indices, specify <code>rows=train</code> in the above <code>fit!</code> call. In that case, the above <code>predict</code> calls would be based on training the optimal model on all <code>train</code> rows.</p><h2 id="A-probabilistic-classifier-example"><a class="docs-heading-anchor" href="#A-probabilistic-classifier-example">A probabilistic classifier example</a><a id="A-probabilistic-classifier-example-1"></a><a class="docs-heading-anchor-permalink" href="#A-probabilistic-classifier-example" title="Permalink"></a></h2><p>Tuning a classifier is not essentially different from tuning a regressor. A common gotcha however is to overlook the distinction between supervised models that make point predictions (subtypes of <code>Deterministic</code>) and those that make probabilistic predictions (subtypes of <code>Probabilistic</code>). The <code>DecisionTreeRegressor</code> model in the preceding illustration was deterministic, so this example will consider a probabilistic classifier:</p><pre><code class="language-julia">info(&quot;KNNClassifier&quot;).prediction_type</code></pre><pre class="documenter-example-output">:probabilistic</pre><pre><code class="language-julia">X, y = @load_iris
KNN = @load KNNClassifier verbosity=0
knn = KNN()</code></pre><pre class="documenter-example-output">KNNClassifier(
  K = 5, 
  algorithm = :kdtree, 
  metric = Distances.Euclidean(0.0), 
  leafsize = 10, 
  reorder = true, 
  weights = NearestNeighborModels.Uniform())</pre><p>We&#39;ll tune the hyperparameter <code>K</code> in the model above, using a grid-search once more:</p><pre><code class="language-julia">K_range = range(knn, :K, lower=5, upper=20);</code></pre><pre class="documenter-example-output">NumericRange(5 ≤ K ≤ 20; origin=12.5, unit=7.5)</pre><p>Since the model is probabilistic, we can choose either: (i) a probabilistic measure, such as <code>brier_loss</code>; or (ii) use a deterministic measure, such as <code>misclassification_rate</code> (which means <code>predict_mean</code> is called instead of <code>predict</code> under the hood).</p><p><strong>Case (i) - probabilistic measure</strong>:</p><pre><code class="language-julia">self_tuning_knn = TunedModel(model=knn,
							 resampling = CV(nfolds=4, rng=1234),
							 tuning = Grid(resolution=5),
							 range = K_range,
							 measure=BrierLoss());

mach = machine(self_tuning_knn, X, y);
fit!(mach, verbosity=0);</code></pre><pre class="documenter-example-output">trained Machine; does not cache data
  model: ProbabilisticTunedModel(model = KNNClassifier(K = 5, …), …)
  args: 
    1:	Source @924 ⏎ Table{AbstractVector{Continuous}}
    2:	Source @884 ⏎ AbstractVector{Multiclass{3}}
</pre><p><strong>Case (ii) - deterministic measure</strong>:</p><pre><code class="language-julia">self_tuning_knn = TunedModel(model=knn,
							 resampling = CV(nfolds=4, rng=1234),
							 tuning = Grid(resolution=5),
							 range = K_range,
							 measure=MisclassificationRate())

mach = machine(self_tuning_knn, X, y);
fit!(mach, verbosity=0);</code></pre><pre class="documenter-example-output">trained Machine; does not cache data
  model: ProbabilisticTunedModel(model = KNNClassifier(K = 5, …), …)
  args: 
    1:	Source @410 ⏎ Table{AbstractVector{Continuous}}
    2:	Source @991 ⏎ AbstractVector{Multiclass{3}}
</pre><p>Let&#39;s inspect the best model and corresponding evaluation of the metric in case (ii):</p><pre><code class="language-julia">entry = report(mach).best_history_entry</code></pre><pre class="documenter-example-output">(model = KNNClassifier(K = 5, …),
 measure = [MisclassificationRate()],
 measurement = [0.026849217638691324],
 per_fold = [[0.0, 0.02631578947368421, 0.0, 0.08108108108108109]],)</pre><pre><code class="language-julia">entry.model.K</code></pre><pre class="documenter-example-output">5</pre><p>Recall that fitting <code>mach</code> also retrains the optimal model on all available data. The following is therefore an optimal model prediction based on all available data:</p><pre><code class="language-julia">predict(mach, rows=148:150)</code></pre><pre class="documenter-example-output">3-element CategoricalDistributions.UnivariateFiniteVector{Multiclass{3}, String, UInt32, Float64}:
 UnivariateFinite{Multiclass{3}}(setosa=&gt;0.0, versicolor=&gt;0.0, virginica=&gt;1.0)
 UnivariateFinite{Multiclass{3}}(setosa=&gt;0.0, versicolor=&gt;0.0, virginica=&gt;1.0)
 UnivariateFinite{Multiclass{3}}(setosa=&gt;0.0, versicolor=&gt;0.0, virginica=&gt;1.0)</pre><h3 id="Specifying-a-custom-measure"><a class="docs-heading-anchor" href="#Specifying-a-custom-measure">Specifying a custom measure</a><a id="Specifying-a-custom-measure-1"></a><a class="docs-heading-anchor-permalink" href="#Specifying-a-custom-measure" title="Permalink"></a></h3><p>Users may specify a custom loss or scoring function.  Suppose, for example, we define a new scoring function <code>custom_accuracy</code> by</p><pre><code class="language-julia">custom_accuracy(y,yhat) = mean(y .== yhat);</code></pre><pre class="documenter-example-output">custom_accuracy (generic function with 1 method)</pre><p>In tuning, scores are maximised, while losses are minimised. By default, a custom measure is assumed to be a loss rather than a score, so we must also declare</p><pre><code class="language-julia">MLJ.orientation(::typeof(custom_accuracy)) = :score</code></pre><p>For full details on constructing custom measures, see <a href="../performance_measures/#Traits-and-custom-measures">Traits and custom measures</a>.</p><pre><code class="language-julia">self_tuning_knn = TunedModel(model=knn,
							 resampling = CV(nfolds=4),
							 tuning = Grid(resolution=5),
							 range = K_range,
							 measure = [custom_accuracy, MulticlassFScore()],
							 operation = predict_mode);

mach = machine(self_tuning_knn, X, y)
fit!(mach, verbosity=0)
entry = report(mach).best_history_entry</code></pre><pre class="documenter-example-output">(model = KNNClassifier(K = 5, …),
 measure = Any[Main.var&quot;ex-goof&quot;.custom_accuracy, MulticlassFScore(β = 1.0, …)],
 measurement = [0.8856685633001422, 0.7428716167317991],
 per_fold = [[1.0, 0.9210526315789473, 0.918918918918919, 0.7027027027027027], [1.0, 0.6462585034013606, 0.9125295508274232, 0.4126984126984127]],)</pre><pre><code class="language-julia">entry.model.K</code></pre><pre class="documenter-example-output">5</pre><h2 id="Tuning-multiple-nested-hyperparameters"><a class="docs-heading-anchor" href="#Tuning-multiple-nested-hyperparameters">Tuning multiple nested hyperparameters</a><a id="Tuning-multiple-nested-hyperparameters-1"></a><a class="docs-heading-anchor-permalink" href="#Tuning-multiple-nested-hyperparameters" title="Permalink"></a></h2><p>The <code>forest</code> model below has another model, namely a <code>DecisionTreeRegressor</code>, as a hyperparameter:</p><pre><code class="language-julia">tree = Tree() # defined above
forest = EnsembleModel(model=tree)</code></pre><pre class="documenter-example-output">DeterministicEnsembleModel(
  model = DecisionTreeRegressor(
        max_depth = -1, 
        min_samples_leaf = 5, 
        min_samples_split = 2, 
        min_purity_increase = 0.0, 
        n_subfeatures = 0, 
        post_prune = false, 
        merge_purity_threshold = 1.0, 
        feature_importance = :impurity, 
        rng = Random._GLOBAL_RNG()), 
  atomic_weights = Float64[], 
  bagging_fraction = 0.8, 
  rng = Random._GLOBAL_RNG(), 
  n = 100, 
  acceleration = CPU1{Nothing}(nothing), 
  out_of_bag_measure = Any[])</pre><p>Ranges for nested hyperparameters are specified using dot syntax. In this case, we will specify a <code>goal</code> for the total number of grid points:</p><pre><code class="language-julia">r1 = range(forest, :(model.n_subfeatures), lower=1, upper=9);
r2 = range(forest, :bagging_fraction, lower=0.4, upper=1.0);
self_tuning_forest = TunedModel(model=forest,
									  tuning=Grid(goal=30),
									  resampling=CV(nfolds=6),
									  range=[r1, r2],
									  measure=rms);

X = MLJ.table(rand(100, 10));
y = 2X.x1 - X.x2 + 0.05*rand(100);

mach = machine(self_tuning_forest, X, y);
fit!(mach, verbosity=0);</code></pre><pre class="documenter-example-output">trained Machine; does not cache data
  model: DeterministicTunedModel(model = DeterministicEnsembleModel(model = DecisionTreeRegressor(max_depth = -1, …), …), …)
  args: 
    1:	Source @561 ⏎ Table{AbstractVector{Continuous}}
    2:	Source @108 ⏎ AbstractVector{Continuous}
</pre><p>We can plot the grid search results:</p><pre><code class="language-julia">using Plots
plot(mach)</code></pre><p><img src="../img/tuning_plot.png" alt/></p><p>Instead of specifying a <code>goal</code>, we can declare a global <code>resolution</code>, which is overridden for a particular parameter by pairing its range with the resolution desired. In the next example, the default <code>resolution=100</code> is applied to the <code>r2</code> field, but a resolution of <code>3</code> is applied to the <code>r1</code> field. Additionally, we ask that the grid points be randomly traversed and the total number of evaluations be limited to 25.</p><pre><code class="language-julia">tuning = Grid(resolution=100, shuffle=true, rng=1234)
self_tuning_forest = TunedModel(model=forest,
									  tuning=tuning,
									  resampling=CV(nfolds=6),
									  range=[(r1, 3), r2],
									  measure=rms,
									  n=25);
fit!(machine(self_tuning_forest, X, y), verbosity=0);</code></pre><pre class="documenter-example-output">trained Machine; does not cache data
  model: DeterministicTunedModel(model = DeterministicEnsembleModel(model = DecisionTreeRegressor(max_depth = -1, …), …), …)
  args: 
    1:	Source @741 ⏎ Table{AbstractVector{Continuous}}
    2:	Source @115 ⏎ AbstractVector{Continuous}
</pre><p>For more options for a grid search, see <a href="#MLJTuning.Grid"><code>Grid</code></a> below.</p><h2 id="Tuning-using-a-random-search"><a class="docs-heading-anchor" href="#Tuning-using-a-random-search">Tuning using a random search</a><a id="Tuning-using-a-random-search-1"></a><a class="docs-heading-anchor-permalink" href="#Tuning-using-a-random-search" title="Permalink"></a></h2><p>Let&#39;s attempt to tune the same hyperparameters using a <code>RandomSearch</code> tuning strategy. By default, bounded numeric ranges like <code>r1</code> and <code>r2</code> are sampled uniformly (before rounding, in the case of the integer range <code>r1</code>). Positive unbounded ranges are sampled using a Gamma distribution by default, and all others using a (truncated) normal distribution.</p><pre><code class="language-julia">self_tuning_forest = TunedModel(model=forest,
									  tuning=RandomSearch(),
									  resampling=CV(nfolds=6),
									  range=[r1, r2],
									  measure=rms,
									  n=25);
X = MLJ.table(rand(100, 10));
y = 2X.x1 - X.x2 + 0.05*rand(100);
mach = machine(self_tuning_forest, X, y);
fit!(mach, verbosity=0)</code></pre><pre class="documenter-example-output">trained Machine; does not cache data
  model: DeterministicTunedModel(model = DeterministicEnsembleModel(model = DecisionTreeRegressor(max_depth = -1, …), …), …)
  args: 
    1:	Source @268 ⏎ Table{AbstractVector{Continuous}}
    2:	Source @624 ⏎ AbstractVector{Continuous}
</pre><pre><code class="language-julia">using Plots
plot(mach)</code></pre><p><img src="../img/random_search_tuning_plot.png" alt/></p><p>The prior distributions used for sampling each hyperparameter can be customized, as can the global fallbacks. See the <a href="#MLJTuning.RandomSearch"><code>RandomSearch</code></a> doc-string below for details.</p><h2 id="Tuning-using-Latin-hypercube-sampling"><a class="docs-heading-anchor" href="#Tuning-using-Latin-hypercube-sampling">Tuning using Latin hypercube sampling</a><a id="Tuning-using-Latin-hypercube-sampling-1"></a><a class="docs-heading-anchor-permalink" href="#Tuning-using-Latin-hypercube-sampling" title="Permalink"></a></h2><p>One can also tune the hyperparameters using the <code>LatinHypercube</code> tuning strategy.  This method uses a genetic-based optimization algorithm based on the inverse of the Audze-Eglais function, using the library <a href="https://github.com/MrUrq/LatinHypercubeSampling.jl"><code>LatinHypercubeSampling.jl</code></a>.</p><p>We&#39;ll work with the data <code>X</code>, <code>y</code> and ranges <code>r1</code> and <code>r2</code> defined above and instantiate a Latin hypercube resampling strategy:</p><pre><code class="language-julia">latin = LatinHypercube(gens=2, popsize=120)</code></pre><pre class="documenter-example-output">LatinHypercube(
  gens = 2, 
  popsize = 120, 
  ntour = 2, 
  ptour = 0.8, 
  interSampleWeight = 1.0, 
  ae_power = 2, 
  periodic_ae = false, 
  rng = Random._GLOBAL_RNG())</pre><p>Here <code>gens</code> is the number of generations to run the optimisation for and <code>popsize</code> is the population size in the genetic algorithm. For more on these and other <code>LatinHypercube</code> parameters refer to the <a href="https://github.com/MrUrq/LatinHypercubeSampling.jl">LatinHypercubeSampling.jl</a> documentation. Pay attention that <code>gens</code> and <code>popsize</code> are not to be confused with the iteration parameter <code>n</code> in the construction of a corresponding <code>TunedModel</code> instance, which specifies the total number of models to be evaluated, independent of the tuning strategy.</p><p>For this illustration we&#39;ll add a third, nominal,  hyper-parameter:</p><pre><code class="language-julia">r3 = range(forest, :(model.post_prune), values=[true, false]);
self_tuning_forest = TunedModel(model=forest,
									  tuning=latin,
									  resampling=CV(nfolds=6),
									  range=[r1, r2, r3],
									  measure=rms,
									  n=25);
mach = machine(self_tuning_forest, X, y);
fit!(mach, verbosity=0)</code></pre><pre class="documenter-example-output">trained Machine; does not cache data
  model: DeterministicTunedModel(model = DeterministicEnsembleModel(model = DecisionTreeRegressor(max_depth = -1, …), …), …)
  args: 
    1:	Source @470 ⏎ Table{AbstractVector{Continuous}}
    2:	Source @247 ⏎ AbstractVector{Continuous}
</pre><pre><code class="language-julia">using Plots
plot(mach)</code></pre><p><img src="../img/latin_hypercube_tuning_plot.png" alt/></p><h2 id="explicit"><a class="docs-heading-anchor" href="#explicit">Comparing models of different type and nested cross-validation</a><a id="explicit-1"></a><a class="docs-heading-anchor-permalink" href="#explicit" title="Permalink"></a></h2><p>Instead of mutating hyperparameters of a fixed model, one can instead optimise over an explicit list of models, whose types are allowed to vary. As with other tuning strategies, evaluating the resulting <code>TunedModel</code> itself implies nested resampling (e.g., nested cross-validation) which we now examine in a bit more detail.</p><pre><code class="language-julia">tree = (@load DecisionTreeClassifier pkg=DecisionTree verbosity=0)()
knn = (@load KNNClassifier pkg=NearestNeighborModels verbosity=0)()
models = [tree, knn]</code></pre><p>The following model is equivalent to the best in <code>models</code> by using 3-fold cross-validation:</p><pre><code class="language-julia">multi_model = TunedModel(models=models,
						 resampling=CV(nfolds=3),
						 measure=log_loss,
						 check_measure=false)</code></pre><p>Note that there is no need to specify a <code>tuning</code> strategy or <code>range</code> but we do specify <code>models</code> (plural) instead of <code>model</code>. Evaluating <code>multi_model</code> implies nested cross-validation (each model gets evaluated 2 x 3 times):</p><pre><code class="language-julia">X, y = make_blobs()

e = evaluate(multi_model, X, y,
			 resampling=CV(nfolds=2),
			 measure=log_loss,
			 verbosity=6)</code></pre><pre class="documenter-example-output">PerformanceEvaluation object with these fields:
  measure, operation, measurement, per_fold,
  per_observation, fitted_params_per_fold,
  report_per_fold, train_test_rows
Extract:
┌────────────────────────────────┬───────────┬─────────────┬─────────┬──────────
│ measure                        │ operation │ measurement │ 1.96*SE │ per_fol ⋯
├────────────────────────────────┼───────────┼─────────────┼─────────┼──────────
│ LogLoss(                       │ predict   │ 0.477       │ 1.02    │ [0.844, ⋯
│   tol = 2.220446049250313e-16) │           │             │         │         ⋯
└────────────────────────────────┴───────────┴─────────────┴─────────┴──────────
                                                                1 column omitted
</pre><p>Now, for example, we can get the best model for the first fold out of the two folds:</p><pre><code class="language-julia">e.report_per_fold[1].best_model</code></pre><pre class="documenter-example-output">KNNClassifier(
  K = 5, 
  algorithm = :kdtree, 
  metric = Distances.Euclidean(0.0), 
  leafsize = 10, 
  reorder = true, 
  weights = NearestNeighborModels.Uniform())</pre><p>And the losses in the outer loop (these still have to be matched to the best performing model):</p><pre><code class="language-julia">e.per_fold</code></pre><pre class="documenter-example-output">1-element Vector{Vector{Float64}}:
 [0.8439681182861232, 0.10948055729255236]</pre><p>It is also possible to get the results for the nested evaluations. For example, for the first fold of the outer loop and the second model:</p><pre><code class="language-julia">e.report_per_fold[2].history[1]</code></pre><pre class="documenter-example-output">(model = DecisionTreeClassifier(max_depth = -1, …),
 measure = LogLoss{Float64}[LogLoss(tol = 2.220446049250313e-16)],
 measurement = [4.328772098202795],
 per_fold = [[2.1202149052421855, 6.360644715726557, 4.505456673639644]],)</pre><h2 id="API"><a class="docs-heading-anchor" href="#API">API</a><a id="API-1"></a><a class="docs-heading-anchor-permalink" href="#API" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="Base.range" href="#Base.range"><code>Base.range</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">r = range(model, :hyper; values=nothing)</code></pre><p>Define a one-dimensional <code>NominalRange</code> object for a field <code>hyper</code> of <code>model</code>. Note that <code>r</code> is not directly iterable but <code>iterator(r)</code> is.</p><p>A nested hyperparameter is specified using dot notation. For example, <code>:(atom.max_depth)</code> specifies the <code>max_depth</code> hyperparameter of the submodel <code>model.atom</code>.</p><pre><code class="language-none">r = range(model, :hyper; upper=nothing, lower=nothing,
          scale=nothing, values=nothing)</code></pre><p>Assuming <code>values</code> is not specified, define a one-dimensional <code>NumericRange</code> object for a <code>Real</code> field <code>hyper</code> of <code>model</code>.  Note that <code>r</code> is not directly iteratable but <code>iterator(r, n)</code>is an iterator of length <code>n</code>. To generate random elements from <code>r</code>, instead apply <code>rand</code> methods to <code>sampler(r)</code>. The supported scales are <code>:linear</code>,<code>:log</code>, <code>:logminus</code>, <code>:log10</code>, <code>:log10minus</code>, <code>:log2</code>, or a callable object.</p><p>Note that <code>r</code> is not directly iterable, but <code>iterator(r, n)</code> is, for given resolution (length) <code>n</code>.</p><p>By default, the behaviour of the constructed object depends on the type of the value of the hyperparameter <code>:hyper</code> at <code>model</code> <em>at the time of construction.</em> To override this behaviour (for instance if <code>model</code> is not available) specify a type in place of <code>model</code> so the behaviour is determined by the value of the specified type.</p><p>A nested hyperparameter is specified using dot notation (see above).</p><p>If <code>scale</code> is unspecified, it is set to <code>:linear</code>, <code>:log</code>, <code>:log10minus</code>, or <code>:linear</code>, according to whether the interval <code>(lower, upper)</code> is bounded, right-unbounded, left-unbounded, or doubly unbounded, respectively.  Note <code>upper=Inf</code> and <code>lower=-Inf</code> are allowed.</p><p>If <code>values</code> is specified, the other keyword arguments are ignored and a <code>NominalRange</code> object is returned (see above).</p><p>See also: <a href="#MLJBase.iterator"><code>iterator</code></a>, <a href="#Distributions.sampler"><code>sampler</code></a></p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJBase.iterator" href="#MLJBase.iterator"><code>MLJBase.iterator</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">iterator([rng, ], r::NominalRange, [,n])
iterator([rng, ], r::NumericRange, n)</code></pre><p>Return an iterator (currently a vector) for a <code>ParamRange</code> object <code>r</code>. In the first case iteration is over all <code>values</code> stored in the range (or just the first <code>n</code>, if <code>n</code> is specified). In the second case, the iteration is over approximately <code>n</code> ordered values, generated as follows:</p><p>(i) First, exactly <code>n</code> values are generated between <code>U</code> and <code>L</code>, with a spacing determined by <code>r.scale</code> (uniform if <code>scale=:linear</code>) where <code>U</code> and <code>L</code> are given by the following table:</p><table><tr><th style="text-align: right"><code>r.lower</code></th><th style="text-align: right"><code>r.upper</code></th><th style="text-align: right"><code>L</code></th><th style="text-align: right"><code>U</code></th></tr><tr><td style="text-align: right">finite</td><td style="text-align: right">finite</td><td style="text-align: right"><code>r.lower</code></td><td style="text-align: right"><code>r.upper</code></td></tr><tr><td style="text-align: right"><code>-Inf</code></td><td style="text-align: right">finite</td><td style="text-align: right"><code>r.upper - 2r.unit</code></td><td style="text-align: right"><code>r.upper</code></td></tr><tr><td style="text-align: right">finite</td><td style="text-align: right"><code>Inf</code></td><td style="text-align: right"><code>r.lower</code></td><td style="text-align: right"><code>r.lower + 2r.unit</code></td></tr><tr><td style="text-align: right"><code>-Inf</code></td><td style="text-align: right"><code>Inf</code></td><td style="text-align: right"><code>r.origin - r.unit</code></td><td style="text-align: right"><code>r.origin + r.unit</code></td></tr></table><p>(ii) If a callable <code>f</code> is provided as <code>scale</code>, then a uniform spacing is always applied in (i) but <code>f</code> is broadcast over the results. (Unlike ordinary scales, this alters the effective range of values generated, instead of just altering the spacing.)</p><p>(iii) If <code>r</code> is a discrete numeric range (<code>r isa NumericRange{&lt;:Integer}</code>) then the values are additionally rounded, with any duplicate values removed. Otherwise all the values are used (and there are exacltly <code>n</code> of them).</p><p>(iv) Finally, if a random number generator <code>rng</code> is specified, then the values are returned in random order (sampling without replacement), and otherwise they are returned in numeric order, or in the order provided to the range constructor, in the case of a <code>NominalRange</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Distributions.sampler" href="#Distributions.sampler"><code>Distributions.sampler</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">sampler(r::NominalRange, probs::AbstractVector{&lt;:Real})
sampler(r::NominalRange)
sampler(r::NumericRange{T}, d)</code></pre><p>Construct an object <code>s</code> which can be used to generate random samples from a <code>ParamRange</code> object <code>r</code> (a one-dimensional range) using one of the following calls:</p><pre><code class="language-none">rand(s)             # for one sample
rand(s, n)          # for n samples
rand(rng, s [, n])  # to specify an RNG</code></pre><p>The argument <code>probs</code> can be any probability vector with the same length as <code>r.values</code>. The second <code>sampler</code> method above calls the first with a uniform <code>probs</code> vector.</p><p>The argument <code>d</code> can be either an arbitrary instance of <code>UnivariateDistribution</code> from the Distributions.jl package, or one of a Distributions.jl <em>types</em> for which <code>fit(d, ::NumericRange)</code> is defined. These include: <code>Arcsine</code>, <code>Uniform</code>, <code>Biweight</code>, <code>Cosine</code>, <code>Epanechnikov</code>, <code>SymTriangularDist</code>, <code>Triweight</code>, <code>Normal</code>, <code>Gamma</code>, <code>InverseGaussian</code>, <code>Logistic</code>, <code>LogNormal</code>, <code>Cauchy</code>, <code>Gumbel</code>, <code>Laplace</code>, and <code>Poisson</code>; but see the doc-string for <a href="#StatsAPI.fit-Union{Tuple{D}, Tuple{Type{D}, MLJBase.NumericRange}} where D&lt;:Distributions.Distribution"><code>Distributions.fit</code></a> for an up-to-date list.</p><p>If <code>d</code> is an <em>instance</em>, then sampling is from a truncated form of the supplied distribution <code>d</code>, the truncation bounds being <code>r.lower</code> and <code>r.upper</code> (the attributes <code>r.origin</code> and <code>r.unit</code> attributes are ignored). For discrete numeric ranges (<code>T &lt;: Integer</code>) the samples are rounded.</p><p>If <code>d</code> is a <em>type</em> then a suitably truncated distribution is automatically generated using <code>Distributions.fit(d, r)</code>.</p><p><em>Important.</em> Values are generated with no regard to <code>r.scale</code>, except in the special case <code>r.scale</code> is a callable object <code>f</code>. In that case, <code>f</code> is applied to all values generated by <code>rand</code> as described above (prior to rounding, in the case of discrete numeric ranges).</p><p><strong>Examples</strong></p><pre><code class="language-none">r = range(Char, :letter, values=collect(&quot;abc&quot;))
s = sampler(r, [0.1, 0.2, 0.7])
samples =  rand(s, 1000);
StatsBase.countmap(samples)
Dict{Char,Int64} with 3 entries:
  &#39;a&#39; =&gt; 107
  &#39;b&#39; =&gt; 205
  &#39;c&#39; =&gt; 688

r = range(Int, :k, lower=2, upper=6) # numeric but discrete
s = sampler(r, Normal)
samples = rand(s, 1000);
UnicodePlots.histogram(samples)
           ┌                                        ┐
[2.0, 2.5) ┤▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 119
[2.5, 3.0) ┤ 0
[3.0, 3.5) ┤▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 296
[3.5, 4.0) ┤ 0
[4.0, 4.5) ┤▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 275
[4.5, 5.0) ┤ 0
[5.0, 5.5) ┤▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 221
[5.5, 6.0) ┤ 0
[6.0, 6.5) ┤▇▇▇▇▇▇▇▇▇▇▇ 89
           └                                        ┘</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="StatsAPI.fit-Union{Tuple{D}, Tuple{Type{D}, MLJBase.NumericRange}} where D&lt;:Distributions.Distribution" href="#StatsAPI.fit-Union{Tuple{D}, Tuple{Type{D}, MLJBase.NumericRange}} where D&lt;:Distributions.Distribution"><code>StatsAPI.fit</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Distributions.fit(D, r::MLJBase.NumericRange)</code></pre><p>Fit and return a distribution <code>d</code> of type <code>D</code> to the one-dimensional range <code>r</code>.</p><p>Only types <code>D</code> in the table below are supported.</p><p>The distribution <code>d</code> is constructed in two stages. First, a distributon <code>d0</code>, characterized by the conditions in the second column of the table, is fit to <code>r</code>. Then <code>d0</code> is truncated between <code>r.lower</code> and <code>r.upper</code> to obtain <code>d</code>.</p><table><tr><th style="text-align: left">Distribution type <code>D</code></th><th style="text-align: left">Characterization of <code>d0</code></th></tr><tr><td style="text-align: left"><code>Arcsine</code>, <code>Uniform</code>, <code>Biweight</code>, <code>Cosine</code>, <code>Epanechnikov</code>, <code>SymTriangularDist</code>, <code>Triweight</code></td><td style="text-align: left"><code>minimum(d) = r.lower</code>, <code>maximum(d) = r.upper</code></td></tr><tr><td style="text-align: left"><code>Normal</code>, <code>Gamma</code>, <code>InverseGaussian</code>, <code>Logistic</code>, <code>LogNormal</code></td><td style="text-align: left"><code>mean(d) = r.origin</code>, <code>std(d) = r.unit</code></td></tr><tr><td style="text-align: left"><code>Cauchy</code>, <code>Gumbel</code>, <code>Laplace</code>, (<code>Normal</code>)</td><td style="text-align: left"><code>Dist.location(d) = r.origin</code>, <code>Dist.scale(d)  = r.unit</code></td></tr><tr><td style="text-align: left"><code>Poisson</code></td><td style="text-align: left"><code>Dist.mean(d) = r.unit</code></td></tr></table><p>Here <code>Dist = Distributions</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJTuning.TunedModel" href="#MLJTuning.TunedModel"><code>MLJTuning.TunedModel</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">tuned_model = TunedModel(; model=&lt;model to be mutated&gt;,
                         tuning=RandomSearch(),
                         resampling=Holdout(),
                         range=nothing,
                         measure=nothing,
                         n=default_n(tuning, range),
                         operation=nothing,
                         other_options...)</code></pre><p>Construct a model wrapper for hyper-parameter optimization of a supervised learner, specifying the <code>tuning</code> strategy and <code>model</code> whose hyper-parameters are to be mutated.</p><pre><code class="language-none">tuned_model = TunedModel(; models=&lt;models to be compared&gt;,
                         resampling=Holdout(),
                         measure=nothing,
                         n=length(models),
                         operation=nothing,
                         other_options...)</code></pre><p>Construct a wrapper for multiple <code>models</code>, for selection of an optimal one (equivalent to specifying <code>tuning=Explicit()</code> and <code>range=models</code> above). Elements of the iterator <code>models</code> need not have a common type, but they must all be <code>Deterministic</code> or all be <code>Probabilistic</code> <em>and this is not checked</em> but inferred from the first element generated.</p><p>See below for a complete list of options.</p><p><strong>Training</strong></p><p>Calling <code>fit!(mach)</code> on a machine <code>mach=machine(tuned_model, X, y)</code> or <code>mach=machine(tuned_model, X, y, w)</code> will:</p><ul><li><p>Instigate a search, over clones of <code>model</code>, with the hyperparameter mutations specified by <code>range</code>, for a model optimizing the specified <code>measure</code>, using performance evaluations carried out using the specified <code>tuning</code> strategy and <code>resampling</code> strategy. In the case <code>models</code> is explictly listed, the search is instead over the models generated by the iterator <code>models</code>.</p></li><li><p>Fit an internal machine, based on the optimal model <code>fitted_params(mach).best_model</code>, wrapping the optimal <code>model</code> object in <em>all</em> the provided data <code>X</code>, <code>y</code>(, <code>w</code>). Calling <code>predict(mach, Xnew)</code> then returns predictions on <code>Xnew</code> of this internal machine. The final train can be supressed by setting <code>train_best=false</code>.</p></li></ul><p><strong>Search space</strong></p><p>The <code>range</code> objects supported depend on the <code>tuning</code> strategy specified. Query the <code>strategy</code> docstring for details. To optimize over an explicit list <code>v</code> of models of the same type, use <code>strategy=Explicit()</code> and specify <code>model=v[1]</code> and <code>range=v</code>.</p><p>The number of models searched is specified by <code>n</code>. If unspecified, then <code>MLJTuning.default_n(tuning, range)</code> is used. When <code>n</code> is increased and <code>fit!(mach)</code> called again, the old search history is re-instated and the search continues where it left off.</p><p><strong>Measures (metrics)</strong></p><p>If more than one <code>measure</code> is specified, then only the first is optimized (unless <code>strategy</code> is multi-objective) but the performance against every measure specified will be computed and reported in <code>report(mach).best_performance</code> and other relevant attributes of the generated report. Options exist to pass per-observation weights or class weights to measures; see below.</p><p><em>Important.</em> If a custom measure, <code>my_measure</code> is used, and the measure is a score, rather than a loss, be sure to check that <code>MLJ.orientation(my_measure) == :score</code> to ensure maximization of the measure, rather than minimization. Override an incorrect value with <code>MLJ.orientation(::typeof(my_measure)) = :score</code>.</p><p><strong>Accessing the fitted parameters and other training (tuning) outcomes</strong></p><p>A Plots.jl plot of performance estimates is returned by <code>plot(mach)</code> or <code>heatmap(mach)</code>.</p><p>Once a tuning machine <code>mach</code> has bee trained as above, then <code>fitted_params(mach)</code> has these keys/values:</p><table><tr><th style="text-align: right">key</th><th style="text-align: right">value</th></tr><tr><td style="text-align: right"><code>best_model</code></td><td style="text-align: right">optimal model instance</td></tr><tr><td style="text-align: right"><code>best_fitted_params</code></td><td style="text-align: right">learned parameters of the optimal model</td></tr></table><p>The named tuple <code>report(mach)</code> includes these keys/values:</p><table><tr><th style="text-align: right">key</th><th style="text-align: right">value</th></tr><tr><td style="text-align: right"><code>best_model</code></td><td style="text-align: right">optimal model instance</td></tr><tr><td style="text-align: right"><code>best_history_entry</code></td><td style="text-align: right">corresponding entry in the history, including performance estimate</td></tr><tr><td style="text-align: right"><code>best_report</code></td><td style="text-align: right">report generated by fitting the optimal model to all data</td></tr><tr><td style="text-align: right"><code>history</code></td><td style="text-align: right">tuning strategy-specific history of all evaluations</td></tr></table><p>plus other key/value pairs specific to the <code>tuning</code> strategy.</p><p><strong>Complete list of key-word options</strong></p><ul><li><p><code>model</code>: <code>Supervised</code> model prototype that is cloned and mutated to generate models for evaluation</p></li><li><p><code>models</code>: Alternatively, an iterator of MLJ models to be explicitly evaluated. These may have varying types.</p></li><li><p><code>tuning=RandomSearch()</code>: tuning strategy to be applied (eg, <code>Grid()</code>). See the <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/tuning_models/#Tuning-Models">Tuning Models</a> section of the MLJ manual for a complete list of options.</p></li><li><p><code>resampling=Holdout()</code>: resampling strategy (eg, <code>Holdout()</code>, <code>CV()</code>), <code>StratifiedCV()</code>) to be applied in performance evaluations</p></li><li><p><code>measure</code>: measure or measures to be applied in performance evaluations; only the first used in optimization (unless the strategy is multi-objective) but all reported to the history</p></li><li><p><code>weights</code>: per-observation weights to be passed the measure(s) in performance evaluations, where supported. Check support with <code>supports_weights(measure)</code>.</p></li><li><p><code>class_weights</code>: class weights to be passed the measure(s) in performance evaluations, where supported. Check support with <code>supports_class_weights(measure)</code>.</p></li><li><p><code>repeats=1</code>: for generating train/test sets multiple times in resampling (&quot;Monte Carlo&quot; resampling); see <a href="../evaluating_model_performance/#MLJBase.evaluate!"><code>evaluate!</code></a> for details</p></li><li><p><code>operation</code>/<code>operations</code> - One of <code>predict</code>, <code>predict_mean</code>, <code>predict_mode</code>, <code>predict_median</code>, or <code>predict_joint</code>, or a vector of these of the same length as <code>measure</code>/<code>measures</code>. Automatically inferred if left unspecified.</p></li><li><p><code>range</code>: range object; tuning strategy documentation describes supported types</p></li><li><p><code>selection_heuristic</code>: the rule determining how the best model is decided. According to the default heuristic, <code>NaiveSelection()</code>, <code>measure</code> (or the first element of <code>measure</code>) is evaluated for each resample and these per-fold measurements are aggregrated. The model with the lowest (resp. highest) aggregate is chosen if the measure is a <code>:loss</code> (resp. a <code>:score</code>).</p></li><li><p><code>n</code>: number of iterations (ie, models to be evaluated); set by tuning strategy if left unspecified</p></li><li><p><code>train_best=true</code>: whether to train the optimal model</p></li><li><p><code>acceleration=default_resource()</code>: mode of parallelization for tuning strategies that support this</p></li><li><p><code>acceleration_resampling=CPU1()</code>: mode of parallelization for resampling</p></li><li><p><code>check_measure=true</code>: whether to check <code>measure</code> is compatible with the specified <code>model</code> and <code>operation</code>)</p></li><li><p><code>cache=true</code>: whether to cache model-specific representations of user-suplied data; set to <code>false</code> to conserve memory. Speed gains likely limited to the case <code>resampling isa Holdout</code>.</p></li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJTuning.Grid" href="#MLJTuning.Grid"><code>MLJTuning.Grid</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Grid(goal=nothing, resolution=10, rng=Random.GLOBAL_RNG, shuffle=true)</code></pre><p>Instantiate a Cartesian grid-based hyperparameter tuning strategy with a specified number of grid points as <code>goal</code>, or using a specified default <code>resolution</code> in each numeric dimension.</p><p><strong>Supported ranges:</strong></p><p>A single one-dimensional range or vector of one-dimensioinal ranges can be specified. Specifically, in <code>Grid</code> search, the <code>range</code> field of a <code>TunedModel</code> instance can be:</p><ul><li><p>A single one-dimensional range - ie, <code>ParamRange</code> object - <code>r</code>, or pair of the form <code>(r, res)</code> where <code>res</code> specifies a resolution to override the default <code>resolution</code>.</p></li><li><p>Any vector of objects of the above form</p></li></ul><p>Two elements of a <code>range</code> vector may share the same <code>field</code> attribute, with the effect that their grids are combined, as in Example 3 below.</p><p><code>ParamRange</code> objects are constructed using the <code>range</code> method.</p><p>Example 1:</p><pre><code class="language-none">range(model, :hyper1, lower=1, origin=2, unit=1)</code></pre><p>Example 2:</p><pre><code class="language-none">[(range(model, :hyper1, lower=1, upper=10), 15),
  range(model, :hyper2, lower=2, upper=4),
  range(model, :hyper3, values=[:ball, :tree])]</code></pre><p>Example 3:</p><pre><code class="language-none"># a range generating the grid `[1, 2, 10, 20, 30]` for `:hyper1`:
[range(model, :hyper1, values=[1, 2]),
 (range(model, :hyper1, lower= 10, upper=30), 3)]</code></pre><p>Note: All the <code>field</code> values of the <code>ParamRange</code> objects (<code>:hyper1</code>, <code>:hyper2</code>, <code>:hyper3</code> in the preceding example) must refer to field names a of single model (the <code>model</code> specified during <code>TunedModel</code> construction).</p><p><strong>Algorithm</strong></p><p>This is a standard grid search with the following specifics: In all cases all <code>values</code> of each specified <code>NominalRange</code> are exhausted. If <code>goal</code> is specified, then all resolutions are ignored, and a global resolution is applied to the <code>NumericRange</code> objects that maximizes the number of grid points, subject to the restriction that this not exceed <code>goal</code>. (This assumes no field appears twice in the <code>range</code> vector.) Otherwise the default <code>resolution</code> and any parameter-specific resolutions apply.</p><p>In all cases the models generated are shuffled using <code>rng</code>, unless <code>shuffle=false</code>.</p><p>See also <a href="#MLJTuning.TunedModel"><code>TunedModel</code></a>, <a href="#Base.range"><code>range</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJTuning.RandomSearch" href="#MLJTuning.RandomSearch"><code>MLJTuning.RandomSearch</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">RandomSearch(bounded=Distributions.Uniform,
             positive_unbounded=Distributions.Gamma,
             other=Distributions.Normal,
             rng=Random.GLOBAL_RNG)</code></pre><p>Instantiate a random search tuning strategy, for searching over Cartesian hyperparameter domains, with customizable priors in each dimension.</p><p><strong>Supported ranges</strong></p><p>A single one-dimensional range or vector of one-dimensioinal ranges can be specified. If not paired with a prior, then one is fitted, according to fallback distribution types specified by the tuning strategy hyperparameters. Specifically, in <code>RandomSearch</code>, the <code>range</code> field of a <code>TunedModel</code> instance can be:</p><ul><li><p>a single one-dimensional range (<code>ParamRange</code> object) <code>r</code></p></li><li><p>a pair of the form <code>(r, d)</code>, with <code>r</code> as above and where <code>d</code> is:</p><ul><li><p>a probability vector of the same length as <code>r.values</code> (<code>r</code> a <code>NominalRange</code>)</p></li><li><p>any <code>Distributions.UnivariateDistribution</code> <em>instance</em> (<code>r</code> a <code>NumericRange</code>)</p></li><li><p>one of the <em>subtypes</em> of <code>Distributions.UnivariateDistribution</code> listed in the table below, for automatic fitting using <code>Distributions.fit(d, r)</code>, a distribution whose support always lies between <code>r.lower</code> and <code>r.upper</code> (<code>r</code> a <code>NumericRange</code>)</p></li></ul></li><li><p>any pair of the form <code>(field, s)</code>, where <code>field</code> is the (possibly nested) name of a field of the model to be tuned, and <code>s</code> an arbitrary sampler object for that field. This means only that <code>rand(rng, s)</code> is defined and returns valid values for the field.</p></li><li><p>any vector of objects of the above form</p></li></ul><p>A range vector may contain multiple entries for the same model field, as in <code>range = [(:lambda, s1), (:alpha, s), (:lambda, s2)]</code>. In that case the entry used in each iteration is random.</p><table><tr><th style="text-align: right">distribution types</th><th style="text-align: right">for fitting to ranges of this type</th></tr><tr><td style="text-align: right"><code>Arcsine</code>, <code>Uniform</code>, <code>Biweight</code>, <code>Cosine</code>, <code>Epanechnikov</code>, <code>SymTriangularDist</code>, <code>Triweight</code></td><td style="text-align: right">bounded</td></tr><tr><td style="text-align: right"><code>Gamma</code>, <code>InverseGaussian</code>, <code>Poisson</code></td><td style="text-align: right">positive (bounded or unbounded)</td></tr><tr><td style="text-align: right"><code>Normal</code>, <code>Logistic</code>, <code>LogNormal</code>, <code>Cauchy</code>, <code>Gumbel</code>, <code>Laplace</code></td><td style="text-align: right">any</td></tr></table><p><code>ParamRange</code> objects are constructed using the <code>range</code> method.</p><p><strong>Examples</strong></p><pre><code class="language-none">using Distributions

range1 = range(model, :hyper1, lower=0, upper=1)

range2 = [(range(model, :hyper1, lower=1, upper=10), Arcsine),
          range(model, :hyper2, lower=2, upper=Inf, unit=1, origin=3),
          (range(model, :hyper2, lower=2, upper=4), Normal(0, 3)),
          (range(model, :hyper3, values=[:ball, :tree]), [0.3, 0.7])]

# uniform sampling of :(atom.λ) from [0, 1] without defining a NumericRange:
struct MySampler end
Base.rand(rng::Random.AbstractRNG, ::MySampler) = rand(rng)
range3 = (:(atom.λ), MySampler())</code></pre><p><strong>Algorithm</strong></p><p>In each iteration, a model is generated for evaluation by mutating the fields of a deep copy of <code>model</code>. The range vector is shuffled and the fields sampled according to the new order (repeated fields being mutated more than once). For a <code>range</code> entry of the form <code>(field, s)</code> the algorithm calls <code>rand(rng, s)</code> and mutates the field <code>field</code> of the model clone to have this value. For an entry of the form <code>(r, d)</code>, <code>s</code> is substituted with <code>sampler(r, d)</code>. If no <code>d</code> is specified, then sampling is uniform (with replacement) if <code>r</code> is a <code>NominalRange</code>, and is otherwise given by the defaults specified by the tuning strategy parameters <code>bounded</code>, <code>positive_unbounded</code>, and <code>other</code>, depending on the field values of the <code>NumericRange</code> object <code>r</code>.</p><p>See also <a href="#MLJTuning.TunedModel"><code>TunedModel</code></a>, <a href="#Base.range"><code>range</code></a>, <a href="#Distributions.sampler"><code>sampler</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJTuning.LatinHypercube" href="#MLJTuning.LatinHypercube"><code>MLJTuning.LatinHypercube</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">LatinHypercube(gens = 1,
               popsize = 100,
               ntour = 2,
               ptour = 0.8.,
               interSampleWeight = 1.0,
               ae_power = 2,
               periodic_ae = false,
               rng=Random.GLOBAL_RNG)</code></pre><p>Instantiate grid-based hyperparameter tuning strategy using the library <a href="https://github.com/MrUrq/LatinHypercubeSampling.jl">LatinHypercubeSampling.jl</a>.</p><p>An optimised Latin Hypercube sampling plan is created using a genetic based optimization algorithm based on the inverse of the Audze-Eglais function.  The optimization is run for <code>nGenerations</code> and creates <code>n</code> models for evaluation, where <code>n</code> is specified by a corresponding <code>TunedModel</code> instance, as in</p><pre><code class="language-none">tuned_model = TunedModel(model=...,
                         tuning=LatinHypercube(...),
                         range=...,
                         measures=...,
                         n=...)</code></pre><p>(See <a href="#MLJTuning.TunedModel"><code>TunedModel</code></a> for complete options.)</p><p>To use a periodic version of the Audze-Eglais function (to reduce clustering along the boundaries) specify <code>periodic_ae = true</code>.</p><p><strong>Supported ranges:</strong></p><p>A single one-dimensional range or vector of one-dimensioinal ranges can be specified. Specifically, in <code>LatinHypercubeSampling</code> search, the <code>range</code> field of a <code>TunedModel</code> instance can be:</p><ul><li>A single one-dimensional range - ie, <code>ParamRange</code> object - <code>r</code>, constructed</li></ul><p>using the <code>range</code> method.</p><ul><li>Any vector of objects of the above form</li></ul><p>Both <code>NumericRange</code>s and <code>NominalRange</code>s are supported, and hyper-parameter values are sampled on a scale specified by the range (eg, <code>r.scale = :log</code>).</p></div></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../weights/">« Weights</a><a class="docs-footer-nextpage" href="../learning_curves/">Learning Curves »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 7 November 2022 23:07">Monday 7 November 2022</span>. Using Julia version 1.8.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
