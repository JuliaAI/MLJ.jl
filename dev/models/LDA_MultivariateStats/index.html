<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>LDA · MLJ</title><meta name="title" content="LDA · MLJ"/><meta property="og:title" content="LDA · MLJ"/><meta property="twitter:title" content="LDA · MLJ"/><meta name="description" content="Documentation for MLJ."/><meta property="og:description" content="Documentation for MLJ."/><meta property="twitter:description" content="Documentation for MLJ."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="MLJ logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">MLJ</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../model_browser/">Model Browser</a></li><li><a class="tocitem" href="../../about_mlj/">About MLJ</a></li><li><a class="tocitem" href="../../learning_mlj/">Learning MLJ</a></li><li><a class="tocitem" href="../../getting_started/">Getting Started</a></li><li><a class="tocitem" href="../../common_mlj_workflows/">Common MLJ Workflows</a></li><li><a class="tocitem" href="../../working_with_categorical_data/">Working with Categorical Data</a></li><li><a class="tocitem" href="../../model_search/">Model Search</a></li><li><a class="tocitem" href="../../loading_model_code/">Loading Model Code</a></li><li><a class="tocitem" href="../../machines/">Machines</a></li><li><a class="tocitem" href="../../evaluating_model_performance/">Evaluating Model Performance</a></li><li><a class="tocitem" href="../../performance_measures/">Performance Measures</a></li><li><a class="tocitem" href="../../weights/">Weights</a></li><li><a class="tocitem" href="../../tuning_models/">Tuning Models</a></li><li><a class="tocitem" href="../../learning_curves/">Learning Curves</a></li><li><a class="tocitem" href="../../preparing_data/">Preparing Data</a></li><li><a class="tocitem" href="../../transformers/">Transformers and Other Unsupervised models</a></li><li><a class="tocitem" href="../../more_on_probabilistic_predictors/">More on Probabilistic Predictors</a></li><li><a class="tocitem" href="../../composing_models/">Composing Models</a></li><li><a class="tocitem" href="../../linear_pipelines/">Linear Pipelines</a></li><li><a class="tocitem" href="../../target_transformations/">Target Transformations</a></li><li><a class="tocitem" href="../../homogeneous_ensembles/">Homogeneous Ensembles</a></li><li><a class="tocitem" href="../../correcting_class_imbalance/">Correcting Class Imbalance</a></li><li><a class="tocitem" href="../../model_stacking/">Model Stacking</a></li><li><a class="tocitem" href="../../learning_networks/">Learning Networks</a></li><li><a class="tocitem" href="../../controlling_iterative_models/">Controlling Iterative Models</a></li><li><a class="tocitem" href="../../generating_synthetic_data/">Generating Synthetic Data</a></li><li><a class="tocitem" href="../../logging_workflows/">Logging Workflows</a></li><li><a class="tocitem" href="../../openml_integration/">OpenML Integration</a></li><li><a class="tocitem" href="../../acceleration_and_parallelism/">Acceleration and Parallelism</a></li><li><a class="tocitem" href="../../simple_user_defined_models/">Simple User Defined Models</a></li><li><a class="tocitem" href="../../quick_start_guide_to_adding_models/">Quick-Start Guide to Adding Models</a></li><li><a class="tocitem" href="../../adding_models_for_general_use/">Adding Models for General Use</a></li><li><a class="tocitem" href="../../modifying_behavior/">Modifying Behavior</a></li><li><a class="tocitem" href="../../internals/">Internals</a></li><li><a class="tocitem" href="../../list_of_supported_models/">List of Supported Models</a></li><li><a class="tocitem" href="../../third_party_packages/">Third Party Packages</a></li><li><a class="tocitem" href="../../glossary/">Glossary</a></li><li><a class="tocitem" href="../../mlj_cheatsheet/">MLJ Cheatsheet</a></li><li><a class="tocitem" href="../../frequently_asked_questions/">FAQ</a></li><li><a class="tocitem" href="../../api/">Index of Methods</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>LDA</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>LDA</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/alan-turing-institute/MLJ.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/alan-turing-institute/MLJ.jl/blob/dev/docs/src/models/LDA_MultivariateStats.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="LDA_MultivariateStats"><a class="docs-heading-anchor" href="#LDA_MultivariateStats">LDA</a><a id="LDA_MultivariateStats-1"></a><a class="docs-heading-anchor-permalink" href="#LDA_MultivariateStats" title="Permalink"></a></h1><pre><code class="nohighlight hljs">LDA</code></pre><p>A model type for constructing a linear discriminant analysis model, based on <a href="https://github.com/JuliaStats/MultivariateStats.jl">MultivariateStats.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">LDA = @load LDA pkg=MultivariateStats</code></pre><p>Do <code>model = LDA()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>LDA(method=...)</code>.</p><p><a href="https://en.wikipedia.org/wiki/Linear_discriminant_analysis">Multiclass linear discriminant analysis</a> learns a projection in a space of features to a lower dimensional space, in a way that attempts to preserve as much as possible the degree to which the classes of a discrete target variable can be discriminated. This can be used either for dimension reduction of the features (see <code>transform</code> below) or for probabilistic classification of the target (see <code>predict</code> below).</p><p>In the case of prediction, the class probability for a new observation reflects the proximity of that observation to training observations associated with that class, and how far away the observation is from observations associated with other classes. Specifically, the distances, in the transformed (projected) space, of a new observation, from the centroid of each target class, is computed; the resulting vector of distances, multiplied by minus one, is passed to a softmax function to obtain a class probability prediction. Here &quot;distance&quot; is computed using a user-specified distance function.</p><h2 id="Training-data"><a class="docs-heading-anchor" href="#Training-data">Training data</a><a id="Training-data-1"></a><a class="docs-heading-anchor-permalink" href="#Training-data" title="Permalink"></a></h2><p>In MLJ or MLJBase, bind an instance <code>model</code> to data with</p><pre><code class="nohighlight hljs">mach = machine(model, X, y)</code></pre><p>Here:</p><ul><li><code>X</code> is any table of input features (eg, a <code>DataFrame</code>) whose columns are of scitype <code>Continuous</code>; check column scitypes with <code>schema(X)</code>.</li><li><code>y</code> is the target, which can be any <code>AbstractVector</code> whose element scitype is <code>OrderedFactor</code> or <code>Multiclass</code>; check the scitype with <code>scitype(y)</code></li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><h2 id="Hyper-parameters"><a class="docs-heading-anchor" href="#Hyper-parameters">Hyper-parameters</a><a id="Hyper-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Hyper-parameters" title="Permalink"></a></h2><ul><li><code>method::Symbol=:gevd</code>: The solver, one of <code>:gevd</code> or <code>:whiten</code> methods.</li><li><code>cov_w::StatsBase.SimpleCovariance()</code>: An estimator for the within-class covariance (used in computing the within-class scatter matrix, <code>Sw</code>). Any robust estimator from <code>CovarianceEstimation.jl</code> can be used.</li><li><code>cov_b::StatsBase.SimpleCovariance()</code>: The same as <code>cov_w</code> but for the between-class covariance (used in computing the between-class scatter matrix, <code>Sb</code>).</li><li><code>outdim::Int=0</code>: The output dimension, i.e dimension of the transformed space, automatically set to <code>min(indim, nclasses-1)</code> if equal to 0.</li><li><code>regcoef::Float64=1e-6</code>: The regularization coefficient. A positive value <code>regcoef*eigmax(Sw)</code> where <code>Sw</code> is the within-class scatter matrix, is added to the diagonal of <code>Sw</code> to improve numerical stability. This can be useful if using the standard covariance estimator.</li><li><code>dist=Distances.SqEuclidean()</code>: The distance metric to use when performing classification (to compare the distance between a new point and centroids in the transformed space); must be a subtype of <code>Distances.SemiMetric</code> from Distances.jl, e.g., <code>Distances.CosineDist</code>.</li></ul><h2 id="Operations"><a class="docs-heading-anchor" href="#Operations">Operations</a><a id="Operations-1"></a><a class="docs-heading-anchor-permalink" href="#Operations" title="Permalink"></a></h2><ul><li><code>transform(mach, Xnew)</code>: Return a lower dimensional projection of the input <code>Xnew</code>, which should have the same scitype as <code>X</code> above.</li><li><code>predict(mach, Xnew)</code>: Return predictions of the target given features <code>Xnew</code> having the same scitype as <code>X</code> above. Predictions are probabilistic but uncalibrated.</li><li><code>predict_mode(mach, Xnew)</code>: Return the modes of the probabilistic predictions returned above.</li></ul><h2 id="Fitted-parameters"><a class="docs-heading-anchor" href="#Fitted-parameters">Fitted parameters</a><a id="Fitted-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Fitted-parameters" title="Permalink"></a></h2><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><code>classes</code>: The classes seen during model fitting.</li><li><code>projection_matrix</code>: The learned projection matrix, of size <code>(indim, outdim)</code>, where <code>indim</code> and <code>outdim</code> are the input and output dimensions respectively (See Report section below).</li></ul><h2 id="Report"><a class="docs-heading-anchor" href="#Report">Report</a><a id="Report-1"></a><a class="docs-heading-anchor-permalink" href="#Report" title="Permalink"></a></h2><p>The fields of <code>report(mach)</code> are:</p><ul><li><code>indim</code>: The dimension of the input space i.e the number of training features.</li><li><code>outdim</code>: The dimension of the transformed space the model is projected to.</li><li><code>mean</code>: The mean of the untransformed training data. A vector of length <code>indim</code>.</li><li><code>nclasses</code>: The number of classes directly observed in the training data (which can be less than the total number of classes in the class pool).</li><li><code>class_means</code>: The class-specific means of the training data. A matrix of size <code>(indim, nclasses)</code> with the ith column being the class-mean of the ith class in <code>classes</code> (See fitted params section above).</li><li><code>class_weights</code>: The weights (class counts) of each class. A vector of length <code>nclasses</code> with the ith element being the class weight of the ith class in <code>classes</code>. (See fitted params section above.)</li><li><code>Sb</code>: The between class scatter matrix.</li><li><code>Sw</code>: The within class scatter matrix.</li></ul><h2 id="Examples"><a class="docs-heading-anchor" href="#Examples">Examples</a><a id="Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Examples" title="Permalink"></a></h2><pre><code class="nohighlight hljs">using MLJ

LDA = @load LDA pkg=MultivariateStats

X, y = @load_iris ## a table and a vector

model = LDA()
mach = machine(model, X, y) |&gt; fit!

Xproj = transform(mach, X)
y_hat = predict(mach, X)
labels = predict_mode(mach, X)
</code></pre><p>See also <code>BayesianLDA</code>, <code>SubspaceLDA</code>, <code>BayesianSubspaceLDA</code></p></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Wednesday 17 January 2024 02:56">Wednesday 17 January 2024</span>. Using Julia version 1.10.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
