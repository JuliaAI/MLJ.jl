<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Controlling Iterative Models · MLJ</title><meta name="title" content="Controlling Iterative Models · MLJ"/><meta property="og:title" content="Controlling Iterative Models · MLJ"/><meta property="twitter:title" content="Controlling Iterative Models · MLJ"/><meta name="description" content="Documentation for MLJ."/><meta property="og:description" content="Documentation for MLJ."/><meta property="twitter:description" content="Documentation for MLJ."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="MLJ logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">MLJ</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../model_browser/">Model Browser</a></li><li><a class="tocitem" href="../about_mlj/">About MLJ</a></li><li><a class="tocitem" href="../learning_mlj/">Learning MLJ</a></li><li><a class="tocitem" href="../getting_started/">Getting Started</a></li><li><a class="tocitem" href="../common_mlj_workflows/">Common MLJ Workflows</a></li><li><a class="tocitem" href="../working_with_categorical_data/">Working with Categorical Data</a></li><li><a class="tocitem" href="../model_search/">Model Search</a></li><li><a class="tocitem" href="../loading_model_code/">Loading Model Code</a></li><li><a class="tocitem" href="../machines/">Machines</a></li><li><a class="tocitem" href="../evaluating_model_performance/">Evaluating Model Performance</a></li><li><a class="tocitem" href="../performance_measures/">Performance Measures</a></li><li><a class="tocitem" href="../weights/">Weights</a></li><li><a class="tocitem" href="../tuning_models/">Tuning Models</a></li><li><a class="tocitem" href="../learning_curves/">Learning Curves</a></li><li><a class="tocitem" href="../preparing_data/">Preparing Data</a></li><li><a class="tocitem" href="../transformers/">Transformers and Other Unsupervised models</a></li><li><a class="tocitem" href="../more_on_probabilistic_predictors/">More on Probabilistic Predictors</a></li><li><a class="tocitem" href="../composing_models/">Composing Models</a></li><li><a class="tocitem" href="../linear_pipelines/">Linear Pipelines</a></li><li><a class="tocitem" href="../target_transformations/">Target Transformations</a></li><li><a class="tocitem" href="../homogeneous_ensembles/">Homogeneous Ensembles</a></li><li><a class="tocitem" href="../correcting_class_imbalance/">Correcting Class Imbalance</a></li><li><a class="tocitem" href="../model_stacking/">Model Stacking</a></li><li><a class="tocitem" href="../learning_networks/">Learning Networks</a></li><li class="is-active"><a class="tocitem" href>Controlling Iterative Models</a><ul class="internal"><li><a class="tocitem" href="#Basic-use"><span>Basic use</span></a></li><li><a class="tocitem" href="#Controls-provided"><span>Controls provided</span></a></li><li><a class="tocitem" href="#Using-training-losses,-and-controlling-model-tuning"><span>Using training losses, and controlling model tuning</span></a></li><li><a class="tocitem" href="#Custom-controls"><span>Custom controls</span></a></li><li><a class="tocitem" href="#API-Reference"><span>API Reference</span></a></li></ul></li><li><a class="tocitem" href="../generating_synthetic_data/">Generating Synthetic Data</a></li><li><a class="tocitem" href="../logging_workflows/">Logging Workflows</a></li><li><a class="tocitem" href="../openml_integration/">OpenML Integration</a></li><li><a class="tocitem" href="../acceleration_and_parallelism/">Acceleration and Parallelism</a></li><li><a class="tocitem" href="../simple_user_defined_models/">Simple User Defined Models</a></li><li><a class="tocitem" href="../quick_start_guide_to_adding_models/">Quick-Start Guide to Adding Models</a></li><li><a class="tocitem" href="../adding_models_for_general_use/">Adding Models for General Use</a></li><li><a class="tocitem" href="../modifying_behavior/">Modifying Behavior</a></li><li><a class="tocitem" href="../internals/">Internals</a></li><li><a class="tocitem" href="../list_of_supported_models/">List of Supported Models</a></li><li><a class="tocitem" href="../third_party_packages/">Third Party Packages</a></li><li><a class="tocitem" href="../glossary/">Glossary</a></li><li><a class="tocitem" href="../mlj_cheatsheet/">MLJ Cheatsheet</a></li><li><a class="tocitem" href="../frequently_asked_questions/">FAQ</a></li><li><a class="tocitem" href="../api/">Index of Methods</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Controlling Iterative Models</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Controlling Iterative Models</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/alan-turing-institute/MLJ.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/alan-turing-institute/MLJ.jl/blob/dev/docs/src/controlling_iterative_models.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Controlling-Iterative-Models"><a class="docs-heading-anchor" href="#Controlling-Iterative-Models">Controlling Iterative Models</a><a id="Controlling-Iterative-Models-1"></a><a class="docs-heading-anchor-permalink" href="#Controlling-Iterative-Models" title="Permalink"></a></h1><p>Iterative supervised machine learning models are usually trained until an out-of-sample estimate of the performance satisfies some stopping criterion, such as <code>k</code> consecutive deteriorations of the performance (see <a href="#EarlyStopping.Patience"><code>Patience</code></a> below). A more sophisticated kind of control might dynamically mutate parameters, such as a learning rate, in response to the behavior of these estimates.</p><p>Some iterative model implementations enable some form of automated control, with the method and options for doing so varying from model to model. But sometimes it is up to the user to arrange control, which in the crudest case reduces to manually experimenting with the iteration parameter.</p><p>In response to this ad hoc state of affairs, MLJ provides a uniform and feature-rich interface for controlling any iterative model that exposes its iteration parameter as a hyper-parameter, and which implements the &quot;warm restart&quot; behavior described in <a href="../machines/#Machines">Machines</a>.</p><h2 id="Basic-use"><a class="docs-heading-anchor" href="#Basic-use">Basic use</a><a id="Basic-use-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-use" title="Permalink"></a></h2><p>As in <a href="../tuning_models/#Tuning-Models">Tuning Models</a>, iteration control in MLJ is implemented as a model wrapper, which allows composition with other meta-algorithms. Ordinarily, the wrapped model behaves just like the original model, but with the training occurring on a subset of the provided data (to allow computation of an out-of-sample loss) and with the iteration parameter automatically determined by the controls specified in the wrapper.</p><p>By setting <code>retrain=true</code> one can ask that the wrapped model retrain on <em>all</em> supplied data, after learning the appropriate number of iterations from the controlled training phase:</p><pre><code class="language-julia hljs">using MLJ

X, y = make_moons(100, rng=123, noise=0.5)
EvoTreeClassifier = @load EvoTreeClassifier verbosity=0

iterated_model = IteratedModel(model=EvoTreeClassifier(rng=123, eta=0.005),
                               resampling=Holdout(),
                               measures=log_loss,
                               controls=[Step(5),
                                         Patience(2),
                                         NumberLimit(100)],
                               retrain=true)

mach = machine(iterated_model, X, y)</code></pre><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; fit!(mach)</code><code class="nohighlight hljs ansi" style="display:block;">┌ Info: Training machine(ProbabilisticIteratedModel(model = EvoTrees.EvoTreeClassifier{EvoTrees.MLogLoss}
│  - nrounds: 100
│  - L2: 0.0
│  - lambda: 0.0
│  - gamma: 0.0
│  - eta: 0.005
│  - max_depth: 6
│  - min_weight: 1.0
│  - rowsample: 1.0
│  - colsample: 1.0
│  - nbins: 64
│  - alpha: 0.5
│  - tree_type: binary
│  - rng: Random.MersenneTwister(123)
└ , …), …).
[ Info: No iteration parameter specified. Using `iteration_parameter=:(nrounds)`. 
[ Info: final loss: 0.46683584745719836
[ Info: Stop triggered by Patience(2) stopping criterion. 
[ Info: Retraining on all provided data. To suppress, specify `retrain=false`. 
[ Info: Total of 215 iterations. 
trained Machine; does not cache data
  model: ProbabilisticIteratedModel(model = EvoTrees.EvoTreeClassifier{EvoTrees.MLogLoss}
 - nrounds: 100
 - L2: 0.0
 - lambda: 0.0
 - gamma: 0.0
 - eta: 0.005
 - max_depth: 6
 - min_weight: 1.0
 - rowsample: 1.0
 - colsample: 1.0
 - nbins: 64
 - alpha: 0.5
 - tree_type: binary
 - rng: Random.MersenneTwister(123)
, …)
  args:
    1:	Source @526 ⏎ Table{AbstractVector{Continuous}}
    2:	Source @507 ⏎ AbstractVector{Multiclass{2}}</code></pre><p>As detailed under <a href="#MLJIteration.IteratedModel"><code>IteratedModel</code></a> below, the specified <code>controls</code> are repeatedly applied in sequence to a <em>training machine</em>, constructed under the hood, until one of the controls triggers a stop. Here <code>Step(5)</code> means &quot;Compute 5 more iterations&quot; (in this case starting from none); <code>Patience(2)</code> means &quot;Stop at the end of the control cycle if there have been 2 consecutive drops in the log loss&quot;; and <code>NumberLimit(100)</code> is a safeguard ensuring a stop after 100 control cycles (500 iterations). See <a href="#Controls-provided">Controls provided</a> below for a complete list.</p><p>Because iteration is implemented as a wrapper, the &quot;self-iterating&quot; model can be evaluated using cross-validation, say, and the number of iterations on each fold will generally be different:</p><pre><code class="language-julia hljs">e = evaluate!(mach, resampling=CV(nfolds=3), measure=log_loss, verbosity=0);
map(e.report_per_fold) do r
    r.n_iterations
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3-element Vector{Int64}:
 340
 150
 500</code></pre><p>Alternatively, one might wrap the self-iterating model in a tuning strategy, using <code>TunedModel</code>; see <a href="../tuning_models/#Tuning-Models">Tuning Models</a>. In this way, the optimization of some other hyper-parameter is realized simultaneously with that of the iteration parameter, which will frequently be more efficient than a direct two-parameter search.</p><h2 id="Controls-provided"><a class="docs-heading-anchor" href="#Controls-provided">Controls provided</a><a id="Controls-provided-1"></a><a class="docs-heading-anchor-permalink" href="#Controls-provided" title="Permalink"></a></h2><p>In the table below, <code>mach</code> is the <em>training machine</em> being iterated, constructed by binding the supplied data to the <code>model</code> specified in the <code>IteratedModel</code> wrapper, but trained in each iteration on a subset of the data, according to the value of the <code>resampling</code> hyper-parameter of the wrapper (using all data if <code>resampling=nothing</code>).</p><table><tr><th style="text-align: right">control</th><th style="text-align: right">description</th><th style="text-align: right">can trigger a stop</th></tr><tr><td style="text-align: right"><a href="#IterationControl.Step"><code>Step</code></a><code>(n=1)</code></td><td style="text-align: right">Train model for <code>n</code> more iterations</td><td style="text-align: right">no</td></tr><tr><td style="text-align: right"><a href="#EarlyStopping.TimeLimit"><code>TimeLimit</code></a><code>(t=0.5)</code></td><td style="text-align: right">Stop after <code>t</code> hours</td><td style="text-align: right">yes</td></tr><tr><td style="text-align: right"><a href="#EarlyStopping.NumberLimit"><code>NumberLimit</code></a><code>(n=100)</code></td><td style="text-align: right">Stop after <code>n</code> applications of the control</td><td style="text-align: right">yes</td></tr><tr><td style="text-align: right"><a href="#EarlyStopping.NumberSinceBest"><code>NumberSinceBest</code></a><code>(n=6)</code></td><td style="text-align: right">Stop when best loss occurred <code>n</code> control applications ago</td><td style="text-align: right">yes</td></tr><tr><td style="text-align: right"><a href="#EarlyStopping.InvalidValue"><code>InvalidValue</code></a>()</td><td style="text-align: right">Stop when <code>NaN</code>, <code>Inf</code> or <code>-Inf</code> loss/training loss encountered</td><td style="text-align: right">yes</td></tr><tr><td style="text-align: right"><a href="#EarlyStopping.Threshold"><code>Threshold</code></a><code>(value=0.0)</code></td><td style="text-align: right">Stop when <code>loss &lt; value</code></td><td style="text-align: right">yes</td></tr><tr><td style="text-align: right"><a href="#EarlyStopping.GL"><code>GL</code></a><code>(alpha=2.0)</code></td><td style="text-align: right">† Stop after the &quot;generalization loss (GL)&quot; exceeds <code>alpha</code></td><td style="text-align: right">yes</td></tr><tr><td style="text-align: right"><a href="#EarlyStopping.PQ"><code>PQ</code></a><code>(alpha=0.75, k=5)</code></td><td style="text-align: right">† Stop after &quot;progress-modified GL&quot; exceeds <code>alpha</code></td><td style="text-align: right">yes</td></tr><tr><td style="text-align: right"><a href="#EarlyStopping.Patience"><code>Patience</code></a><code>(n=5)</code></td><td style="text-align: right">† Stop after <code>n</code> consecutive loss increases</td><td style="text-align: right">yes</td></tr><tr><td style="text-align: right"><a href="@ref EarlyStopping.Warmup"><code>Warmup</code></a><code>(c; n=1)</code></td><td style="text-align: right">Wait for <code>n</code> loss updates before checking criteria <code>c</code></td><td style="text-align: right">no</td></tr><tr><td style="text-align: right"><a href="#IterationControl.Info"><code>Info</code></a><code>(f=identity)</code></td><td style="text-align: right">Log to <code>Info</code> the value of <code>f(mach)</code>, where <code>mach</code> is current machine</td><td style="text-align: right">no</td></tr><tr><td style="text-align: right"><a href="#IterationControl.Warn"><code>Warn</code></a><code>(predicate; f=&quot;&quot;)</code></td><td style="text-align: right">Log to <code>Warn</code> the value of <code>f</code> or <code>f(mach)</code>, if <code>predicate(mach)</code> holds</td><td style="text-align: right">no</td></tr><tr><td style="text-align: right"><a href="#IterationControl.Error"><code>Error</code></a><code>(predicate; f=&quot;&quot;)</code></td><td style="text-align: right">Log to <code>Error</code> the value of <code>f</code> or <code>f(mach)</code>, if <code>predicate(mach)</code> holds and then stop</td><td style="text-align: right">yes</td></tr><tr><td style="text-align: right"><a href="#IterationControl.Callback"><code>Callback</code></a><code>(f=mach-&gt;nothing)</code></td><td style="text-align: right">Call <code>f(mach)</code></td><td style="text-align: right">yes</td></tr><tr><td style="text-align: right"><a href="#IterationControl.WithNumberDo"><code>WithNumberDo</code></a><code>(f=n-&gt;@info(n))</code></td><td style="text-align: right">Call <code>f(n + 1)</code> where <code>n</code> is the number of complete control cycles so far</td><td style="text-align: right">yes</td></tr><tr><td style="text-align: right"><a href="#MLJIteration.WithIterationsDo"><code>WithIterationsDo</code></a><code>(f=i-&gt;@info(&quot;iterations: $i&quot;))</code></td><td style="text-align: right">Call <code>f(i)</code>, where <code>i</code> is total number of iterations</td><td style="text-align: right">yes</td></tr><tr><td style="text-align: right"><a href="#IterationControl.WithLossDo"><code>WithLossDo</code></a><code>(f=x-&gt;@info(&quot;loss: $x&quot;))</code></td><td style="text-align: right">Call <code>f(loss)</code> where <code>loss</code> is the current loss</td><td style="text-align: right">yes</td></tr><tr><td style="text-align: right"><a href="#IterationControl.WithTrainingLossesDo"><code>WithTrainingLossesDo</code></a><code>(f=v-&gt;@info(v))</code></td><td style="text-align: right">Call <code>f(v)</code> where <code>v</code> is the current batch of training losses</td><td style="text-align: right">yes</td></tr><tr><td style="text-align: right"><a href="#MLJIteration.WithEvaluationDo"><code>WithEvaluationDo</code></a><code>(f-&gt;e-&gt;@info(&quot;evaluation: $e))</code></td><td style="text-align: right">Call <code>f(e)</code> where <code>e</code> is the current performance evaluation object</td><td style="text-align: right">yes</td></tr><tr><td style="text-align: right"><a href="#MLJIteration.WithFittedParamsDo"><code>WithFittedParamsDo</code></a><code>(f-&gt;fp-&gt;@info(&quot;fitted_params: $fp))</code></td><td style="text-align: right">Call <code>f(fp)</code> where <code>fp</code> is fitted parameters of training machine</td><td style="text-align: right">yes</td></tr><tr><td style="text-align: right"><a href="#MLJIteration.WithReportDo"><code>WithReportDo</code></a><code>(f-&gt;e-&gt;@info(&quot;report: $e))</code></td><td style="text-align: right">Call <code>f(r)</code> where <code>r</code> is the training machine report</td><td style="text-align: right">yes</td></tr><tr><td style="text-align: right"><a href="#MLJIteration.WithModelDo"><code>WithModelDo</code></a><code>(f-&gt;m-&gt;@info(&quot;model: $m))</code></td><td style="text-align: right">Call <code>f(m)</code> where <code>m</code> is the model, which may be mutated by <code>f</code></td><td style="text-align: right">yes</td></tr><tr><td style="text-align: right"><a href="#MLJIteration.WithMachineDo"><code>WithMachineDo</code></a><code>(f-&gt;mach-&gt;@info(&quot;report: $mach))</code></td><td style="text-align: right">Call <code>f(mach)</code> wher <code>mach</code> is the training machine in its current state</td><td style="text-align: right">yes</td></tr><tr><td style="text-align: right"><a href="#MLJIteration.Save"><code>Save</code></a><code>(filename=&quot;machine.jls&quot;)</code></td><td style="text-align: right">Save current training machine to <code>machine1.jls</code>, <code>machine2.jsl</code>, etc</td><td style="text-align: right">yes</td></tr></table><blockquote><p>Table 1. Atomic controls. Some advanced options are omitted.</p></blockquote><p>† For more on these controls see <a href="https://link.springer.com/chapter/10.1007%2F3-540-49430-8_3">Prechelt, Lutz  (1998)</a>:  &quot;Early Stopping - But When?&quot;, in <em>Neural Networks: Tricks of the  Trade</em>, ed. G. Orr, Springer.</p><p><strong>Stopping option.</strong> All the following controls trigger a stop if the provided function <code>f</code> returns <code>true</code> and <code>stop_if_true=true</code> is specified in the constructor: <code>Callback</code>, <code>WithNumberDo</code>, <code>WithLossDo</code>, <code>WithTrainingLossesDo</code>.</p><p>There are also three control wrappers to modify a control&#39;s behavior:</p><table><tr><th style="text-align: right">wrapper</th><th style="text-align: right">description</th></tr><tr><td style="text-align: right"><a href="#IterationControl.skip"><code>IterationControl.skip</code></a><code>(control, predicate=1)</code></td><td style="text-align: right">Apply <code>control</code> every <code>predicate</code> applications of the control wrapper (can also be a function; see doc-string)</td></tr><tr><td style="text-align: right"><a href="#IterationControl.louder"><code>IterationControl.louder</code></a><code>(control, by=1)</code></td><td style="text-align: right">Increase the verbosity level of <code>control</code> by the specified value (negative values lower verbosity)</td></tr><tr><td style="text-align: right"><a href="#IterationControl.with_state_do"><code>IterationControl.with_state_do</code></a><code>(control; f=...)</code></td><td style="text-align: right">Apply control <em>and</em> call <code>f(x)</code> where <code>x</code> is the internal state of control; useful for debugging. Default <code>f</code> logs state to <code>Info</code>. <strong>Warning</strong>: internal control state is not yet part of the public API.</td></tr><tr><td style="text-align: right"><a href="#IterationControl.composite"><code>IterationControl.composite</code></a><code>(controls...)</code></td><td style="text-align: right">Apply each <code>control</code> in <code>controls</code> in sequence; used internally by IterationControl.jl</td></tr></table><blockquote><p>Table 2. Wrapped controls</p></blockquote><h2 id="Using-training-losses,-and-controlling-model-tuning"><a class="docs-heading-anchor" href="#Using-training-losses,-and-controlling-model-tuning">Using training losses, and controlling model tuning</a><a id="Using-training-losses,-and-controlling-model-tuning-1"></a><a class="docs-heading-anchor-permalink" href="#Using-training-losses,-and-controlling-model-tuning" title="Permalink"></a></h2><p>Some iterative models report a training loss, as a byproduct of a <code>fit!</code> call and these can be used in two ways:</p><ol><li><p>To supplement an out-of-sample estimate of the loss in deciding when to stop, as in the <code>PQ</code> stopping criterion (see <a href="https://link.springer.com/chapter/10.1007%2F3-540-49430-8_3">Prechelt, Lutz (1998)</a>)); or</p></li><li><p>As a (generally less reliable) substitute for an out-of-sample loss, when wishing to train exclusively on all supplied data.</p></li></ol><p>To have <code>IteratedModel</code> bind all data to the training machine and use training losses in place of an out-of-sample loss, specify <code>resampling=nothing</code>. To check if <code>MyFavoriteIterativeModel</code> reports training losses, load the model code and inspect <code>supports_training_losses(MyFavoriteIterativeModel)</code> (or do <code>info(&quot;MyFavoriteIterativeModel&quot;)</code>)</p><h3 id="Controlling-model-tuning"><a class="docs-heading-anchor" href="#Controlling-model-tuning">Controlling model tuning</a><a id="Controlling-model-tuning-1"></a><a class="docs-heading-anchor-permalink" href="#Controlling-model-tuning" title="Permalink"></a></h3><p>An example of scenario 2 occurs when controlling hyperparameter optimization (model tuning). Recall that MLJ&#39;s <a href="../tuning_models/#MLJTuning.TunedModel"><code>TunedModel</code></a> wrapper is implemented as an iterative model. Moreover, this wrapper reports, as a training loss, the lowest value of the optimization objective function so far (typically the lowest value of an out-of-sample loss, or -1 times an out-of-sample score). One may want to simply end the hyperparameter search when this value meets the <a href="#EarlyStopping.NumberSinceBest"><code>NumberSinceBest</code></a> stopping criterion discussed below, say, rather than introducing an extra layer of resampling to first &quot;learn&quot; the optimal value of the iteration parameter.</p><p>In the following example, we conduct a <a href="../tuning_models/#MLJTuning.RandomSearch"><code>RandomSearch</code></a> for the optimal value of the regularization parameter <code>lambda</code> in a <code>RidgeRegressor</code> using 6-fold cross-validation. By wrapping our &quot;self-tuning&quot; version of the regressor as an <a href="#MLJIteration.IteratedModel"><code>IteratedModel</code></a>, with <code>resampling=nothing</code> and <code>NumberSinceBest(20)</code> in the controls, we terminate the search when the number of <code>lambda</code> values tested since the previous best cross-validation loss reaches 20.</p><pre><code class="language-julia hljs">using MLJ

X, y = @load_boston;
RidgeRegressor = @load RidgeRegressor pkg=MLJLinearModels verbosity=0
model = RidgeRegressor()
r = range(model, :lambda, lower=-1, upper=2, scale=x-&gt;10^x)
self_tuning_model = TunedModel(model=model,
                               tuning=RandomSearch(rng=123),
                               resampling=CV(nfolds=6),
                               range=r,
                               measure=mae);
iterated_model = IteratedModel(model=self_tuning_model,
                               resampling=nothing,
                               control=[Step(1), NumberSinceBest(20), NumberLimit(1000)])
mach = machine(iterated_model, X, y)</code></pre><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; fit!(mach)</code><code class="nohighlight hljs ansi" style="display:block;">[ Info: Training machine(DeterministicIteratedModel(model = DeterministicTunedModel(model = RidgeRegressor(lambda = 1.0, …), …), …), …).
[ Info: No iteration parameter specified. Using `iteration_parameter=:(n)`. 
[ Info: final loss: 3.8928800658727467
[ Info: final training loss: 3.8928800658727467
[ Info: Stop triggered by NumberSinceBest(20) stopping criterion. 
[ Info: Total of 45 iterations. 
trained Machine; does not cache data
  model: DeterministicIteratedModel(model = DeterministicTunedModel(model = RidgeRegressor(lambda = 1.0, …), …), …)
  args:
    1:	Source @735 ⏎ Table{AbstractVector{Continuous}}
    2:	Source @860 ⏎ AbstractVector{Continuous}</code></pre><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; report(mach).model_report.best_model</code><code class="nohighlight hljs ansi" style="display:block;">RidgeRegressor(
  lambda = 0.4243170708090101,
  fit_intercept = true,
  penalize_intercept = false,
  scale_penalty_with_samples = true,
  solver = nothing)</code></pre><p>We can use <code>mach</code> here to directly obtain predictions using the optimal model (trained on all data), as in</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; predict(mach, selectrows(X, 1:4))</code><code class="nohighlight hljs ansi" style="display:block;">4-element Vector{Float64}:
 31.309570596541448
 25.24911135120517
 29.89525728277618
 29.237112147518744</code></pre><h2 id="Custom-controls"><a class="docs-heading-anchor" href="#Custom-controls">Custom controls</a><a id="Custom-controls-1"></a><a class="docs-heading-anchor-permalink" href="#Custom-controls" title="Permalink"></a></h2><p>Under the hood, control in MLJIteration is implemented using <a href="https://github.com/ablaom/IterationControl.jl">IterationControl.jl</a>. Rather than iterating a training machine directly, we iterate a wrapped version of this object, which includes other information that a control may want to access, such as the MLJ evaluation object. This information is summarized under <a href="#The-training-machine-wrapper">The training machine wrapper</a> below.</p><p>Controls must implement two <code>update!</code> methods, one for initializing the control&#39;s <em>state</em> on the first application of the control (this state being external to the control <code>struct</code>) and one for all subsequent control applications, which generally updates the state as well. There are two optional methods: <code>done</code>, for specifying conditions triggering a stop, and <code>takedown</code> for specifying actions to perform at the end of controlled training.</p><p>We summarize the training algorithm, as it relates to controls, after giving a simple example.</p><h3 id="Example-1-Non-uniform-iteration-steps"><a class="docs-heading-anchor" href="#Example-1-Non-uniform-iteration-steps">Example 1 - Non-uniform iteration steps</a><a id="Example-1-Non-uniform-iteration-steps-1"></a><a class="docs-heading-anchor-permalink" href="#Example-1-Non-uniform-iteration-steps" title="Permalink"></a></h3><p>Below we define a control, <code>IterateFromList(list)</code>, to train, on each application of the control, until the iteration count reaches the next value in a user-specified <code>list</code>, triggering a stop when the <code>list</code> is exhausted. For example, to train on iteration counts on a log scale, one might use <code>IterateFromList([round(Int, 10^x) for x in range(1, 2, length=10)]</code>.</p><p>In the code, <code>wrapper</code> is an object that wraps the training machine (see above). The variable <code>n</code> is a counter for control cycles (unused in this example).</p><pre><code class="language-julia hljs">
import IterationControl # or MLJ.IterationControl

struct IterateFromList
    list::Vector{&lt;:Int} # list of iteration parameter values
    IterateFromList(v) = new(unique(sort(v)))
end

function IterationControl.update!(control::IterateFromList, wrapper, verbosity, n)
    Δi = control.list[1]
    verbosity &gt; 1 &amp;&amp; @info &quot;Training $Δi more iterations. &quot;
    MLJIteration.train!(wrapper, Δi) # trains the training machine
    return (index = 2, )
end

function IterationControl.update!(control::IterateFromList, wrapper, verbosity, n, state)
    index = state.positioin_in_list
    Δi = control.list[i] - wrapper.n_iterations
    verbosity &gt; 1 &amp;&amp; @info &quot;Training $Δi more iterations. &quot;
    MLJIteration.train!(wrapper, Δi)
    return (index = index + 1, )
end</code></pre><p>The first <code>update</code> method will be called the first time the control is applied, returning an initialized <code>state = (index = 2,)</code>, which is passed to the second <code>update</code> method, which is called on subsequent control applications (and which returns the updated <code>state</code>).</p><p>A <code>done</code> method articulates the criterion for stopping:</p><pre><code class="language-julia hljs">IterationControl.done(control::IterateFromList, state) =
    state.index &gt; length(control.list)</code></pre><p>For the sake of illustration, we&#39;ll implement a <code>takedown</code> method; its return value is included in the <code>IteratedModel</code> report:</p><pre><code class="language-julia hljs">IterationControl.takedown(control::IterateFromList, verbosity, state)
    verbosity &gt; 1 &amp;&amp; = @info &quot;Stepped through these values of the &quot;*
                              &quot;iteration parameter: $(control.list)&quot;
    return (iteration_values=control.list, )
end</code></pre><h3 id="The-training-machine-wrapper"><a class="docs-heading-anchor" href="#The-training-machine-wrapper">The training machine wrapper</a><a id="The-training-machine-wrapper-1"></a><a class="docs-heading-anchor-permalink" href="#The-training-machine-wrapper" title="Permalink"></a></h3><p>A training machine <code>wrapper</code> has these properties:</p><ul><li><p><code>wrapper.machine</code> - the training machine, type <code>Machine</code></p></li><li><p><code>wrapper.model</code>   - the mutable atomic model, coinciding with <code>wrapper.machine.model</code></p></li><li><p><code>wrapper.n_cycles</code> - the number <code>IterationControl.train!(wrapper, _)</code> calls so far; generally the current control cycle count</p></li><li><p><code>wrapper.n_iterations</code> - the total number of iterations applied to the model so far</p></li><li><p><code>wrapper.Δiterations</code> - the number of iterations applied in the last <code>IterationControl.train!(wrapper, _)</code> call</p></li><li><p><code>wrapper.loss</code> - the out-of-sample loss (based on the first measure in <code>measures</code>)</p></li><li><p><code>wrapper.training_losses</code> - the last batch of training losses (if reported by <code>model</code>), an abstract vector of length <code>wrapper.Δiteration</code>.</p></li><li><p><code>wrapper.evaluation</code> - the complete MLJ performance evaluation object, which has the following properties: <code>measure</code>, <code>measurement</code>, <code>per_fold</code>, <code>per_observation</code>, <code>fitted_params_per_fold</code>, <code>report_per_fold</code> (here there is only one fold). For further details, see <a href="../evaluating_model_performance/#Evaluating-Model-Performance">Evaluating Model Performance</a>.</p></li></ul><h3 id="The-training-algorithm"><a class="docs-heading-anchor" href="#The-training-algorithm">The training algorithm</a><a id="The-training-algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#The-training-algorithm" title="Permalink"></a></h3><p>Here now is a simplified description of the training of an <code>IteratedModel</code>. First, the atomic <code>model</code> is bound in a machine - the <em>training machine</em> above - to a subset of the supplied data, and then wrapped in an object called <code>wrapper</code> below. To train the training machine machine for <code>i</code> more iterations, and update the other data in the wrapper, requires the call <code>MLJIteration.train!(wrapper, i)</code>. Only controls can make this call (e.g., <code>Step(...)</code>, or <code>IterateFromList(...)</code> above). If we assume for simplicity there is only a single control, called <code>control</code>, then training proceeds as follows:</p><pre><code class="language-julia hljs">n = 1 # initialize control cycle counter
state = update!(control, wrapper, verbosity, n)
finished = done(control, state)

# subsequent training events:
while !finished
    n += 1
    state = update!(control, wrapper, verbosity, n, state)
    finished = done(control, state)
end

# finalization:
return takedown(control, verbosity, state)</code></pre><h3 id="Example-2-Cyclic-learning-rates"><a class="docs-heading-anchor" href="#Example-2-Cyclic-learning-rates">Example 2 - Cyclic learning rates</a><a id="Example-2-Cyclic-learning-rates-1"></a><a class="docs-heading-anchor-permalink" href="#Example-2-Cyclic-learning-rates" title="Permalink"></a></h3><p>The control below implements a triangular cyclic learning rate policy, close to that described in <a href="https://ieeexplore.ieee.org/document/7926641">L. N. Smith (2019)</a>: &quot;Cyclical Learning Rates for Training Neural Networks,&quot; 2017 IEEE Winter Conference on Applications of Computer Vision (WACV), Santa Rosa, CA, USA, pp. 464-472. [In that paper learning rates are mutated (slowly) <em>during</em> each training iteration (epoch) while here mutations can occur once per iteration of the model, at most.]</p><p>For the sake of illustration, we suppose the iterative model, <code>model</code>, specified in the <code>IteratedModel</code> constructor, has a field called <code>:learning_parameter</code>, and that mutating this parameter does not trigger cold-restarts.</p><pre><code class="language-julia hljs">struct CycleLearningRate{F&lt;:AbstractFloat}
    stepsize::Int
    lower::F
    upper::F
end

# return one cycle of learning rate values:
function one_cycle(c::CycleLearningRate)
    rise = range(c.lower, c.upper, length=c.stepsize + 1)
    fall = reverse(rise)
    return vcat(rise[1:end - 1], fall[1:end - 1])
end

function IterationControl.update!(control::CycleLearningRate,
                                  wrapper,
                                  verbosity,
                                  n,
                                  state = (learning_rates=nothing, ))
    rates = n == 0 ? one_cycle(control) : state.learning_rates
    index = mod(n, length(rates)) + 1
    r = rates[index]
    verbosity &gt; 1 &amp;&amp; @info &quot;learning rate: $r&quot;
    wrapper.model.iteration_control = r
    return (learning_rates = rates,)
end</code></pre><h2 id="API-Reference"><a class="docs-heading-anchor" href="#API-Reference">API Reference</a><a id="API-Reference-1"></a><a class="docs-heading-anchor-permalink" href="#API-Reference" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJIteration.IteratedModel" href="#MLJIteration.IteratedModel"><code>MLJIteration.IteratedModel</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">IteratedModel(model=nothing,
              controls=Any[Step(1), Patience(5), GL(2.0), TimeLimit(Dates.Millisecond(108000)), InvalidValue()],
              retrain=false,
              resampling=Holdout(),
              measure=nothing,
              weights=nothing,
              class_weights=nothing,
              operation=predict,
              verbosity=1,
              check_measure=true,
              iteration_parameter=nothing,
              cache=true)</code></pre><p>Wrap the specified <code>model &lt;: Supervised</code> in the specified iteration <code>controls</code>. Training a machine bound to the wrapper iterates a corresonding machine bound to <code>model</code>. Here <code>model</code> should support iteration.</p><p>To list all controls, do <code>MLJIteration.CONTROLS</code>. Controls are summarized at <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/controlling_iterative_models/">https://alan-turing-institute.github.io/MLJ.jl/dev/getting_started/</a> but query individual doc-strings for details and advanced options. For creating your own controls, refer to the documentation just cited.</p><p>To make out-of-sample losses available to the controls, the machine bound to <code>model</code> is only trained on part of the data, as iteration proceeds.  See details on training below. Specify <code>retrain=true</code> to ensure the model is retrained on <em>all</em> available data, using the same number of iterations, once controlled iteration has stopped.</p><p>Specify <code>resampling=nothing</code> if all data is to be used for controlled iteration, with each out-of-sample loss replaced by the most recent training loss, assuming this is made available by the model (<code>supports_training_losses(model) == true</code>). Otherwise, <code>resampling</code> must have type <code>Holdout</code> (eg, <code>Holdout(fraction_train=0.8, rng=123)</code>).</p><p>Assuming <code>retrain=true</code> or <code>resampling=nothing</code>, <code>iterated_model</code> behaves exactly like the original <code>model</code> but with the iteration parameter automatically selected. If <code>retrain=false</code> (default) and <code>resampling</code> is not <code>nothing</code>, then <code>iterated_model</code> behaves like the original model trained on a subset of the provided data.</p><p>Controlled iteration can be continued with new <code>fit!</code> calls (warm restart) by mutating a control, or by mutating the iteration parameter of <code>model</code>, which is otherwise ignored.</p><p><strong>Training</strong></p><p>Given an instance <code>iterated_model</code> of <code>IteratedModel</code>, calling <code>fit!(mach)</code> on a machine <code>mach = machine(iterated_model, data...)</code> performs the following actions:</p><ul><li><p>Assuming <code>resampling !== nothing</code>, the <code>data</code> is split into <em>train</em> and <em>test</em> sets, according to the specified <code>resampling</code> strategy, which must have type <code>Holdout</code>.</p></li><li><p>A clone of the wrapped model, <code>iterated_model.model</code>, is bound to the train data in an internal machine, <code>train_mach</code>. If <code>resampling === nothing</code>, all data is used instead. This machine is the object to which controls are applied. For example, <code>Callback(fitted_params |&gt; print)</code> will print the value of <code>fitted_params(train_mach)</code>.</p></li><li><p>The iteration parameter of the clone is set to <code>0</code>.</p></li><li><p>The specified <code>controls</code> are repeatedly applied to <code>train_mach</code> in sequence, until one of the controls triggers a stop. Loss-based controls (eg, <code>Patience()</code>, <code>GL()</code>, <code>Threshold(0.001)</code>) use an out-of-sample loss, obtained by applying <code>measure</code> to predictions and the test target values. (Specifically, these predictions are those returned by <code>operation(train_mach)</code>.)  If <code>resampling === nothing</code> then the most recent training loss is used instead. Some controls require <em>both</em> out-of-sample and training losses (eg, <code>PQ()</code>).</p></li><li><p>Once a stop has been triggered, a clone of <code>model</code> is bound to all <code>data</code> in a machine called <code>mach_production</code> below, unless <code>retrain == false</code> or <code>resampling === nothing</code>, in which case <code>mach_production</code> coincides with <code>train_mach</code>.</p></li></ul><p><strong>Prediction</strong></p><p>Calling <code>predict(mach, Xnew)</code> returns <code>predict(mach_production, Xnew)</code>. Similar similar statements hold for <code>predict_mean</code>, <code>predict_mode</code>, <code>predict_median</code>.</p><p><strong>Controls</strong></p><p>A control is permitted to mutate the fields (hyper-parameters) of <code>train_mach.model</code> (the clone of <code>model</code>). For example, to mutate a learning rate one might use the control</p><pre><code class="nohighlight hljs">Callback(mach -&gt; mach.model.eta = 1.05*mach.model.eta)</code></pre><p>However, unless <code>model</code> supports warm restarts with respect to changes in that parameter, this will trigger retraining of <code>train_mach</code> from scratch, with a different training outcome, which is not recommended.</p><p><strong>Warm restarts</strong></p><p>If <code>iterated_model</code> is mutated and <code>fit!(mach)</code> is called again, then a warm restart is attempted if the only parameters to change are <code>model</code> or <code>controls</code> or both.</p><p>Specifically, <code>train_mach.model</code> is mutated to match the current value of <code>iterated_model.model</code> and the iteration parameter of the latter is updated to the last value used in the preceding <code>fit!(mach)</code> call. Then repeated application of the (updated) controls begin anew.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/MLJIteration.jl/blob/v0.6.1/src/constructors.jl#L74-L188">source</a></section></article><h3 id="Controls"><a class="docs-heading-anchor" href="#Controls">Controls</a><a id="Controls-1"></a><a class="docs-heading-anchor-permalink" href="#Controls" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IterationControl.Step" href="#IterationControl.Step"><code>IterationControl.Step</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Step(; n=1)</code></pre><p>An iteration control, as in, <code>Step(2)</code>. </p><p>Train for <code>n</code> more iterations. Will never trigger a stop. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/IterationControl.jl/blob/v0.5.4/src/utilities.jl#L28-L33">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="EarlyStopping.TimeLimit" href="#EarlyStopping.TimeLimit"><code>EarlyStopping.TimeLimit</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">TimeLimit(; t=0.5)</code></pre><p>An early stopping criterion for loss-reporting iterative algorithms. </p><p>Stopping is triggered after <code>t</code> hours have elapsed since the stopping criterion was initiated.</p><p>Any Julia built-in <code>Real</code> type can be used for <code>t</code>. Subtypes of <code>Period</code> may also be used, as in <code>TimeLimit(t=Minute(30))</code>.</p><p>Internally, <code>t</code> is rounded to nearest millisecond. ``</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/EarlyStopping.jl/blob/v0.3.0/src/criteria.jl#L61-L74">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="EarlyStopping.NumberLimit" href="#EarlyStopping.NumberLimit"><code>EarlyStopping.NumberLimit</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NumberLimit(; n=100)</code></pre><p>An early stopping criterion for loss-reporting iterative algorithms. </p><p>A stop is triggered by <code>n</code> consecutive loss updates, excluding &quot;training&quot; loss updates.</p><p>If wrapped in a <code>stopper::EarlyStopper</code>, this is the number of calls to <code>done!(stopper)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/EarlyStopping.jl/blob/v0.3.0/src/criteria.jl#L335-L346">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="EarlyStopping.NumberSinceBest" href="#EarlyStopping.NumberSinceBest"><code>EarlyStopping.NumberSinceBest</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NumberSinceBest(; n=6)</code></pre><p>An early stopping criterion for loss-reporting iterative algorithms. </p><p>A stop is triggered when the number of calls to the control, since the lowest value of the loss so far, is <code>n</code>.</p><p>For a customizable loss-based stopping criterion, use <a href="@ref"><code>WithLossDo</code></a> or <a href="@ref"><code>WithTrainingLossesDo</code></a> with the <code>stop_if_true=true</code> option. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/EarlyStopping.jl/blob/v0.3.0/src/criteria.jl#L296-L306">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="EarlyStopping.InvalidValue" href="#EarlyStopping.InvalidValue"><code>EarlyStopping.InvalidValue</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">InvalidValue()</code></pre><p>An early stopping criterion for loss-reporting iterative algorithms. </p><p>Stop if a loss (or training loss) is <code>NaN</code>, <code>Inf</code> or <code>-Inf</code> (or, more precisely, if <code>isnan(loss)</code> or <code>isinf(loss)</code> is <code>true</code>).</p><p>For a customizable loss-based stopping criterion, use <a href="@ref"><code>WithLossDo</code></a> or <a href="@ref"><code>WithTrainingLossesDo</code></a> with the <code>stop_if_true=true</code> option. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/EarlyStopping.jl/blob/v0.3.0/src/criteria.jl#L31-L41">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="EarlyStopping.Threshold" href="#EarlyStopping.Threshold"><code>EarlyStopping.Threshold</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Threshold(; value=0.0)</code></pre><p>An early stopping criterion for loss-reporting iterative algorithms. </p><p>A stop is triggered as soon as the loss drops below <code>value</code>.</p><p>For a customizable loss-based stopping criterion, use <a href="@ref"><code>WithLossDo</code></a> or <a href="@ref"><code>WithTrainingLossesDo</code></a> with the <code>stop_if_true=true</code> option. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/EarlyStopping.jl/blob/v0.3.0/src/criteria.jl#L365-L374">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="EarlyStopping.GL" href="#EarlyStopping.GL"><code>EarlyStopping.GL</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GL(; alpha=2.0)</code></pre><p>An early stopping criterion for loss-reporting iterative algorithms. </p><p>A stop is triggered when the (rescaled) generalization loss exceeds the threshold <code>alpha</code>.</p><p><strong>Terminology.</strong> Suppose <span>$E_1, E_2, ..., E_t$</span> are a sequence of losses, for example, out-of-sample estimates of the loss associated with some iterative machine learning algorithm. Then the <em>generalization loss</em> at time <code>t</code>, is given by</p><p><span>$GL_t = 100 (E_t - E_{opt}) \over |E_{opt}|$</span></p><p>where <span>$E_{opt}$</span> is the minimum value of the sequence.</p><p>Reference: <a href="https://link.springer.com/chapter/10.1007%2F3-540-49430-8_3">Prechelt, Lutz (1998): &quot;Early Stopping- But When?&quot;, in <em>Neural Networks: Tricks of the Trade</em>, ed. G. Orr, Springer.</a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/EarlyStopping.jl/blob/v0.3.0/src/criteria.jl#L101-L120">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="EarlyStopping.PQ" href="#EarlyStopping.PQ"><code>EarlyStopping.PQ</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PQ(; alpha=0.75, k=5, tol=eps(Float64))</code></pre><p>A stopping criterion for training iterative supervised learners.</p><p>A stop is triggered when Prechelt&#39;s progress-modified generalization loss exceeds the threshold <span>$PQ_T &gt; alpha$</span>, or if the training progress drops below <span>$P_j ≤ tol$</span>. Here <code>k</code> is the number of training (in-sample) losses used to estimate the training progress.</p><p><strong>Context and explanation of terminology</strong></p><p>The <em>training progress</em> at time <span>$j$</span> is defined by</p><p><span>$P_j = 1000 |M - m|/|m|$</span></p><p>where <span>$M$</span> is the mean of the last <code>k</code> training losses <span>$F_1, F_2, …, F_k$</span> and <span>$m$</span> is the minimum value of those losses.</p><p>The <em>progress-modified generalization loss</em> at time <span>$t$</span> is then given by</p><p><span>$PQ_t = GL_t / P_t$</span></p><p>where <span>$GL_t$</span> is the generalization loss at time <span>$t$</span>; see <a href="#EarlyStopping.GL"><code>GL</code></a>.</p><p>PQ will stop when the following are true:</p><ol><li>At least <code>k</code> training samples have been collected via <code>done!(c::PQ, loss; training = true)</code> or <code>update_training(c::PQ, loss, state)</code></li><li>The last update was an out-of-sample update. (<code>done!(::PQ, loss; training=true)</code> is always false)</li><li>The progress-modified generalization loss exceeds the threshold <span>$PQ_t &gt; alpha$</span> <strong>OR</strong> the training progress stalls <span>$P_j ≤ tol$</span>.</li></ol><p>Reference: <a href="https://link.springer.com/chapter/10.1007%2F3-540-49430-8_3">Prechelt, Lutz (1998): &quot;Early Stopping- But When?&quot;, in <em>Neural Networks: Tricks of the Trade</em>, ed. G. Orr, Springer.</a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/EarlyStopping.jl/blob/v0.3.0/src/criteria.jl#L161-L198">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="EarlyStopping.Patience" href="#EarlyStopping.Patience"><code>EarlyStopping.Patience</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Patience(; n=5)</code></pre><p>An early stopping criterion for loss-reporting iterative algorithms. </p><p>A stop is triggered by <code>n</code> consecutive increases in the loss.</p><p>Denoted &quot;<em>UP</em>s&quot; in <a href="https://link.springer.com/chapter/10.1007%2F3-540-49430-8_3">Prechelt, Lutz (1998): &quot;Early Stopping- But When?&quot;, in <em>Neural Networks: Tricks of the Trade</em>, ed. G. Orr, Springer.</a>.</p><p>For a customizable loss-based stopping criterion, use <a href="@ref"><code>WithLossDo</code></a> or <a href="@ref"><code>WithTrainingLossesDo</code></a> with the <code>stop_if_true=true</code> option. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/EarlyStopping.jl/blob/v0.3.0/src/criteria.jl#L254-L265">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IterationControl.Info" href="#IterationControl.Info"><code>IterationControl.Info</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Info(f=identity)</code></pre><p>An iteration control, as in, <code>Info(my_loss_function)</code>. </p><p>Log to <code>Info</code> the value of <code>f(m)</code>, where <code>m</code> is the object being iterated. If <code>IterativeControl.expose(m)</code> has been overloaded, then log <code>f(expose(m))</code> instead.</p><p>Can be suppressed by setting the global verbosity level sufficiently low. </p><p>See also <a href="#IterationControl.Warn"><code>Warn</code></a>, <a href="#IterationControl.Error"><code>Error</code></a>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/IterationControl.jl/blob/v0.5.4/src/utilities.jl#L28-L37">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IterationControl.Warn" href="#IterationControl.Warn"><code>IterationControl.Warn</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Warn(predicate; f=&quot;&quot;)</code></pre><p>An iteration control, as in, <code>Warn(m -&gt; length(m.cache) &gt; 100, f=&quot;Memory low&quot;)</code>. </p><p>If <code>predicate(m)</code> is <code>true</code>, then log to <code>Warn</code> the value of <code>f</code> (or <code>f(IterationControl.expose(m))</code> if <code>f</code> is a function). Here <code>m</code> is the object being iterated.</p><p>Can be suppressed by setting the global verbosity level sufficiently low.</p><p>See also <a href="#IterationControl.Info"><code>Info</code></a>, <a href="#IterationControl.Error"><code>Error</code></a>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/IterationControl.jl/blob/v0.5.4/src/utilities.jl#L28-L37">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IterationControl.Error" href="#IterationControl.Error"><code>IterationControl.Error</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Error(predicate; f=&quot;&quot;, exception=nothing))</code></pre><p>An iteration control, as in, <code>Error(m -&gt; isnan(m.bias), f=&quot;Bias overflow!&quot;)</code>. </p><p>If <code>predicate(m)</code> is <code>true</code>, then log at the <code>Error</code> level the value of <code>f</code> (or <code>f(IterationControl.expose(m))</code> if <code>f</code> is a function) and stop iteration at the end of the current control cycle. Here <code>m</code> is the object being iterated.</p><p>Specify <code>exception=...</code> to throw an immediate execption, without waiting to the end of the control cycle.</p><p>See also <a href="#IterationControl.Info"><code>Info</code></a>, <a href="#IterationControl.Warn"><code>Warn</code></a>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/IterationControl.jl/blob/v0.5.4/src/utilities.jl#L28-L37">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IterationControl.Callback" href="#IterationControl.Callback"><code>IterationControl.Callback</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Callback(f=_-&gt;nothing, stop_if_true=false, stop_message=nothing, raw=false)</code></pre><p>An iteration control, as in, <code>Callback(m-&gt;put!(v, my_loss_function(m))</code>. </p><p>Call <code>f(IterationControl.expose(m))</code>, where <code>m</code> is the object being iterated, unless <code>raw=true</code>, in which case call <code>f(m)</code> (guaranteed if <code>expose</code> has not been overloaded.) If <code>stop_if_true</code> is <code>true</code>, then trigger an early stop if the value returned by <code>f</code> is <code>true</code>, logging the <code>stop_message</code> if specified. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/IterationControl.jl/blob/v0.5.4/src/utilities.jl#L28-L33">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IterationControl.WithNumberDo" href="#IterationControl.WithNumberDo"><code>IterationControl.WithNumberDo</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">WithNumberDo(f=n-&gt;@info(&quot;number: $n&quot;), stop_if_true=false, stop_message=nothing)</code></pre><p>An iteration control, as in, <code>WithNumberDo(n-&gt;put!(my_channel, n))</code>. </p><p>Call <code>f(n + 1)</code>, where <code>n</code> is the number of complete control cycles. of the control (so, <code>n = 1, 2, 3, ...</code>, unless control is wrapped in a <a href="#IterationControl.skip"><code>IterationControl.skip</code></a>)`.</p><p>If <code>stop_if_true</code> is <code>true</code>, then trigger an early stop if the value returned by <code>f</code> is <code>true</code>, logging the <code>stop_message</code> if specified. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/IterationControl.jl/blob/v0.5.4/src/utilities.jl#L28-L35">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJIteration.WithIterationsDo" href="#MLJIteration.WithIterationsDo"><code>MLJIteration.WithIterationsDo</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">WithIterationsDo(f=x-&gt;@info(&quot;iterations: $x&quot;), stop_if_true=false, stop_message=nothing)</code></pre><p>An iteration control, as in, <code>WithIterationsDo(x-&gt;put!(my_channel, x))</code>. </p><p>Call <code>f(x)</code>, where <code>x</code> is the current number of model iterations (generally more than the number of control cycles). If <code>stop_if_true</code> is <code>true</code>, then trigger an early stop if the value returned by <code>f</code> is <code>true</code>, logging the <code>stop_message</code> if specified. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/IterationControl.jl/blob/v0.5.4/src/utilities.jl#L28-L33">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IterationControl.WithLossDo" href="#IterationControl.WithLossDo"><code>IterationControl.WithLossDo</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">WithLossDo(f=x-&gt;@info(&quot;loss: $x&quot;), stop_if_true=false, stop_message=nothing)</code></pre><p>An iteration control, as in, <code>WithLossDo(x-&gt;put!(my_losses, x))</code>. </p><p>Call <code>f(loss)</code>, where <code>loss</code> is current loss.</p><p>If <code>stop_if_true</code> is <code>true</code>, then trigger an early stop if the value returned by <code>f</code> is <code>true</code>, logging the <code>stop_message</code> if specified. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/IterationControl.jl/blob/v0.5.4/src/utilities.jl#L28-L35">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IterationControl.WithTrainingLossesDo" href="#IterationControl.WithTrainingLossesDo"><code>IterationControl.WithTrainingLossesDo</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">WithTrainingLossesDo(f=v-&gt;@info(&quot;training: $v&quot;), stop_if_true=false, stop_message=nothing)</code></pre><p>An iteration control, as in, <code>WithTrainingLossesDo(v-&gt;put!(my_losses, last(v))</code>. </p><p>Call <code>f(training_losses)</code>, where <code>training_losses</code> is the vector of most recent batch of training losses.</p><p>If <code>stop_if_true</code> is <code>true</code>, then trigger an early stop if the value returned by <code>f</code> is <code>true</code>, logging the <code>stop_message</code> if specified. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/IterationControl.jl/blob/v0.5.4/src/utilities.jl#L28-L35">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJIteration.WithEvaluationDo" href="#MLJIteration.WithEvaluationDo"><code>MLJIteration.WithEvaluationDo</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">WithEvaluationDo(f=x-&gt;@info(&quot;evaluation: $x&quot;), stop_if_true=false, stop_message=nothing)</code></pre><p>An iteration control, as in, <code>WithEvaluationDo(x-&gt;put!(my_channel, x))</code>. </p><p>Call <code>f(x)</code>, where <code>x</code> is the latest performance evaluation, as returned by <code>evaluate!(train_mach, resampling=..., ...)</code>. Not valid if <code>resampling=nothing</code>. If <code>stop_if_true</code> is <code>true</code>, then trigger an early stop if the value returned by <code>f</code> is <code>true</code>, logging the <code>stop_message</code> if specified. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/IterationControl.jl/blob/v0.5.4/src/utilities.jl#L28-L33">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJIteration.WithFittedParamsDo" href="#MLJIteration.WithFittedParamsDo"><code>MLJIteration.WithFittedParamsDo</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">WithFittedParamsDo(f=x-&gt;@info(&quot;fitted_params: $x&quot;), stop_if_true=false, stop_message=nothing)</code></pre><p>An iteration control, as in, <code>WithFittedParamsDo(x-&gt;put!(my_channel, x))</code>. </p><p>Call <code>f(x)</code>, where <code>x = fitted_params(mach)</code> is the fitted parameters of the training machine, <code>mach</code>, in its current state. If <code>stop_if_true</code> is <code>true</code>, then trigger an early stop if the value returned by <code>f</code> is <code>true</code>, logging the <code>stop_message</code> if specified. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/IterationControl.jl/blob/v0.5.4/src/utilities.jl#L28-L33">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJIteration.WithReportDo" href="#MLJIteration.WithReportDo"><code>MLJIteration.WithReportDo</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">WithReportDo(f=x-&gt;@info(&quot;report: $x&quot;), stop_if_true=false, stop_message=nothing)</code></pre><p>An iteration control, as in, <code>WithReportDo(x-&gt;put!(my_channel, x))</code>. </p><p>Call <code>f(x)</code>, where <code>x = report(mach)</code> is the report associated with the training machine, <code>mach</code>,  in its current state. If <code>stop_if_true</code> is <code>true</code>, then trigger an early stop if the value returned by <code>f</code> is <code>true</code>, logging the <code>stop_message</code> if specified. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/IterationControl.jl/blob/v0.5.4/src/utilities.jl#L28-L33">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJIteration.WithModelDo" href="#MLJIteration.WithModelDo"><code>MLJIteration.WithModelDo</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">WithModelDo(f=x-&gt;@info(&quot;model: $x&quot;), stop_if_true=false, stop_message=nothing)</code></pre><p>An iteration control, as in, <code>WithModelDo(x-&gt;put!(my_channel, x))</code>. </p><p>Call <code>f(x)</code>, where <code>x</code> is the model associated with the training machine; <code>f</code> may mutate <code>x</code>, as in <code>f(x) = (x.learning_rate *= 0.9)</code>. If <code>stop_if_true</code> is <code>true</code>, then trigger an early stop if the value returned by <code>f</code> is <code>true</code>, logging the <code>stop_message</code> if specified. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/IterationControl.jl/blob/v0.5.4/src/utilities.jl#L28-L33">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJIteration.WithMachineDo" href="#MLJIteration.WithMachineDo"><code>MLJIteration.WithMachineDo</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">WithMachineDo(f=x-&gt;@info(&quot;machine: $x&quot;), stop_if_true=false, stop_message=nothing)</code></pre><p>An iteration control, as in, <code>WithMachineDo(x-&gt;put!(my_channel, x))</code>. </p><p>Call <code>f(x)</code>, where <code>x</code> is the training machine in its current state. If <code>stop_if_true</code> is <code>true</code>, then trigger an early stop if the value returned by <code>f</code> is <code>true</code>, logging the <code>stop_message</code> if specified. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/IterationControl.jl/blob/v0.5.4/src/utilities.jl#L28-L33">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJIteration.Save" href="#MLJIteration.Save"><code>MLJIteration.Save</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Save(filename=&quot;machine.jls&quot;)</code></pre><p>An iteration control, as in, <code>Save(&quot;run3/machine.jls&quot;)</code>. </p><p>Save the current state of the machine being iterated to disk, using the provided <code>filename</code>, decorated with a number, as in &quot;run3/machine42.jls&quot;. The default behaviour uses the Serialization module but this can be changed by setting the <code>method=save_fn(::String, ::Any)</code> argument where <code>save_fn</code> is any serialization method. For more on what is meant by &quot;the machine being iterated&quot;, see <a href="#MLJIteration.IteratedModel"><code>IteratedModel</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/IterationControl.jl/blob/v0.5.4/src/utilities.jl#L28-L33">source</a></section></article><h3 id="Control-wrappers"><a class="docs-heading-anchor" href="#Control-wrappers">Control wrappers</a><a id="Control-wrappers-1"></a><a class="docs-heading-anchor-permalink" href="#Control-wrappers" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IterationControl.skip" href="#IterationControl.skip"><code>IterationControl.skip</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">IterationControl.skip(control, predicate=1)</code></pre><p>An iteration control wrapper.</p><p>If <code>predicate</code> is an <strong>integer</strong>, <code>k</code>: Apply <code>control</code> on every <code>k</code> calls to apply the wrapped control, starting with the <code>k</code>th call.</p><p>If <code>predicate</code> is a <strong>function</strong>: Apply <code>control</code> as usual when <code>predicate(n + 1)</code> is <code>true</code> but otherwise skip. Here <code>n</code> is the number of control cycles applied so far.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/IterationControl.jl/blob/v0.5.4/src/wrapped_controls.jl#L73-L85">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IterationControl.louder" href="#IterationControl.louder"><code>IterationControl.louder</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">IterationControl.louder(control, by=1)</code></pre><p>Wrap <code>control</code> to make in more (or less) verbose. The same as <code>control</code>, but as if the global <code>verbosity</code> were increased by the value <code>by</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/IterationControl.jl/blob/v0.5.4/src/wrapped_controls.jl#L8-L15">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IterationControl.with_state_do" href="#IterationControl.with_state_do"><code>IterationControl.with_state_do</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">IterationControl.with_state_do(control,
                              f=x-&gt;@info &quot;$(typeof(control)) state: $x&quot;)</code></pre><p>Wrap <code>control</code> to give access to it&#39;s internal state. Acts exactly like <code>control</code> except that <code>f</code> is called on the internal state of <code>control</code>. If <code>f</code> is not specified, the control type and state are logged to <code>Info</code> at every update (useful for debugging new controls).</p><p><strong>Warning.</strong> The internal state of a control is not yet considered part of the public interface and could change between in any pre 1.0 release of IterationControl.jl.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/IterationControl.jl/blob/v0.5.4/src/wrapped_controls.jl#L36-L49">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IterationControl.composite" href="#IterationControl.composite"><code>IterationControl.composite</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">composite(controls...)</code></pre><p>Construct an iteration control that applies the specified <code>controls</code> in sequence.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/IterationControl.jl/blob/v0.5.4/src/composite_controls.jl#L16-L22">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../learning_networks/">« Learning Networks</a><a class="docs-footer-nextpage" href="../generating_synthetic_data/">Generating Synthetic Data »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Friday 8 March 2024 06:58">Friday 8 March 2024</span>. Using Julia version 1.10.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
