<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>MLJ Cheatsheet · MLJ</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="MLJ logo"/></a><div class="docs-package-name"><span class="docs-autofit">MLJ</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../about_mlj/">About MLJ</a></li><li><a class="tocitem" href="../getting_started/">Getting Started</a></li><li><a class="tocitem" href="../common_mlj_workflows/">Common MLJ Workflows</a></li><li><a class="tocitem" href="../working_with_categorical_data/">Working with Categorical Data</a></li><li><a class="tocitem" href="../model_search/">Model Search</a></li><li><a class="tocitem" href="../loading_model_code/">Loading Model Code</a></li><li><a class="tocitem" href="../machines/">Machines</a></li><li><a class="tocitem" href="../evaluating_model_performance/">Evaluating Model Performance</a></li><li><a class="tocitem" href="../performance_measures/">Performance Measures</a></li><li><a class="tocitem" href="../weights/">Weights</a></li><li><a class="tocitem" href="../tuning_models/">Tuning Models</a></li><li><a class="tocitem" href="../learning_curves/">Learning Curves</a></li><li><a class="tocitem" href="../preparing_data/">Preparing Data</a></li><li><a class="tocitem" href="../transformers/">Transformers and Other Unsupervised models</a></li><li><a class="tocitem" href="../more_on_probabilistic_predictors/">More on Probablistic Predictors</a></li><li><a class="tocitem" href="../composing_models/">Composing Models</a></li><li><a class="tocitem" href="../linear_pipelines/">Linear Pipelines</a></li><li><a class="tocitem" href="../target_transformations/">Target Transformations</a></li><li><a class="tocitem" href="../homogeneous_ensembles/">Homogeneous Ensembles</a></li><li><a class="tocitem" href="../model_stacking/">Model Stacking</a></li><li><a class="tocitem" href="../controlling_iterative_models/">Controlling Iterative Models</a></li><li><a class="tocitem" href="../generating_synthetic_data/">Generating Synthetic Data</a></li><li><a class="tocitem" href="../openml_integration/">OpenML Integration</a></li><li><a class="tocitem" href="../acceleration_and_parallelism/">Acceleration and Parallelism</a></li><li><a class="tocitem" href="../simple_user_defined_models/">Simple User Defined Models</a></li><li><a class="tocitem" href="../quick_start_guide_to_adding_models/">Quick-Start Guide to Adding Models</a></li><li><a class="tocitem" href="../adding_models_for_general_use/">Adding Models for General Use</a></li><li><a class="tocitem" href="../modifying_behavior/">Modifying Behavior</a></li><li><a class="tocitem" href="../internals/">Internals</a></li><li><a class="tocitem" href="../list_of_supported_models/">List of Supported Models</a></li><li><a class="tocitem" href="../third_party_packages/">Third Party Packages</a></li><li><a class="tocitem" href="../glossary/">Glossary</a></li><li class="is-active"><a class="tocitem" href>MLJ Cheatsheet</a><ul class="internal"><li><a class="tocitem" href="#Starting-an-interactive-MLJ-session"><span>Starting an interactive MLJ session</span></a></li><li><a class="tocitem" href="#Model-search-and-code-loading"><span>Model search and code loading</span></a></li><li><a class="tocitem" href="#Scitypes-and-coercion"><span>Scitypes and coercion</span></a></li><li><a class="tocitem" href="#Ingesting-data"><span>Ingesting data</span></a></li><li><a class="tocitem" href="#Machine-construction"><span>Machine construction</span></a></li><li><a class="tocitem" href="#Fitting"><span>Fitting</span></a></li><li><a class="tocitem" href="#Prediction"><span>Prediction</span></a></li><li><a class="tocitem" href="#Inspecting-objects"><span>Inspecting objects</span></a></li><li><a class="tocitem" href="#Saving-and-retrieving-machines"><span>Saving and retrieving machines</span></a></li><li><a class="tocitem" href="#Performance-estimation"><span>Performance estimation</span></a></li><li><a class="tocitem" href="#Resampling-strategies-(resampling...)"><span>Resampling strategies (<code>resampling=...</code>)</span></a></li><li><a class="tocitem" href="#Tuning"><span>Tuning</span></a></li><li><a class="tocitem" href="#Controlling-iterative-models"><span>Controlling iterative models</span></a></li><li><a class="tocitem" href="#Performance-measures-(metrics)"><span>Performance measures (metrics)</span></a></li><li><a class="tocitem" href="#Transformers"><span>Transformers</span></a></li><li><a class="tocitem" href="#Ensemble-model-wrapper"><span>Ensemble model wrapper</span></a></li><li><a class="tocitem" href="#Target-transformation-wrapper"><span>Target transformation wrapper</span></a></li><li><a class="tocitem" href="#Pipelines"><span>Pipelines</span></a></li><li><a class="tocitem" href="#Define-a-supervised-learning-network:"><span>Define a supervised learning network:</span></a></li><li><a class="tocitem" href="#Exporting-a-learning-network-as-stand-alone-model:"><span>Exporting a learning network as stand-alone model:</span></a></li></ul></li><li><a class="tocitem" href="../known_issues/">Known Issues</a></li><li><a class="tocitem" href="../frequently_asked_questions/">FAQ</a></li><li><a class="tocitem" href="../julia_blogpost/">Julia BlogPost</a></li><li><a class="tocitem" href="../api/">Index of Methods</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>MLJ Cheatsheet</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>MLJ Cheatsheet</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/alan-turing-institute/MLJ.jl/blob/master/docs/src/mlj_cheatsheet.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="MLJ-Cheatsheet"><a class="docs-heading-anchor" href="#MLJ-Cheatsheet">MLJ Cheatsheet</a><a id="MLJ-Cheatsheet-1"></a><a class="docs-heading-anchor-permalink" href="#MLJ-Cheatsheet" title="Permalink"></a></h1><h2 id="Starting-an-interactive-MLJ-session"><a class="docs-heading-anchor" href="#Starting-an-interactive-MLJ-session">Starting an interactive MLJ session</a><a id="Starting-an-interactive-MLJ-session-1"></a><a class="docs-heading-anchor-permalink" href="#Starting-an-interactive-MLJ-session" title="Permalink"></a></h2><pre><code class="language-julia-repl">julia&gt; using MLJ

julia&gt; MLJ_VERSION # version of MLJ for this cheatsheet
v&quot;0.17.1&quot;</code></pre><h2 id="Model-search-and-code-loading"><a class="docs-heading-anchor" href="#Model-search-and-code-loading">Model search and code loading</a><a id="Model-search-and-code-loading-1"></a><a class="docs-heading-anchor-permalink" href="#Model-search-and-code-loading" title="Permalink"></a></h2><p><code>info(&quot;PCA&quot;)</code> retrieves registry metadata for the model called &quot;PCA&quot;</p><p><code>info(&quot;RidgeRegressor&quot;, pkg=&quot;MultivariateStats&quot;)</code> retrieves metadata for &quot;RidgeRegresssor&quot;, which is provided by multiple packages</p><p><code>models()</code> lists metadata of every registered model.</p><p><code>models(&quot;Tree&quot;)</code> lists models with &quot;Tree&quot; in the model or package name.</p><p><code>models(x -&gt; x.is_supervised &amp;&amp; x.is_pure_julia)</code> lists all supervised models written in pure julia.</p><p><code>models(matching(X))</code> lists all unsupervised models compatible with input <code>X</code>.</p><p><code>models(matching(X, y))</code> lists all supervised models compatible with input/target <code>X/y</code>.</p><p>With additional conditions:</p><pre><code class="language-julia">models() do model
    matching(model, X, y) &amp;&amp;
    model.prediction_type == :probabilistic &amp;&amp;
        model.is_pure_julia
end</code></pre><p><code>Tree = @load DecisionTreeClassifier pkg=DecisionTree</code> imports &quot;DecisionTreeClassifier&quot; type and binds it to <code>Tree</code> <code>tree = Tree()</code> to instantiate a <code>Tree</code>. </p><p><code>tree2  = Tree(max_depth=2)</code> instantiates a tree with different hyperparameter</p><p><code>Ridge = @load RidgeRegressor pkg=MultivariateStats</code> imports a type for a model provided by multiple packages</p><p>For interactive loading instead use <code>@iload</code></p><h2 id="Scitypes-and-coercion"><a class="docs-heading-anchor" href="#Scitypes-and-coercion">Scitypes and coercion</a><a id="Scitypes-and-coercion-1"></a><a class="docs-heading-anchor-permalink" href="#Scitypes-and-coercion" title="Permalink"></a></h2><p><code>scitype(x)</code> is the scientific type of <code>x</code>. For example <code>scitype(2.4) == Continuous</code></p><p><img src="../img/scitypes_small.png" alt="scitypes_small.png"/></p><table><tr><th style="text-align: right">type</th><th style="text-align: right">scitype</th></tr><tr><td style="text-align: right"><code>AbstractFloat</code></td><td style="text-align: right"><code>Continuous</code></td></tr><tr><td style="text-align: right"><code>Integer</code></td><td style="text-align: right"><code>Count</code></td></tr><tr><td style="text-align: right"><code>CategoricalValue</code> and <code>CategoricalString</code></td><td style="text-align: right"><code>Multiclass</code> or <code>OrderedFactor</code></td></tr><tr><td style="text-align: right"><code>AbstractString</code></td><td style="text-align: right"><code>Textual</code></td></tr></table><p><em>Figure and Table for common scalar scitypes</em></p><p>Use <code>schema(X)</code> to get the column scitypes of a table <code>X</code></p><p><code>coerce(y, Multiclass)</code> attempts coercion of all elements of <code>y</code> into scitype <code>Multiclass</code></p><p><code>coerce(X, :x1 =&gt; Continuous, :x2 =&gt; OrderedFactor)</code> to coerce columns <code>:x1</code> and <code>:x2</code> of table <code>X</code>.</p><p><code>coerce(X, Count =&gt; Continuous)</code> to coerce all columns with <code>Count</code> scitype to <code>Continuous</code>.</p><h2 id="Ingesting-data"><a class="docs-heading-anchor" href="#Ingesting-data">Ingesting data</a><a id="Ingesting-data-1"></a><a class="docs-heading-anchor-permalink" href="#Ingesting-data" title="Permalink"></a></h2><p>Split the table <code>channing</code> into target <code>y</code> (the <code>:Exit</code> column) and features <code>X</code> (everything else), after a seeded row shuffling:</p><pre><code class="language-julia">using RDatasets
channing = dataset(&quot;boot&quot;, &quot;channing&quot;)
y, X =  unpack(channing, ==(:Exit); rng=123)</code></pre><p>Same as above but exclude <code>:Time</code> column from <code>X</code>:</p><pre><code class="language-julia">using RDatasets
channing = dataset(&quot;boot&quot;, &quot;channing&quot;)
y, X =  unpack(channing,
               ==(:Exit),            # y is the :Exit column
               !=(:Time);            # X is the rest, except :Time
               rng=123)</code></pre><p>Splitting row indices into train/validation/test, with seeded shuffling:</p><p><code>train, valid, test = partition(eachindex(y), 0.7, 0.2, rng=1234)</code> for 70:20:10 ratio</p><p>For a stratified split:</p><p><code>train, test = partition(eachindex(y), 0.8, stratify=y)</code></p><p>Split a table or matrix <code>X</code>, instead of indices:</p><p><code>Xtrain, Xvalid, Xtest = partition(X, 0.5, 0.3, rng=123)</code> </p><p>Getting data from <a href="https://www.openml.org">OpenML</a>:</p><p><code>table = OpenML.load(91)</code></p><p>Creating synthetic classification data:</p><p><code>X, y = make_blobs(100, 2)</code> (also: <code>make_moons</code>, <code>make_circles</code>)</p><p>Creating synthetic regression data:</p><p><code>X, y = make_regression(100, 2)</code></p><h2 id="Machine-construction"><a class="docs-heading-anchor" href="#Machine-construction">Machine construction</a><a id="Machine-construction-1"></a><a class="docs-heading-anchor-permalink" href="#Machine-construction" title="Permalink"></a></h2><p>Supervised case:</p><p><code>model = KNNRegressor(K=1)</code> and <code>mach = machine(model, X, y)</code></p><p>Unsupervised case:</p><p><code>model = OneHotEncoder()</code> and <code>mach = machine(model, X)</code></p><h2 id="Fitting"><a class="docs-heading-anchor" href="#Fitting">Fitting</a><a id="Fitting-1"></a><a class="docs-heading-anchor-permalink" href="#Fitting" title="Permalink"></a></h2><p><code>fit!(mach, rows=1:100, verbosity=1, force=false)</code> (defaults shown)</p><h2 id="Prediction"><a class="docs-heading-anchor" href="#Prediction">Prediction</a><a id="Prediction-1"></a><a class="docs-heading-anchor-permalink" href="#Prediction" title="Permalink"></a></h2><p>Supervised case: <code>predict(mach, Xnew)</code> or <code>predict(mach, rows=1:100)</code></p><p>Similarly, for probabilistic models: <code>predict_mode</code>, <code>predict_mean</code> and <code>predict_median</code>.</p><p>Unsupervised case: <code>transform(mach, rows=1:100)</code> or <code>inverse_transform(mach, rows)</code>, etc.</p><h2 id="Inspecting-objects"><a class="docs-heading-anchor" href="#Inspecting-objects">Inspecting objects</a><a id="Inspecting-objects-1"></a><a class="docs-heading-anchor-permalink" href="#Inspecting-objects" title="Permalink"></a></h2><p><code>@more</code> gets detail on last object in REPL</p><p><code>params(model)</code> gets nested-tuple of all hyperparameters, even nested ones</p><p><code>info(ConstantRegressor())</code>, <code>info(&quot;PCA&quot;)</code>, <code>info(&quot;RidgeRegressor&quot;, pkg=&quot;MultivariateStats&quot;)</code> gets all properties (aka traits) of registered models</p><p><code>info(rms)</code> gets all properties of a performance measure</p><p><code>schema(X)</code> get column names, types and scitypes, and nrows, of a table <code>X</code></p><p><code>scitype(X)</code> gets scientific type of <code>X</code></p><p><code>fitted_params(mach)</code> gets learned parameters of fitted machine</p><p><code>report(mach)</code> gets other training results (e.g. feature rankings)</p><h2 id="Saving-and-retrieving-machines"><a class="docs-heading-anchor" href="#Saving-and-retrieving-machines">Saving and retrieving machines</a><a id="Saving-and-retrieving-machines-1"></a><a class="docs-heading-anchor-permalink" href="#Saving-and-retrieving-machines" title="Permalink"></a></h2><p><code>MLJ.save(&quot;trained_for_five_days.jlso&quot;, mach)</code> to save machine <code>mach</code></p><p><code>predict_only_mach = machine(&quot;trained_for_five_days.jlso&quot;)</code> to deserialize.</p><h2 id="Performance-estimation"><a class="docs-heading-anchor" href="#Performance-estimation">Performance estimation</a><a id="Performance-estimation-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-estimation" title="Permalink"></a></h2><p><code>evaluate(model, X, y, resampling=CV(), measure=rms, operation=predict, weights=..., verbosity=1)</code></p><p><code>evaluate!(mach, resampling=Holdout(), measure=[rms, mav], operation=predict, weights=..., verbosity=1)</code></p><p><code>evaluate!(mach, resampling=[(fold1, fold2), (fold2, fold1)], measure=rms)</code></p><h2 id="Resampling-strategies-(resampling...)"><a class="docs-heading-anchor" href="#Resampling-strategies-(resampling...)">Resampling strategies (<code>resampling=...</code>)</a><a id="Resampling-strategies-(resampling...)-1"></a><a class="docs-heading-anchor-permalink" href="#Resampling-strategies-(resampling...)" title="Permalink"></a></h2><p><code>Holdout(fraction_train=0.7, rng=1234)</code> for simple holdout</p><p><code>CV(nfolds=6, rng=1234)</code> for cross-validation</p><p><code>StratifiedCV(nfolds=6, rng=1234)</code> for stratified cross-validation</p><p><code>TimeSeriesSV(nfolds=4)</code> for time-series cross-validation</p><p>or a list of pairs of row indices:</p><p><code>[(train1, eval1), (train2, eval2), ... (traink, evalk)]</code></p><h2 id="Tuning"><a class="docs-heading-anchor" href="#Tuning">Tuning</a><a id="Tuning-1"></a><a class="docs-heading-anchor-permalink" href="#Tuning" title="Permalink"></a></h2><h3 id="Tuning-model-wrapper"><a class="docs-heading-anchor" href="#Tuning-model-wrapper">Tuning model wrapper</a><a id="Tuning-model-wrapper-1"></a><a class="docs-heading-anchor-permalink" href="#Tuning-model-wrapper" title="Permalink"></a></h3><p><code>tuned_model = TunedModel(model=…, tuning=RandomSearch(), resampling=Holdout(), measure=…, operation=predict, range=…)</code></p><h3 id="Ranges-for-tuning-(range...)"><a class="docs-heading-anchor" href="#Ranges-for-tuning-(range...)">Ranges for tuning (<code>range=...</code>)</a><a id="Ranges-for-tuning-(range...)-1"></a><a class="docs-heading-anchor-permalink" href="#Ranges-for-tuning-(range...)" title="Permalink"></a></h3><p>If <code>r = range(KNNRegressor(), :K, lower=1, upper = 20, scale=:log)</code></p><p>then <code>Grid()</code> search uses <code>iterator(r, 6) == [1, 2, 3, 6, 11, 20]</code>.</p><p><code>lower=-Inf</code> and <code>upper=Inf</code> are allowed.</p><p>Non-numeric ranges: <code>r = range(model, :parameter, values=…)</code></p><p>Nested ranges: Use dot syntax, as in <code>r = range(EnsembleModel(atom=tree), :(atom.max_depth), ...)</code></p><p>Can specify multiple ranges, as in <code>range=[r1, r2, r3]</code>. For more range options do <code>?Grid</code> or <code>?RandomSearch</code></p><h3 id="Tuning-strategies"><a class="docs-heading-anchor" href="#Tuning-strategies">Tuning strategies</a><a id="Tuning-strategies-1"></a><a class="docs-heading-anchor-permalink" href="#Tuning-strategies" title="Permalink"></a></h3><p><code>RandomSearch(rng=1234)</code> for basic random search</p><p><code>Grid(resolution=10)</code> or <code>Grid(goal=50)</code> for basic grid search</p><p>Also available: <code>LatinHyperCube</code>, <code>Explicit</code> (built-in), <code>MLJTreeParzenTuning</code>, <code>ParticleSwarm</code>, <code>AdaptiveParticleSwarm</code> (3rd-party packages)</p><h4 id="Learning-curves"><a class="docs-heading-anchor" href="#Learning-curves">Learning curves</a><a id="Learning-curves-1"></a><a class="docs-heading-anchor-permalink" href="#Learning-curves" title="Permalink"></a></h4><p>For generating plot of performance against parameter specified by <code>range</code>:</p><p><code>curve = learning_curve(mach, resolution=30, resampling=Holdout(), measure=…, operation=predict, range=…, n=1)</code></p><p><code>curve = learning_curve(model, X, y, resolution=30, resampling=Holdout(), measure=…, operation=predict, range=…, n=1)</code></p><p>If using Plots.jl:</p><p><code>plot(curve.parameter_values, curve.measurements, xlab=curve.parameter_name, xscale=curve.parameter_scale)</code></p><h2 id="Controlling-iterative-models"><a class="docs-heading-anchor" href="#Controlling-iterative-models">Controlling iterative models</a><a id="Controlling-iterative-models-1"></a><a class="docs-heading-anchor-permalink" href="#Controlling-iterative-models" title="Permalink"></a></h2><p>Requires: <code>using MLJIteration</code></p><p><code>iterated_model = IteratedModel(model=…, resampling=Holdout(), measure=…, controls=…, retrain=false)</code></p><h3 id="Controls"><a class="docs-heading-anchor" href="#Controls">Controls</a><a id="Controls-1"></a><a class="docs-heading-anchor-permalink" href="#Controls" title="Permalink"></a></h3><p>Increment training: <code>Step(n=1)</code></p><p>Stopping: <code>TimeLimit(t=0.5)</code> (in hours), <code>NumberLimit(n=100)</code>, <code>NumberSinceBest(n=6)</code>, <code>NotANumber()</code>, <code>Threshold(value=0.0)</code>, <code>GL(alpha=2.0)</code>, <code>PQ(alpha=0.75, k=5)</code>, <code>Patience(n=5)</code></p><p>Logging: <code>Info(f=identity)</code>, <code>Warn(f=&quot;&quot;)</code>, <code>Error(predicate, f=&quot;&quot;)</code></p><p>Callbacks: <code>Callback(f=mach-&gt;nothing)</code>, <code>WithNumberDo(f=n-&gt;@info(n))</code>, <code>WithIterationsDo(f=i-&gt;@info(&quot;num iterations: $i&quot;))</code>, <code>WithLossDo(f=x-&gt;@info(&quot;loss: $x&quot;))</code>, <code>WithTrainingLossesDo(f=v-&gt;@info(v))</code></p><p>Snapshots: <code>Save(filename=&quot;machine.jlso&quot;)</code></p><p>Wraps: <code>MLJIteration.skip(control, predicate=1)</code>, <code>IterationControl.with_state_do(control)</code></p><h2 id="Performance-measures-(metrics)"><a class="docs-heading-anchor" href="#Performance-measures-(metrics)">Performance measures (metrics)</a><a id="Performance-measures-(metrics)-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-measures-(metrics)" title="Permalink"></a></h2><p>Do <code>measures()</code> to get full list.</p><p><code>info(rms)</code> to list properties (aka traits) of the <code>rms</code> measure</p><h2 id="Transformers"><a class="docs-heading-anchor" href="#Transformers">Transformers</a><a id="Transformers-1"></a><a class="docs-heading-anchor-permalink" href="#Transformers" title="Permalink"></a></h2><p>Built-ins include: <code>Standardizer</code>, <code>OneHotEncoder</code>, <code>UnivariateBoxCoxTransformer</code>, <code>FeatureSelector</code>, <code>FillImputer</code>, <code>UnivariateDiscretizer</code>, <code>ContinuousEncoder</code>, <code>UnivariateTimeTypeToContinuous</code></p><p>Externals include: <code>PCA</code> (in MultivariateStats), <code>KMeans</code>, <code>KMedoids</code> (in Clustering).</p><p><code>models(m -&gt; !m.is_supervised)</code> to get full list</p><h2 id="Ensemble-model-wrapper"><a class="docs-heading-anchor" href="#Ensemble-model-wrapper">Ensemble model wrapper</a><a id="Ensemble-model-wrapper-1"></a><a class="docs-heading-anchor-permalink" href="#Ensemble-model-wrapper" title="Permalink"></a></h2><p><code>EnsembleModel(atom=…, weights=Float64[], bagging_fraction=0.8, rng=GLOBAL_RNG, n=100, parallel=true, out_of_bag_measure=[])</code></p><h2 id="Target-transformation-wrapper"><a class="docs-heading-anchor" href="#Target-transformation-wrapper">Target transformation wrapper</a><a id="Target-transformation-wrapper-1"></a><a class="docs-heading-anchor-permalink" href="#Target-transformation-wrapper" title="Permalink"></a></h2><p><code>TransformedTargetModel(model=ConstantClassifier(), target=Standardizer())</code></p><h2 id="Pipelines"><a class="docs-heading-anchor" href="#Pipelines">Pipelines</a><a id="Pipelines-1"></a><a class="docs-heading-anchor-permalink" href="#Pipelines" title="Permalink"></a></h2><p><code>pipe = (X -&gt; coerce(X, :height=&gt;Continuous)) |&gt; OneHotEncoder |&gt; KNNRegressor(K=3)</code> </p><p>Unsupervised:</p><p><code>pipe = Standardizer |&gt; OneHotEncoder</code></p><p>Concatenation:</p><p><code>pipe1 |&gt; pipe2</code> or <code>model |&gt; pipe</code> or <code>pipe |&gt; model</code>, etc</p><h2 id="Define-a-supervised-learning-network:"><a class="docs-heading-anchor" href="#Define-a-supervised-learning-network:">Define a supervised learning network:</a><a id="Define-a-supervised-learning-network:-1"></a><a class="docs-heading-anchor-permalink" href="#Define-a-supervised-learning-network:" title="Permalink"></a></h2><p><code>Xs = source(X)</code> <code>ys = source(y)</code></p><p>... define further nodal machines and nodes ...</p><p><code>yhat = predict(knn_machine, W, ys)</code> (final node)</p><h2 id="Exporting-a-learning-network-as-stand-alone-model:"><a class="docs-heading-anchor" href="#Exporting-a-learning-network-as-stand-alone-model:">Exporting a learning network as stand-alone model:</a><a id="Exporting-a-learning-network-as-stand-alone-model:-1"></a><a class="docs-heading-anchor-permalink" href="#Exporting-a-learning-network-as-stand-alone-model:" title="Permalink"></a></h2><p>Supervised, with final node <code>yhat</code> returning point-predictions:</p><pre><code class="language-julia">@from_network machine(Deterministic(), Xs, ys; predict=yhat) begin
    mutable struct Composite
	    reducer=network_pca
		regressor=network_knn
    end</code></pre><p>Here <code>network_pca</code> and <code>network_knn</code> are models appearing in the learning network.</p><p>Supervised, with <code>yhat</code> final node returning probabilistic predictions:</p><pre><code class="language-julia">@from_network machine(Probabilistic(), Xs, ys; predict=yhat) begin
    mutable struct Composite
        reducer=network_pca
        classifier=network_tree
    end</code></pre><p>Unsupervised, with final node <code>Xout</code>:</p><pre><code class="language-julia">@from_network machine(Unsupervised(), Xs; transform=Xout) begin
    mutable struct Composite
	    reducer1=network_pca
		reducer2=clusterer
    end
end</code></pre><p>UnivariateTimeTypeToContinuous</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../glossary/">« Glossary</a><a class="docs-footer-nextpage" href="../known_issues/">Known Issues »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 17 February 2022 01:51">Thursday 17 February 2022</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
